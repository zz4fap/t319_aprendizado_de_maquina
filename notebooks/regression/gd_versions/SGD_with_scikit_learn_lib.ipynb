{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDRegressor\n",
    "\n",
    "+ A biblioteca Scikit-Learn disponibiliza a classe `SGDRegressor` para realizar regressão linear utilizando o algoritmo do **Gradiente Descendente Estocástico**.\n",
    "+ A classe possui vários parâmetros que podem ser configurados (e.g., tipo de função de erro, esquema de variação do passo de aprendizagem, etc.).\n",
    "+ Após instanciarmos um objeto dessa classe, o treinamento é feito com o método `fit` e a predição é feita com o método `predict`.\n",
    "+ Os pesos são acessados, **após o treinamento**, através dos atributos `intercept_` e `coef_` do objeto da classe `SGDRegressor`.\n",
    "+ Não conseguimos implementar as versões em batelada e mini-batch com esta classe.\n",
    "+ Para mais informações sobre a classe `SGDRegressor`, acesse sua documentação: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/zz4fap/t319_aprendizado_de_maquina/main/figures/scikitlearn.png\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Importamos a classe SGDRegressor do módulo Linear da biblioteca sklearn.\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reseta gerador de sequências pseudo-aleatórias.\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerando o conjunto de treinamento.\n",
    "\n",
    "A função objetivo do exemplo é dada por: $y = a_1 x_1 + a_2 x_2$, onde $a_1=2$ e $a_2=4$.\n",
    "\n",
    "A função hipótese que iremos usar tem o seguinte formato: $h(x) = \\hat{a}_1 x_1 + \\hat{a}_2 x_2$, onde $\\hat{a}_1$ e $\\hat{a}_2$ são os parâmetros (ou seja, os pesos) que queremos encontrar.\n",
    "\n",
    "**OBS**.: Percebam que não temos peso de bias (ou intercept), $a_0$, e, portanto, não precisamos do atributo de bias (valor sempre igual a 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de exemplos\n",
    "N = 1000\n",
    "\n",
    "# Atributos.\n",
    "x1 = np.random.randn(N, 1)\n",
    "x2 = np.random.randn(N, 1)\n",
    "\n",
    "# Ruído.\n",
    "w = np.random.randn(N, 1)\n",
    "\n",
    "# Modelo gerador.\n",
    "y = 2*x1 + 4*x2\n",
    "\n",
    "# Função observável.\n",
    "y_noisy = y + w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instancia o regressor baseado no gradiente descendente estocástico. \n",
    "\n",
    "\n",
    "**OBS**.: Como o modelo gerador e a função hipótese não tem o peso $a_0$ (intercept/bias), não precisamos encontrá-lo. Para fazer com que a classe `SGDRegressor` não estime o valor de $a_0$, configuramos o parâmetro `fit_intercept` da classe `SGDRegressor` com o valor `False`, ou seja `'fit_intercept=False'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia a classe SGDRegressor.\n",
    "sgd_reg = SGDRegressor(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treina o regressor.\n",
    "\n",
    "Como a função hipótese utilizada neste exemplo tem o seguinte formato: $h(x) = \\hat{a}_1 x_1 + \\hat{a}_2 x_2$, então, precisamos criar uma matriz de atributos que concatene os dois vetores coluna, $x_1$ e $x_2$.\n",
    "\n",
    "**OBS**.: O método `fit` espera que os rótulos tenham apenas uma dimensão, portanto, o método `ravel()` converte o vetor coluna (duas dimensões) em uma array com apenas uma dimensão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 9\n"
     ]
    }
   ],
   "source": [
    "# Concatena os vetores coluna x1 e x2.\n",
    "X = np.c_[x1, x2]\n",
    "\n",
    "# Treina o modelo.\n",
    "sgd_reg.fit(X, y.ravel())\n",
    "\n",
    "# O atributo n_iter_ da classe SGDRegressor retorna o número de iterações que foram necessárias até que o algoritmo pare de treinar.\n",
    "print('Number of iterations:', sgd_reg.n_iter_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realiza predições com o regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz previsão com o modelo treinado.\n",
    "y_pred = sgd_reg.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo do erro quadrático médio (MSE).\n",
    "\n",
    "**OBS**.: Observe que é feito o reshape do vetor `y_pred`, pois ele é apenas uma array com um única dimensão e para realizar o cálculo do MSE, espera-se vetores coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jgde: 0.9607751023749168\n"
     ]
    }
   ],
   "source": [
    "Jgde = (1.0/N)*np.sum(np.square(y_noisy - y_pred.reshape(N, 1)))\n",
    "print('Jgde:', Jgde)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imprime os pesos encontrados pelo GDE.\n",
    "\n",
    "**OBS**.: Como não configuramos a classe `SGDRegressor` para estimar o valor de $a_0$, o atributo `intercept_` da classe terá valor igual a `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a0: 0.0000\n",
      "a1: 1.9998\n",
      "a2: 3.9996\n"
     ]
    }
   ],
   "source": [
    "# Imprime os valores encontrados pelo GDE.\n",
    "print('a0: %1.4f' % (sgd_reg.intercept_))\n",
    "print('a1: %1.4f' % (sgd_reg.coef_[0]))\n",
    "print('a2: %1.4f' % (sgd_reg.coef_[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
