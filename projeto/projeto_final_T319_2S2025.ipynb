{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "da867ff1",
      "metadata": {
        "id": "da867ff1"
      },
      "source": [
        "# Projeto Final - T319 (2S2025)\n",
        "\n",
        "### Instruções\n",
        "\n",
        "1. Quando você terminar os exercícios do projeto, vá até o menu do Colab ou Jupyter e selecione a opção para fazer download do notebook.\n",
        "    * Os notebooks tem extensão .ipynb.\n",
        "    * Este deve ser o arquivo que você irá entregar.\n",
        "    * No Colab vá até a opção **File** -> **Download .ipynb**.\n",
        "    * No Jupyter vá até a opção **File** -> **Download as** -> **Notebook (.ipynb)**.\n",
        "2. Após o download do notebook, vá até a aba de tarefas do MS Teams, localize a tarefa referente a este projeto e faça o upload do seu notebook. Veja que há uma opção para anexar arquivos à tarefa.\n",
        "3. Atente-se ao prazo de entrega definido na tarefa do MS Teams. Entregas fora do prazo não serão consideradas.\n",
        "4. **O projeto pode ser resolvido em grupos de no MÁXIMO 3 alunos**.\n",
        "5. Todas as questões têm o mesmo peso.\n",
        "6. Questões copiadas de outros grupos serão anuladas em todos os grupos com a mesma resposta.\n",
        "7. Não se esqueça de colocar seu(s) nome(s) e número(s) de matrícula no campo abaixo. Coloque os nomes dos integrantes do grupo no campo de texto abaixo.\n",
        "8. Você pode consultar todo o material de aula e laboratórios.\n",
        "9. A interpretação faz parte do projeto. Leia o enunciado de cada questão atentamente!\n",
        "10. Boa sorte!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0587a29e",
      "metadata": {
        "id": "0587a29e"
      },
      "source": [
        "**Nomes e matrículas**:\n",
        "\n",
        "1. Nome do primeiro aluno - Matrícula do primeiro aluno\n",
        "2. Nome do segundo aluno - Matrícula do segundo aluno\n",
        "3. Nome do terceiro aluno - Matrícula do terceiro aluno"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "972fea32",
      "metadata": {
        "id": "972fea32"
      },
      "source": [
        "## Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d0755d",
      "metadata": {
        "id": "e4d0755d"
      },
      "source": [
        "### 1) Exercício sobre a escolha do passo de aprendizagem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c352a37",
      "metadata": {
        "id": "8c352a37"
      },
      "source": [
        "1. Execute a célula de código abaixo para importar as bibliotecas e definir algumas funções necessárias para o treinamento de um modelo de regressão linear.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ A função `gradientDescent` implementa a versão **estocástica** do gradiente descendente.\n",
        "+ Note que a função `gradientDescent` utiliza **decaimento temporal** do passo de aprendizagem para tornar o aprendizado do algoritmo mais comportado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c7e72b6",
      "metadata": {
        "id": "9c7e72b6"
      },
      "outputs": [],
      "source": [
        "# Import all necessary libraries.\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Reseta os gerados de sequências pseudo-aleatórias.\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "def calculateErrorSurface(x, y):\n",
        "    \"\"\"Generate data points for plotting the error surface.\"\"\"\n",
        "\n",
        "    # Retrieve number of examples.\n",
        "    N = len(y)\n",
        "\n",
        "    # Generate values for parameter space.\n",
        "    M = 200\n",
        "    a1 = np.linspace(2.5, 2.59, M)\n",
        "    a2 = np.linspace(-1.020, -0.995, M)\n",
        "\n",
        "    # Generate matrices with combinations between a0 and a1 values.\n",
        "    A1, A2 = np.meshgrid(a1, a2)\n",
        "\n",
        "    # Generate points for plotting the cost-function surface.\n",
        "    J = np.zeros((M,M))\n",
        "    for iter1 in range(0, M):\n",
        "        for iter2 in range(0, M):\n",
        "            # Hypothesis function (a second degree function).\n",
        "            yhat = A1[iter1, iter2]*x + A2[iter1, iter2]*np.floor(2.5*x + 0.5)\n",
        "            # Calculate the mean squared error (MSE) for each pair of values.\n",
        "            J[iter1, iter2] = (1.0/N)*np.sum(np.square(y - yhat))\n",
        "\n",
        "    return J, A1, A2\n",
        "\n",
        "def timeBasedDecay(alpha_init, k, t):\n",
        "    '''Decaimento temporal.'''\n",
        "    return alpha_init / (1.0 + k*t)\n",
        "\n",
        "def gradientDescent(X_train, y_train, X_test, y_test, n_epochs, alpha_init, k):\n",
        "    '''\n",
        "    Função que implementa a versão estocástica do gradiente descendente.\n",
        "    Os parâmetros de entrada da função são:\n",
        "    * X_train    - Matriz de atributos de treinamento\n",
        "    * y_train    - vetor de rótulos de treinamento\n",
        "    * X_test     - Matriz de atributos de teste\n",
        "    * y_test     - vetor de rótulos de teste\n",
        "    * n_epochs   - número máximo de épocas de treinamento\n",
        "    * alpha_init - valor inicial do passo de aprendizagem\n",
        "    * k          - taxa de decaimento da redução temporal do passo de aprendizagem\n",
        "\n",
        "    Os valores retornados são:\n",
        "    * a               : vetor de pesos correspondente à última iteração de atualização\n",
        "    * a_min           : vetor de pesos correspondente ao menor erro de teste\n",
        "    * Jgd             : vetor com os valores do erro de treinamento ao longo do treinamento\n",
        "    * Jgd_test        : vetor com os valores do erro de teste ao longo do treinamento\n",
        "    * a_hist          : matriz com o histórico dos valore do vetor de pesos\n",
        "    * alpha_hist      : vetor com histórico dos valores do passo de aprendizagem\n",
        "    * update_hist     : matriz com o histórico de vetores de atualização dos pesos\n",
        "    * gradient_hist   : matriz com o histórico de vetores gradiente\n",
        "    * iteration       : valor da última iteração\n",
        "    '''\n",
        "\n",
        "    # Reseta os geradores de sequências pseudo-aleatórias.\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    # Number of training examples.\n",
        "    N_train = len(y_train)\n",
        "\n",
        "    # Number of test examples.\n",
        "    N_test = len(y_test)\n",
        "\n",
        "    # Reshape y to be a column vector.\n",
        "    y_train = y_train.reshape(N_train,1)\n",
        "\n",
        "    # Inicialização do vetor de pesos.\n",
        "    a = np.array([-5.0, -4.0]).reshape(2, 1)\n",
        "\n",
        "    # Create vector for parameter history.\n",
        "    a_hist = np.zeros((2, n_epochs*N_train+1))\n",
        "    # Initialize history vector.\n",
        "    a_hist[:, 0] = a.reshape(2,)\n",
        "\n",
        "    # Create vector to store eta history.\n",
        "    alpha_hist = np.zeros((n_epochs*N_train))\n",
        "\n",
        "    # Create array for storing training error values.\n",
        "    Jgd = np.zeros(n_epochs*N_train+1)\n",
        "\n",
        "    # Create array for storing test error values.\n",
        "    Jgd_test = np.zeros(n_epochs*N_train+1)\n",
        "\n",
        "    # Calcule o MSE com conjunto de treinamento para o conjunto de pesos inicial.\n",
        "    Jgd[0] = (1.0/N_train)*np.sum(np.power(y_train - X_train.dot(a), 2))\n",
        "\n",
        "    # Calcule o MSE com conjunto de teste para o conjunto de pesos inicial.\n",
        "    Jgd_test[0] = (1.0/N_test)*np.sum(np.power((y_test - X_test.dot(a)), 2))\n",
        "\n",
        "    # Cria arrays para armazenar vetores de atualização e gradiente.\n",
        "    update_hist = np.zeros((2, n_epochs*N_train))\n",
        "    gradient_hist = np.zeros((2, n_epochs*N_train))\n",
        "\n",
        "    # Stocastic gradient-descent loop.\n",
        "    iteration = 0\n",
        "    min_test_error = float('inf')\n",
        "    min_test_error_iteration = 0\n",
        "    a_min = a\n",
        "    # Época de treinamento, apresenta todas os exemplos de treinamento ao modelo.\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # Shuffle the whole dataset before every epoch.\n",
        "        shuffled_data_set_indexes = random.sample(range(0, N_train), N_train)\n",
        "\n",
        "        # Iteração de treinamento, apenas um exemplo é apresentado ao modelo.\n",
        "        for i in range(N_train):\n",
        "            # Retrieve one pair of atribute vector and label.\n",
        "            random_index = shuffled_data_set_indexes[i]\n",
        "            xi = X_train[random_index:random_index+1]\n",
        "            yi = y_train[random_index:random_index+1]\n",
        "\n",
        "            # Decaimento temporal do passo de aprendizagem.\n",
        "            alpha = timeBasedDecay(alpha_init, k, epoch*N_train + i)\n",
        "\n",
        "            # Cálculo da estimativa do vetor gradiente com apenas uma amostra.\n",
        "            gradient = -2.0*xi.T.dot(yi - xi.dot(a))\n",
        "            update = alpha*gradient\n",
        "            a = a - update\n",
        "\n",
        "            # Armazena o histórico de valores.\n",
        "            a_hist[:, epoch*N_train+i+1] = a.reshape(2,)\n",
        "            alpha_hist[epoch*N_train+i] = alpha\n",
        "            update_hist[:, epoch*N_train+i] = update.reshape(2,)\n",
        "            gradient_hist[:, epoch*N_train+i] = gradient.reshape(2,)\n",
        "\n",
        "            # Calcula o MSE com conjunto de treinamento por itereção de treinamento.\n",
        "            Jgd[epoch*N_train+i+1] = (1.0/N_train)*np.sum(np.power((y_train - X_train.dot(a)), 2))\n",
        "\n",
        "            # Calcula o MSE com conjunto de teste por itereção de treinamento.\n",
        "            Jgd_test[epoch*N_train+i+1] = (1.0/N_test)*np.sum(np.power((y_test - X_test.dot(a)), 2))\n",
        "\n",
        "            # Early-stopping.\n",
        "            if Jgd_test[epoch*N_train+i+1] < min_test_error:\n",
        "                min_test_error = Jgd_test[epoch*N_train+i+1]\n",
        "                min_test_error_iteration = epoch*N_train+i+1\n",
        "                a_min = a\n",
        "\n",
        "            # Incrementa o contador de iterações.\n",
        "            iteration = epoch*N_train+i\n",
        "\n",
        "    return a, a_min, Jgd, Jgd_test, a_hist, alpha_hist, update_hist, gradient_hist, iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79ff2f71",
      "metadata": {
        "id": "79ff2f71"
      },
      "source": [
        "2. Execute a célula de código abaixo para criar o conjunto de dados que será usado neste exercício.\n",
        "\n",
        "+ A função objetivo utilizada neste exercício é dada por\n",
        "$$y = 2.5x - \\lfloor 2.5 x + 0.5 \\rfloor,$$\n",
        "onde $a_1=2.5$, $a_2=-1.0$ e $\\lfloor . \\rfloor$ é uma função matemática que arredonda um número real para o menor inteiro que não é maior que o número. Em outras palavras, ela \"arredonda para baixo\" em direção ao negativo infinito.\n",
        "\n",
        "+ A função hipótese que utilizaremos tem o mesmo formato da função objetivo,\n",
        "$$\\hat{y} = \\hat{a}_1 + \\hat{a}_2 \\lfloor 2.5 x + 0.5 \\rfloor,$$\n",
        "sendo o objetivo do algoritmo do gradiente descendente estocástico encontrar aproximações, $\\hat{a}_1$ e $\\hat{a}_2$, para os valores ideais, ${a}_1$ e ${a}_2$.\n",
        "\n",
        "+ Para representarmos a função hipótese em formato matricial, i.e., $\\textbf{y} = \\textbf{X}\\textbf{a}$, precisamos criar a matriz de atributos concatenando os vetores dos atributos $\\textbf{x}$ e $\\lfloor 2.5 \\textbf{x} + 0.5 \\rfloor$.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Na célula de código abaixo, o vetor do atributo $\\textbf{x}$ é concatenado ao vetor do atributo $\\lfloor 2.5 \\textbf{x} + 0.5 \\rfloor$, formando a matriz de atributos, $\\textbf{X}$.\n",
        "+ Essa concatenação é feita de forma manual, pois a implementação da versão estocática do gradiente descendente fornecida acima não faz isso automaticamente como no caso das classes fornecidas pela bilbioteca SciKit-Learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2963942f",
      "metadata": {
        "id": "2963942f"
      },
      "outputs": [],
      "source": [
        "# Número de amostras\n",
        "N = 1000\n",
        "\n",
        "# Gera um vetor de atributo.\n",
        "x = np.linspace(0, 1, N, endpoint=False).reshape(N,1)\n",
        "\n",
        "# Cria uma função dente de serra.\n",
        "y = 2.5*x - np.floor(2.5*x + 0.5)\n",
        "\n",
        "# Ruído.\n",
        "w = np.sqrt(0.01)*np.random.randn(N, 1)\n",
        "\n",
        "# Função observável.\n",
        "y_noisy = y + w\n",
        "\n",
        "# Cria matriz de atributos.\n",
        "X = np.c_[x, np.floor(2.5*x + 0.5)]\n",
        "\n",
        "# Figura comparando as duas funções.\n",
        "plt.plot(x, y_noisy, label='Função observável')\n",
        "plt.plot(x, y, label='Função objetivo')\n",
        "plt.xlabel('x', fontsize=14)\n",
        "plt.ylabel('y', fontsize=14)\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33a0030c",
      "metadata": {
        "id": "33a0030c"
      },
      "source": [
        "3. Analise a geração das amostras da função observável no item anterior e responda: qual é o menor erro (i.e., erro quadrático médio - EQM) possível com um regressor linear treinado com essas amostras?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3352b2fa",
      "metadata": {
        "id": "3352b2fa"
      },
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0ec2d00",
      "metadata": {
        "id": "d0ec2d00"
      },
      "source": [
        "4. Divida o conjunto total de amostras em conjuntos de treinamento e validação. O conjunto de treinamento deve conter 75% do total de amostras e o conjunto de validação os 25% restantes.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Use a função `train_test_split` e a configure com os seguintes parâmetros `test_size=0.25` e `random_state=seed`. A função divide o conjunto original de amostras em dois subconjuntos, um para treinamento e outro para validação (i.e., para avaliar a capacidade de generalização do modelo). Veja o código abaixo.\n",
        "```python\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_noisy, test_size=0.25, random_state=seed)\n",
        "```\n",
        "+ Para que o próximo item do exercício funcione, chame as matrizes de treinamento e de validação de `X_train` e `X_test`, respectivamente, e os vetores de rótulos de treinamento e de validação de `y_train` e `y_test`, respectivamente, como no exemplo acima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf922796",
      "metadata": {
        "id": "cf922796"
      },
      "outputs": [],
      "source": [
        "# Digite o código do exercício aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dce2f23",
      "metadata": {
        "id": "9dce2f23"
      },
      "source": [
        "5. Execute a célula de código abaixo e analise as figuras.\n",
        "\n",
        "A célula abaixo treina o modelo de regressão usando a função `gradientDescent` com os seguintes valores:\n",
        "+ **taxa de decaimento ($k$)**: 0.1, 0.05, e 0.01.\n",
        "+ **passo de aprendizagem ($\\alpha$)**: 0.495, 0.25, 0.125, 0.0625 e 0.03125.\n",
        "\n",
        "Cada figura mostra o erro de treinamento em função das iterações de treinamento para um valor específico da taxa de decaimento ($k$) e vários valores para o passo de aprendizagem ($\\alpha$). O valor de taxa de decaimento ($k$) é mostrado no título (i.e., topo) da figura, enquanto os diferentes valores de passo de aprendizagem ($\\alpha$) são mostrados com cores diferentes na legenda de cada figura.\n",
        "\n",
        "**DICA**:\n",
        "\n",
        "+ Lembrem-se que o menor valor do EQM tende ao valor da variância do ruído adicionado às amostras da função objetivo quando encontra-se os valores ótimos dos pesos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d65e7a56",
      "metadata": {
        "id": "d65e7a56"
      },
      "outputs": [],
      "source": [
        "# Número de épocas.\n",
        "n_epochs = 2\n",
        "# Lista de taxas de decaimento.\n",
        "k_list = [0.1, 0.05, 0.01]\n",
        "# Lista de passos de aprendizagem.\n",
        "alpha_list = [0.495, 0.25, 0.125, 0.0625, 0.03125]\n",
        "\n",
        "# Lista para armazenar os erros das combinações de taxa de decaimento e passo de aprendizagem.\n",
        "error = []\n",
        "for k in k_list:\n",
        "    error_hist = []\n",
        "    for alpha in alpha_list:\n",
        "        a, a_min, Jgd, Jgd_test, a_hist, alpha_hist, update_hist, gradient_hist, iteration = gradientDescent(X_train, y_train, X_test, y_test, n_epochs, alpha_init=alpha, k=k)\n",
        "        error_hist.append(Jgd_test)\n",
        "    error.append(error_hist)\n",
        "\n",
        "# Visualização do erro durante o treinamento de cada passo de aprendizagem.\n",
        "plt.figure(figsize=(15,5))\n",
        "for i in range(len(k_list)):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    plt.title('k = '+str(k_list[i]))\n",
        "    for j in range(len(alpha_list)):\n",
        "        plt.plot(np.arange(error[i][j].shape[0]), error[i][j], label=('alpha = '+f'{alpha_list[j]}'))\n",
        "        plt.yscale('log')\n",
        "    plt.xlabel('Iterações')\n",
        "    plt.ylabel('EQM')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.ylim([0.008, 50])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c17f54a0",
      "metadata": {
        "id": "c17f54a0"
      },
      "source": [
        "6. Analise as figuras do item anterior e responda: Quais são os valores ideais para a taxa de decaimento ($k$) e o passo de aprendizagem ($\\alpha$)? (**Justifique sua resposta**).\n",
        "\n",
        "**DICA**\n",
        "\n",
        "+ A ideia é que o aprendizado seja rápido, ou seja, convirja rapidamente (erro praticamente constante), mas sem muita oscilação no erro."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a49d7b4",
      "metadata": {
        "id": "3a49d7b4"
      },
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51df4a34",
      "metadata": {
        "id": "51df4a34"
      },
      "source": [
        "7. De posse dos valores ideais para a taxa de decaimento ($k$) e passo de aprendizagem ($\\alpha$), treine novamente o modelo com estes valores e imprima os erros quadráticos médios (EQMs) obtidos para os conjuntos de treinamento de validação e o valor dos pesos $\\hat{a}_1$ e $\\hat{a}_2$.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Configure a função `gradientDescent` com os melhores valores para a taxa de decaimento ($k$) e passo de aprendizagem ($\\alpha$) obtidos no item anterior.\n",
        "+ Os parâmetros de entrada da função `gradientDescent` são descritos em seu cabeçalho. Veja a definição da função.\n",
        "+ Treine o modelo com o conjunto de treinamento.\n",
        "+ Configure o **número de épocas**, `n_epochs`, com o valor `2`, ou seja, o modelo será treinado por 2 épocas.\n",
        "+ Lembre-se que a função hipótese é expressa no formato vetorial como $\\hat{\\textbf{y}}=\\textbf{X}\\textbf{a}$, onde $\\textbf{X}$ é a matriz de atributos e $\\textbf{a}$ é o vetor de pesos. Portanto, para fazer predições com as matrizes de atributos de treinamento e validação, você precisa utilizar a função hipótese no formato vetorial.\n",
        "+ Você pode usar a função `mean_squared_error` da biblioteca SciKit-Learn para calcular o EQM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8bad5f2",
      "metadata": {
        "id": "d8bad5f2"
      },
      "outputs": [],
      "source": [
        "# Digite o código do exercício aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dbf858b",
      "metadata": {
        "id": "9dbf858b"
      },
      "source": [
        "8. Treine um modelo usando a **equação normal** (i.e., a equação que dá a solução ótima para o conjunto de treinamento fornecido). Ao final, imprima o erro quadrático médio (EQM) obtido pelo modelo para os conjuntos de treinamento e validação. Além disso, imprima o valor dos pesos $\\hat{a}_1$ e $\\hat{a}_2$ obtidos com a **equação normal**.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Você pode utilizar a classe `LinearRegression` da biblioteca SciKit-Learn para resolver este item ou implementar a equação normal manualmente.\n",
        "+ Caso você use a classe `LinearRegression`, a configure com o parâmetro `fit_intercept=False`, pois a matriz de atributos criada no item 2 do exercício, já contém a coluna do atributos de bias, ou seja, a coluna com todos os valores iguais a 1.\n",
        "+ Usando a classe `LinearRegression`:\n",
        "  * A predição é feita com o método `predict()`.\n",
        "  * Os pesos do modelo podem ser acessados através do atributo `coef_` da classe `LinearRegression`. Por exemplo, dado que o nome do objeto da classe `LinearRegression` é `reg`, então `reg.coef_[0,0]` acessa o valor ótimo encontrado para o peso $\\hat{a}_1$ e `reg.coef_[0,1]` acessa o valor ótimo encontrado para o peso $\\hat{a}_2$.\n",
        "+ Você pode usar a função `mean_squared_error` da biblioteca SciKit-Learn para calcular o EQM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "990cc2be",
      "metadata": {
        "id": "990cc2be"
      },
      "outputs": [],
      "source": [
        "# Digite o código do exercício aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02debd0d",
      "metadata": {
        "id": "02debd0d"
      },
      "source": [
        "9. Compare os pesos ($\\hat{a}_1$ e $\\hat{a}_2$) e os erros, i.e., EQMs, (para os conjuntos de treinamento e validação) obtidos com os modelos usando a equação normal (item 8) e o gradiente descendente estocástico com os melhores valores para a taxa de decaimento e passo de aprendizagem (item 7). Em seguida, responda: os valores dos pesos são diferentes? Se sim, explique o motivo da diferença. (**Justifique sua resposta**).\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Lembre-se que a equação normal dá a solução ótima, ou seja, ela fornece os pesos que minimizam o EQM. Não existem outros pesos que resultem em um EQM menor para o conjunto de treinamento usado.\n",
        "+ As estimativas do vetor gradiente com o gradiente descendente estocástico, mesmo com os melhores valores para a taxa de decaimento e passo de aprendizagem, continuam sendo ruidosas, consequentemente, as atualizações dos pesos também serão ruidosas.\n",
        "+ Além disso, os valores encontrados para a taxa de decaimento e passo de aprendizagem podem não ser os ótimos.\n",
        "+ Reveja o material de aula e os exemplos onde discutimos as versões do gradiente descendente."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "270df576",
      "metadata": {
        "id": "270df576"
      },
      "source": [
        "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>\n",
        "\n",
        "**Resposta**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c6f0622",
      "metadata": {
        "id": "3c6f0622"
      },
      "source": [
        "10. Plote a superfície de contorno desta função hipótese e mostre que os pesos encontrados com a equação normal e gradiente descendente são próximos, mas não idênticos.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Use a função `calculateErrorSurface` definida no item 1 deste exercício.\n",
        "+ A função `calculateErrorSurface` restringe o eixo de $\\hat{a}_1$ entre os valores $2.5$ e $2.59$.\n",
        "+ A função `calculateErrorSurface` restringe o eixo de $\\hat{a}_2$ entre os valores $-1.020$ e $-0.995$.\n",
        "+ Use as funções `xlim` e `ylim` da biblioteca matplotlib para restringir a figura aos limites de $\\hat{a}_1$ e $\\hat{a}_2$ mencionados acima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19e53a35",
      "metadata": {
        "id": "19e53a35"
      },
      "outputs": [],
      "source": [
        "# Digite o código do exercício aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Plote uma figura que compare as funções objetivo, observável e aproximada (via gradiente descendente estocástico e equação normal). Use o conjunto total de amostras. No caso da função aproximada via gradiente descendente estocástico, use o vetor de pesos obtido com o `early-stopping`.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Use a matriz $\\textbf{X}$, criada no item 2, para fazer as predições com o conjunto total de dados.\n",
        "+ Analise o código da função `gradientDescent` definida no item 1 para identificar qual é a variável com o vetor de pesos obtido com o `early-stopping`."
      ],
      "metadata": {
        "id": "Qgt6yJR3EMg5"
      },
      "id": "Qgt6yJR3EMg5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite o código do exercício aqui."
      ],
      "metadata": {
        "id": "mEhtGWxaEMub"
      },
      "id": "mEhtGWxaEMub",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Discuta os resultados apresentados na figura anterior. O que você consegue concluir? (**Justifique sua resposta**)"
      ],
      "metadata": {
        "id": "vXYS4ieuJUX8"
      },
      "id": "vXYS4ieuJUX8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
      ],
      "metadata": {
        "id": "f9hHG0OPJUjz"
      },
      "id": "f9hHG0OPJUjz"
    },
    {
      "cell_type": "markdown",
      "id": "ksgLxcaup0Bu",
      "metadata": {
        "id": "ksgLxcaup0Bu"
      },
      "source": [
        "### 2) Previsão do Desempenho de Hardware de Computadores\n",
        "\n",
        "O conjunto de dados Computer Hardware contém informações sobre características técnicas de computadores de diferentes fabricantes, com o objetivo de estimar seu desempenho medido pelo ERP (Estimated Relative Performance). Sua tarefa será desenvolver um modelo de regressão para prever o ERP com base nas características técnicas dos sistemas. A tabela abaixo aprenta os atributos e o rótulo.\n",
        "\n",
        "\n",
        "| Nome do Atributo | Descrição                                 | Tipo        | Unidade/Faixa                   |\n",
        "|-------------------|-------------------------------------------|-------------|---------------------------------|\n",
        "| **vendor**        | Fabricante do computador                  | Categórico  | Strings, 30 valores (ex: IBM, HP, Siemens) |\n",
        "| **model** | Modelo | Categórico | Strings com os nomes dos modelos |\n",
        "| **MYCT**          | Tempo do ciclo da máquina (Machine Cycle Time) | Numérico    | Nanossegundos (ns)             |\n",
        "| **MMIN**          | Memória principal mínima                  | Numérico    | Kilobytes (KB)                 |\n",
        "| **MMAX**          | Memória principal máxima                  | Numérico    | Kilobytes (KB)                 |\n",
        "| **CACH**          | Memória cache                             | Numérico    | Kilobytes (KB)                 |\n",
        "| **CHMIN**         | Número mínimo de canais de I/O            | Numérico    | Unidades                        |\n",
        "| **CHMAX**         | Número máximo de canais de I/O            | Numérico    | Unidades                        |\n",
        "| **PRP**           | *Published Relative Performance* (desempenho relativo publicado) | Numérico | Escala adimensional           |\n",
        "| **ERP**           | **Rótulo (Target):** *Estimated Relative Performance* (desempenho relativo estimado) | Numérico | Escala adimensional |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "voRP61tJEuuG",
      "metadata": {
        "id": "voRP61tJEuuG"
      },
      "source": [
        "1. Execute a célula de código abaixo para baixar e criar a base de dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2DpjRZHsp0QX",
      "metadata": {
        "id": "2DpjRZHsp0QX"
      },
      "outputs": [],
      "source": [
        "# Importando bibliotecas necessárias\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pandas import DataFrame\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Carregamento dos Dados\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/cpu-performance/machine.data\"\n",
        "columns = ['vendor', 'model', 'MYCT', 'MMIN', 'MMAX', 'CACH', 'CHMIN', 'CHMAX', 'PRP', 'ERP']\n",
        "df = pd.read_csv(url, header=None, names=columns)\n",
        "\n",
        "# Imprime as 5 primeiras linhas da base de dados.\n",
        "print(df.head())\n",
        "\n",
        "# Criando a matriz de atributos, removendo as colunas vendor e model, pois são strings, e as colunas PRP e ERP, pois são os possíveis rótulos. Entretanto, usaremos apenas a coluna ERP como rótulo.\n",
        "X = df.drop([\"vendor\", \"model\", \"PRP\", \"ERP\"], axis=1)\n",
        "# Criando o vetor de rótulos.\n",
        "y = df.ERP"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fqNE1wPMFykR",
      "metadata": {
        "id": "fqNE1wPMFykR"
      },
      "source": [
        "2. Divida o conjunto de dados em 80% para validação e 20% para teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ts-4LJ1iFy6l",
      "metadata": {
        "id": "Ts-4LJ1iFy6l"
      },
      "outputs": [],
      "source": [
        "# Digite o código do item aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SH8O4_gIoazu",
      "metadata": {
        "id": "SH8O4_gIoazu"
      },
      "source": [
        "3. Padronize os conjuntos de treinamento e teste.\n",
        "\n",
        "**DICAS**\n",
        "+ Use a classe `StandardScaler`.\n",
        "+ Não se esqueça que os parâmetros de padronização devem ser calculados com o conjunto de treinamento e aplicados aos conjuntos de treinamento e teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A64-c_21obGT",
      "metadata": {
        "id": "A64-c_21obGT"
      },
      "outputs": [],
      "source": [
        "# Digite o código do item aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CF_HvghZGWWJ",
      "metadata": {
        "id": "CF_HvghZGWWJ"
      },
      "source": [
        "4. Treine um regressor linear com o conjunto de treinamento e calcule o erro quadrático médio com o conjunto de teste. Imprima o valor do erro.\n",
        "\n",
        "**DICAS**\n",
        "+ Use a classe `LinearRegression`.\n",
        "+ Você pode usar a função `mean_squared_error` para calcular o erro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eO2jOFA5GWjt",
      "metadata": {
        "id": "eO2jOFA5GWjt"
      },
      "outputs": [],
      "source": [
        "# Digite o código do item aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mpWCXpwfTRLR",
      "metadata": {
        "id": "mpWCXpwfTRLR"
      },
      "source": [
        "5. Neste item, verificaremos se um regressor polinomial consegue apresentar um desempenho melhor, ou seja, apresentar um erro menor.\n",
        "\n",
        "Portanto, usando a estratégia de validação cruzada **k-Fold**, encontre a ordem ideal para que uma função hipótese polinomial aproxime bem o conjunto de dados. Para avaliar qual é a ordem ideal para o polinômio aproximador, plote gráficos com a média e o desvio padrão do erro quadrático médio (EQM) em função dos graus de polinômio considerados. Para isso:\n",
        "\n",
        "   1. Use o **k-Fold** com **k** igual a 5.\n",
        "   2. Configure o parâmetro `shuffle` da classe `KFold` como `True`, ou seja, `shuffle=True`.\n",
        "   3. Faça a análise de polinômios de ordem 1 até 7, **inclusive**.\n",
        "   4. Desabilite a inclusão da coluna do atributo de bias ao instanciar a classe `PolynomialFeatures` utilizando o parâmetro `include_bias=False`.\n",
        "   5. Use a classe `StandardScaler` para padronizar os atributos.\n",
        "   6. Use todo o conjunto de dados, ou seja, `X` e `y`, para realizar a validação cruzada.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Crie um pipeline de ações com objetos das classes `PolynomialFeatures`, `StandardScaler` e `LinearRegression`.\n",
        "+ O tempo de execução desse exercício é de aproximadamente 10 minutos, mas pode variar de computador para computador, portanto, pegue um café e tenha paciência.\n",
        "+ Para resolver este item, se baseie no seguinte exemplo: [validacao_cruzada.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/main/notebooks/regression/validacao_cruzada.ipynb).\n",
        "+ **Atenção, não basta apenas copiar o código do exemplo dado, você precisa alterá-lo.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TnoreVKeTNIa",
      "metadata": {
        "id": "TnoreVKeTNIa"
      },
      "outputs": [],
      "source": [
        "# Digite o código do item aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32VwqN97rd2c",
      "metadata": {
        "id": "32VwqN97rd2c"
      },
      "source": [
        "6. Após analisar os resultados obtidos com a validação cruzada **k-Fold**, responda qual é a melhor ordem de polinômio para aproximar os dados. **Justifique sua resposta.**\n",
        "\n",
        "**DICA**\n",
        "\n",
        "* Lembre-se do princípio da navalha de Occam para escolher a melhor ordem."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mKuZDNRgrh76",
      "metadata": {
        "id": "mKuZDNRgrh76"
      },
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YMhP-KF6VBoU",
      "metadata": {
        "id": "YMhP-KF6VBoU"
      },
      "source": [
        "7. De posse da melhor ordem, treine um novo modelo considerando esta ordem e ao final imprima o valor do erro quadrático médio para o conjunto de teste.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Treine com o conjunto de treinamento e cacule o erro com o conjunto de teste.\n",
        "+ Desabilite a inclusão da coluna do atributo de bias ao instanciar a classe `PolynomialFeatures` utilizando o parâmetro `include_bias=False`.\n",
        "+ Use a classe `StandardScaler` para normalizar os dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xjQj1uBkVB5v",
      "metadata": {
        "id": "xjQj1uBkVB5v"
      },
      "outputs": [],
      "source": [
        "# Digite o código do item aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lsyUe4Bns7dp",
      "metadata": {
        "id": "lsyUe4Bns7dp"
      },
      "source": [
        "8. O erro obtido no item anterior é menor do que o erro obtido no item 4 deste exercício? **Justifique sua resposta**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D92Q5H_ftaEw",
      "metadata": {
        "id": "D92Q5H_ftaEw"
      },
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F77Zzd3TYiD9",
      "metadata": {
        "id": "F77Zzd3TYiD9"
      },
      "source": [
        "9. Neste item, iremos remover valores discrepantes dos atributos. Valores discrepantes podem distorcer modelos de regressão (e.g., aumentar o erro quadrático médio), especialmente em datasets pequenos.\n",
        "\n",
        "Para identificar e remover tais valores, usaremos o Intervalo Interquartil (IQR). O IQR é uma medida estatística robusta para identificar valores discrepantes. Valores fora do intervalo $[Q1 - 1.5*IQR, Q3 + 1.5*IQR]$ são considerados discrepantes. A remoção de valores discrepantes melhora a generalização do modelo e reduz o impacto de valores extremos em algoritmos sensíveis (e.g., regressão).\n",
        "\n",
        "Execute a célula de código abaixo para remover os valores discrepantes.\n",
        "\n",
        "**DICAS**\n",
        "+ Além de remover os valores discrepantes, o código abaixo cria uma nova base de daos, sem tais valores, e a divide em novos conjuntos de treinamento e validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74hT7Y3YgntZ",
      "metadata": {
        "id": "74hT7Y3YgntZ"
      },
      "outputs": [],
      "source": [
        "# Selecionar features numéricas\n",
        "numeric_features = ['MYCT', 'MMIN', 'MMAX', 'CACH', 'CHMIN', 'CHMAX']\n",
        "\n",
        "df = df.drop([\"vendor\", \"model\", \"PRP\"], axis=1)\n",
        "\n",
        "# Calcular IQR para cada feature\n",
        "Q1 = df[numeric_features].quantile(0.25)\n",
        "Q3 = df[numeric_features].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Definir limites\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Filtrar dados\n",
        "df_clean = df[\n",
        "    ~((df[numeric_features] < lower_bound) | (df[numeric_features] > upper_bound)).any(axis=1)\n",
        "]\n",
        "\n",
        "# Criando um novo dataset, mas desta vez sem amostras discrepantes.\n",
        "X = df_clean.drop([\"ERP\"], axis=1)\n",
        "y = df_clean.ERP\n",
        "\n",
        "# Divide o novo conjunto em conjuntos de treinamento e validação.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state=42)\n",
        "\n",
        "# Criar figura com 2 subplots lado a lado\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Plotar boxplot antes da remoção (subplot esquerdo)\n",
        "sns.boxplot(data=df[numeric_features], ax=axes[0])\n",
        "axes[0].set_title(\"Antes da Remoção de Outliers\")\n",
        "axes[0].tick_params(axis='x', rotation=45)  # Rotacionar labels se necessário\n",
        "\n",
        "# Plotar boxplot após remoção (subplot direito)\n",
        "sns.boxplot(data=df_clean[numeric_features], ax=axes[1])\n",
        "axes[1].set_title(\"Após Remoção de Outliers (IQR)\")\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Ajustar layout e mostrar\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50njUoLgehb5",
      "metadata": {
        "id": "50njUoLgehb5"
      },
      "source": [
        "10. De posse dos novos conjuntos de treinamento e teste sem valores discrepantes e da melhor ordem encontrada no item 5 deste exercício, treine um novo modelo considerando os novos conjuntos e esta ordem e ao final imprima o valor do erro quadrático médio para o conjunto de teste.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Treine com o conjunto de treinamento e cacule o erro com o conjunto de teste.\n",
        "+ Desabilite a inclusão da coluna do atributo de bias ao instanciar a classe `PolynomialFeatures` utilizando o parâmetro `include_bias=False`.\n",
        "+ Use a classe `StandardScaler` para normalizar os dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jpZxr4wdegv7",
      "metadata": {
        "id": "jpZxr4wdegv7"
      },
      "outputs": [],
      "source": [
        "# Digite o código do item aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HzukUqOR0sB4",
      "metadata": {
        "id": "HzukUqOR0sB4"
      },
      "source": [
        "11. O erro obtido no item anterior é menor do que o erro obtido no item 7 deste exercício? **Justifique sua resposta**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m-Ay2oFq0-t5",
      "metadata": {
        "id": "m-Ay2oFq0-t5"
      },
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0507c7f4",
      "metadata": {
        "id": "0507c7f4"
      },
      "source": [
        "### 3) Usando regressão para estimar calorias queimadas.\n",
        "\n",
        "Neste exercício, você utilizará uma técnica de **validação cruzada** para encontrar um modelo que estime a quantidade de calorias queimadas após uma atividade física com base em um conjunto de dados coletados. As informações das **colunas** contidas no conjunto de dados seguem abaixo. O objetivo é utilizar os atributos para estimar a quantidade de calorias queimadas.\n",
        "\n",
        "|            |                   **Atributos**                   |\n",
        "|:----------:|:-------------------------------------------------:|\n",
        "|   User_ID  |              Identificação do usuário             |\n",
        "|   Gender   |                       Gênero                      |\n",
        "|     Age    |                       Idade                       |\n",
        "|   Height   |                       Altura                      |\n",
        "|   Weight   |                        Peso                       |\n",
        "|  Duration  |            Duração da atividade física            |\n",
        "| Heart_Rate | Média de batimentos cardíacos durante a atividade física |\n",
        "|  Body_Temp | Média da temperatura coporal durante a atividade física |\n",
        "|            |                     **Rótulo**                    |\n",
        "|  Calories  |       Calorias queimadas durante a atividade física       |\n",
        "\n",
        "1. Execute a célula de código abaixo para importar o conjunto de dados e as bibliotecas necessárias.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Após a execução bem sucedida da célula abaixo, você visualizará as 5 primeiras linhas do arquivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01a5b419",
      "metadata": {
        "id": "01a5b419"
      },
      "outputs": [],
      "source": [
        "# Importe todas as bibliotecas necessárias.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import urllib\n",
        "\n",
        "# Reseta o gerador de sequências pseudo aleatórias.\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Baixa as bases de dados do dropbox.\n",
        "urllib.request.urlretrieve('https://www.dropbox.com/s/1zka46bw4f4z5xq/exercise.csv?dl=1', 'exercise.csv')\n",
        "urllib.request.urlretrieve('https://www.dropbox.com/s/45gtml94o97bhz8/calories.csv?dl=1', 'calories.csv')\n",
        "\n",
        "# Importa os arquivos CSV.\n",
        "exercise_data = pd.read_csv('./exercise.csv')\n",
        "calories_data = pd.read_csv('./calories.csv')\n",
        "\n",
        "# Une as duas bases de dados.\n",
        "df = exercise_data.join( calories_data.set_index('User_ID'), on='User_ID', how='left')\n",
        "\n",
        "# Mostra uma tabela com as 5 primeiras linhas.\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466f48d3",
      "metadata": {
        "id": "466f48d3"
      },
      "source": [
        "2. Execute a célula de código abaixo para aplicar um pré-processamento aos dados do conjunto.\n",
        "\n",
        "+ Como os modelos de regressão esperam valores numéricos, devemos alterar os valores textuais da coluna `Gender` em valores numéricos. A string `male` é alterada para o valor 0 e a string `female` é alterada para o valor 1.\n",
        "+ Na sequência, a coluna `User_ID` é removida, pois ela não é um atributo e, portanto, não traz informação útil para a regressão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3742ff0",
      "metadata": {
        "id": "f3742ff0"
      },
      "outputs": [],
      "source": [
        "# Mapeia as strings em valores numéricos.\n",
        "df.replace({'Gender':{'male':0, 'female':1}}, inplace=True)\n",
        "\n",
        "# Remove a coluna 'User_ID'.\n",
        "del df[ 'User_ID' ]\n",
        "\n",
        "# Mostra uma tabela com as 5 primeiras linhas.\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43b9e80d",
      "metadata": {
        "id": "43b9e80d"
      },
      "source": [
        "3. Execute a próxima célula de código abaixo para criar a matriz de atributos, $\\textbf{X}$, e o vetor de rótulos, $\\textbf{y}$.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ A primeira linha de comando remove da matriz de atributos a coluna `Calories`, pois ela será nosso rótulo.\n",
        "+ A segunda linha cria o vetor de rótulos contendo apenas a coluna `Calories`.\n",
        "+ A célula imprimirá as dimensões da matriz de atributos e do vetor de rótulos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0be3cd93",
      "metadata": {
        "id": "0be3cd93"
      },
      "outputs": [],
      "source": [
        "# Criando a matriz de atributos e o vetor de rótulos.\n",
        "X = df.drop('Calories', axis=1)\n",
        "y = df['Calories']\n",
        "\n",
        "# Atributos.\n",
        "print('Dimensão da matriz de atributos:', X.shape)\n",
        "# Rótulos.\n",
        "print('Dimensão do vetor de rótulos:',y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d76c781",
      "metadata": {
        "id": "4d76c781"
      },
      "source": [
        "4. Com a matriz de atributos, $\\textbf{X}$, e o vetor de rótulos, $\\textbf{y}$, obtidos no item anterior, utilize a técnica de validação cruzada k-Fold para escolher a melhor ordem para um modelo de regressão polinomial.\n",
        "\n",
        "Para isso, faça o seguinte:\n",
        "\n",
        "1. Use o **k-Fold** instanciado com os seguintes parâmetros `n_splits=10`, `shuffle=True` e `random_state=seed`.\n",
        "2. Faça a análise de **polinômios** de ordem 1 até 7, **inclusive**.\n",
        "3. Para realizar a validação cruzada com o **k-Fold**, use a função `cross_val_score` com o seguinte parâmetro `scoring='neg_mean_squared_error'`.\n",
        "4. Use a classe `StandardScaler` para padronizar os dados.\n",
        "5. Use a classe `LinearRegression` para realizar a regressão propriamente dita.\n",
        "6. Plote gráficos com a média e o desvio padrão do erro quadrático médio em função do grau do polinômio.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ O tempo de execução desse exercício é de aproximadamente 10 minutos, mas pode variar de computador para computador, portanto, pegue um café e tenha paciência.\n",
        "+ Use o princípio da navalha de Occam para escolher a ordem do polinômio.\n",
        "+ Para resolver este item, se baseie no seguinte exemplo: [validacao_cruzada.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/main/notebooks/regression/validacao_cruzada.ipynb).\n",
        "+ **Atenção, não basta apenas copiar o código do exemplo dado, você precisa alterá-lo.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5732e88",
      "metadata": {
        "id": "f5732e88"
      },
      "outputs": [],
      "source": [
        "# Digite o código do item aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e773128",
      "metadata": {
        "id": "3e773128"
      },
      "source": [
        "5. Após analisar os resultados do item anterior responda: Qual a melhor ordem do polinômio para esse problema? **Justifique sua resposta**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68b95c96",
      "metadata": {
        "id": "68b95c96"
      },
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faea1528",
      "metadata": {
        "id": "faea1528"
      },
      "source": [
        "6. De posse da melhor ordem, treine um novo modelo considerando esta ordem e no final imprima o valor do erro quadrático médio (MSE) para os conjuntos de treinamento e de validação.\n",
        "\n",
        "Para isso, faça o seguinte\n",
        "\n",
        "1. Separe 75% do conjunto de dados para o treinamento e 25% para o conjunto de validação com o parâmetro `random_state=seed`.\n",
        "2. Crie um pipeline com as seguintes ações:\n",
        "    + `PolynomialFeatures` com a ordem escolhida.\n",
        "    + `StandardScaler` para padronizar os dados.\n",
        "    + `LinearRegression` para encontrar os pesos da função hipótese polinomal.\n",
        "3. Treine o modelo com o conjunto de treinamento.\n",
        "4. Faça predições com o modelo treinando usando os conjuntos de treinamento e validação.\n",
        "5. Calcule e imprima o MSE entre as predições feitas pelo modelo e os rótulos dos conjuntos de treinamento e validação.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Para resolver este item, se baseie no seguinte exemplo: [validacao_cruzada.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/main/notebooks/regression/validacao_cruzada.ipynb).\n",
        "+ **Atenção, não basta apenas copiar o código do exemplo dado, você precisa alterá-lo.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2834e572",
      "metadata": {
        "id": "2834e572"
      },
      "outputs": [],
      "source": [
        "# Digite o código do item aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1273f180",
      "metadata": {
        "id": "1273f180"
      },
      "source": [
        "7. Comparando os dois erros obtidos no item anterior, erros de treinamento e validação. Você diria que o modelo está subajustando, sobreajustando ou encontrou uma relação de compromisso entre generalização e flexibilidade (ou capacidade)? **Justifique sua resposta**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "388fe820",
      "metadata": {
        "id": "388fe820"
      },
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c21c4a3",
      "metadata": {
        "id": "8c21c4a3"
      },
      "source": [
        "8. Treine um novo modelo considerando uma ordem igual a 10 e no final imprima o valor do erro quadrático médio (MSE) para os conjuntos de treinamento e de validação.\n",
        "\n",
        "Para isso, faça o seguinte\n",
        "\n",
        "1. Separe 75% do conjunto de dados para o treinamento e 25% para o conjunto de validação com o parâmetro `random_state=seed`.\n",
        "2. Crie um pipeline com as seguintes ações:\n",
        "    + `PolynomialFeatures` com a ordem escolhida.\n",
        "    + `StandardScaler` para padronizar os dados.\n",
        "    + `LinearRegression` para encontrar os pesos da função hipótese polinomal.\n",
        "3. Treine o modelo com o conjunto de treinamento.\n",
        "4. Faça predições com o modelo treinando usando os conjuntos de treinamento e de validação.\n",
        "5. Calcule e imprima o MSE entre as predições feitas pelo modelo e os rótulos dos conjuntos de treinamento e validação.\n",
        "\n",
        "**DICAS**\n",
        "\n",
        "+ Para resolver este item, se baseie no seguinte exemplo: [validacao_cruzada.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/main/notebooks/regression/validacao_cruzada.ipynb).\n",
        "+ **Atenção, não basta apenas copiar o código do exemplo dado, você precisa alterá-lo.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a83d1ce2",
      "metadata": {
        "id": "a83d1ce2"
      },
      "outputs": [],
      "source": [
        "# Digite o código do item aqui."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b780354",
      "metadata": {
        "id": "9b780354"
      },
      "source": [
        "9. Comparando os dois erros obtidos no item anterior, erros de treinamento e de validação. Você diria que o modelo está subajustando, sobreajustando ou encontrou uma relação de compromisso entre capacidade de generalização e flexibilidade (ou capacidade)? **Justifique sua resposta**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e99f2ca0",
      "metadata": {
        "id": "e99f2ca0"
      },
      "source": [
        "**Resposta**\n",
        "\n",
        "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}