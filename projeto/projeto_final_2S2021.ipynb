{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bpa_1m9niFLr"
   },
   "source": [
    "# Projeto Final (2S2021)\n",
    "\n",
    "### Instruções\n",
    "\n",
    "1. Quando você terminar os exercícios do projeto, vá até o menu do Jupyter ou Colab e selecione a opção para fazer download do notebook.\n",
    "    * Os notebooks tem extensão .ipynb. \n",
    "    * Este deve ser o arquivo que você irá entregar.\n",
    "    * No Jupyter vá até a opção **File** -> **Download as** -> **Notebook (.ipynb)**.\n",
    "    * No Colab vá até a opção **File** -> **Download .ipynb**.\n",
    "2. Após o download do notebook, vá até a aba de tarefas do MS Teams, localize a tarefa referente a este projeto e faça o upload do seu notebook. Veja que há uma opção de anexar arquivos à tarefa.\n",
    "3. Atente-se ao prazo de entrega definido na tarefa do MS Teams. Entregas fora do prazo não serão aceitas.\n",
    "4. **O projeto pode ser resolvido em grupos de no MÁXIMO 3 alunos**.\n",
    "5. Todas as questões têm o mesmo peso.\n",
    "6. Não se esqueça de colocar seu(s) nome(s) e número(s) de matrícula no campo abaixo. Substitua os nomes que já estão no campo abaixo.\n",
    "7. Você pode consultar todo o material de aula.\n",
    "8. A interpretação faz parte do projeto. Leia o enunciado de cada questão atentamente!\n",
    "9. Boa sorte!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVmRGH60iFLw"
   },
   "source": [
    "**Nomes e matrículas**:\n",
    "\n",
    "1. Nome do primeiro aluno - Matrícula do primeiro aluno\n",
    "2. Nome do segundo aluno - Matrícula do segundo aluno\n",
    "3. Nome do terceiro aluno - Matrícula do terceiro aluno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cs_1NM9tiFLw"
   },
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUbtdl48iFLx"
   },
   "source": [
    "### 1) Regressão polinomial para previsão de temperatura.\n",
    "\n",
    "Neste exercício, você utilizará técnicas de **validação cruzada** para encontrar um modelo para prever a temperatura de uma cidade na Hungria com base em dados coletados sobre o clima do ano de 2006 a 2016. As informações das **colunas** contidas no conjunto de dados seguem abaixo.\n",
    "\n",
    "|   |      Colunas     |\n",
    "|:-:|:----------------:|\n",
    "| 1 |  Formatted Date  |\n",
    "| 2 |    Summary       |\n",
    "| 3 |   Precip Type    |\n",
    "| 4 |  Temperature (C)  |\n",
    "| 5 |Apparent Temperature (C)|\n",
    "| 6 |     Humidity     |\n",
    "| 7 | Wind Speed (km/h)|\n",
    "| 8 |Wind Bearing (degress)|\n",
    "| 9 |  Visibility (km) |\n",
    "| 10 |   Loud Cover    |\n",
    "| 11 |Pressure (millibars)|\n",
    "| 12 |  Daily Summary  |\n",
    "\n",
    "\n",
    "Fonte dos dados: [Referência dados do Clima de Szeged](https://www.kaggle.com/budincsevity/szeged-weather?select=weatherHistory.csv)\n",
    "\n",
    "**A) Execute a célula abaixo para importar os dados e as bibliotecas necessárias**.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Após a execução bem sucedida da célula abaixo, você visualizará as 5 primeiras linhas do arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "tTnDkNYFiFLx",
    "outputId": "2ac1acdc-657c-4ec2-d6b7-bd24900dc67b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Formatted Date</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Precip Type</th>\n",
       "      <th>Temperature (C)</th>\n",
       "      <th>Apparent Temperature (C)</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed (km/h)</th>\n",
       "      <th>Wind Bearing (degrees)</th>\n",
       "      <th>Visibility (km)</th>\n",
       "      <th>Loud Cover</th>\n",
       "      <th>Pressure (millibars)</th>\n",
       "      <th>Daily Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-04-01 00:00:00.000 +0200</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>9.472222</td>\n",
       "      <td>7.388889</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.1197</td>\n",
       "      <td>251.0</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1015.13</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-04-01 01:00:00.000 +0200</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>9.355556</td>\n",
       "      <td>7.227778</td>\n",
       "      <td>0.86</td>\n",
       "      <td>14.2646</td>\n",
       "      <td>259.0</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1015.63</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-01 02:00:00.000 +0200</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>9.377778</td>\n",
       "      <td>9.377778</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.9284</td>\n",
       "      <td>204.0</td>\n",
       "      <td>14.9569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1015.94</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-01 03:00:00.000 +0200</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>8.288889</td>\n",
       "      <td>5.944444</td>\n",
       "      <td>0.83</td>\n",
       "      <td>14.1036</td>\n",
       "      <td>269.0</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.41</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-01 04:00:00.000 +0200</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>8.755556</td>\n",
       "      <td>6.977778</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.0446</td>\n",
       "      <td>259.0</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.51</td>\n",
       "      <td>Partly cloudy throughout the day.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Formatted Date        Summary Precip Type  Temperature (C)  \\\n",
       "0  2006-04-01 00:00:00.000 +0200  Partly Cloudy        rain         9.472222   \n",
       "1  2006-04-01 01:00:00.000 +0200  Partly Cloudy        rain         9.355556   \n",
       "2  2006-04-01 02:00:00.000 +0200  Mostly Cloudy        rain         9.377778   \n",
       "3  2006-04-01 03:00:00.000 +0200  Partly Cloudy        rain         8.288889   \n",
       "4  2006-04-01 04:00:00.000 +0200  Mostly Cloudy        rain         8.755556   \n",
       "\n",
       "   Apparent Temperature (C)  Humidity  Wind Speed (km/h)  \\\n",
       "0                  7.388889      0.89            14.1197   \n",
       "1                  7.227778      0.86            14.2646   \n",
       "2                  9.377778      0.89             3.9284   \n",
       "3                  5.944444      0.83            14.1036   \n",
       "4                  6.977778      0.83            11.0446   \n",
       "\n",
       "   Wind Bearing (degrees)  Visibility (km)  Loud Cover  Pressure (millibars)  \\\n",
       "0                   251.0          15.8263         0.0               1015.13   \n",
       "1                   259.0          15.8263         0.0               1015.63   \n",
       "2                   204.0          14.9569         0.0               1015.94   \n",
       "3                   269.0          15.8263         0.0               1016.41   \n",
       "4                   259.0          15.8263         0.0               1016.51   \n",
       "\n",
       "                       Daily Summary  \n",
       "0  Partly cloudy throughout the day.  \n",
       "1  Partly cloudy throughout the day.  \n",
       "2  Partly cloudy throughout the day.  \n",
       "3  Partly cloudy throughout the day.  \n",
       "4  Partly cloudy throughout the day.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "\n",
    "# Importa os dados.\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/zz4fap/t319_aprendizado_de_maquina/main/projeto/data_weather.csv')\n",
    "\n",
    "# Mostra uma tabela com os 5 primeiros exemplos.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lM1iAlgiFLz"
   },
   "source": [
    "**B) A célula abaixo separa o rótulo dos atributos numéricos. Execute-a para fazer essa separação.**\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ A primeira linha de comando remove do conjunto atributos desnecessários à regressão.\n",
    "+ A célula imprimirá as dimensões da matriz de atributos e do vetor de rótulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jKBnuJlniFLz",
    "outputId": "7e872e76-41f7-4eef-88e6-7290f410a992"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão da matriz de atributos: (43001, 7)\n",
      "Dimensão da matriz de rótulos: (43001,)\n"
     ]
    }
   ],
   "source": [
    "# Features/atributos\n",
    "X = df.drop(['Formatted Date', 'Summary', 'Precip Type', 'Daily Summary', 'Temperature (C)'], axis=1)\n",
    "print('Dimensão da matriz de atributos:', X.shape)\n",
    "\n",
    "# Label/rótulo\n",
    "y = df['Temperature (C)'].copy()\n",
    "print('Dimensão da matriz de rótulos:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-9cNMi3niFL0"
   },
   "source": [
    "**C) Com a matriz de atributos X e o vetor de rótulos y obtidos no item anterior, utilize a técnica de validação cruzada k-Fold para escolher a melhor ordem para o modelo. Para isso:**\n",
    "\n",
    " 1. Use o **k-Fold** com **k** igual a 10 e o parâmetro `random_state=0`.\n",
    " 2. Faça a análise de polinômios de ordem 1 até 6, **inclusive**.\n",
    " 3. Inclua o atributo de bias ao instanciar a classe `PolynomialFeatures` utilizando o parâmetro `include_bias=True`.\n",
    " 4. Use a classe `StandardScaler` para normalizar os dados.\n",
    " 5. Plote gráficos com a média e o desvio padrão do erro quadrático médio em função do grau do polinômio.\n",
    "\n",
    "**DICAS** \n",
    "\n",
    "+ O tempo de execução desse exercício é de aproximadamente 10 minutos, mas pode variar de computador para computador, portanto, pegue um café e tenha paciência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "kqBFq4rpiFL1",
    "outputId": "3a88fec7-082a-43f5-c18a-bba70e6500e6"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFkYLPCDiFL2"
   },
   "source": [
    "**D) Após analisar os resultados do item anterior responda: Qual a melhor ordem do polinômio para esse problema? Justifique sua resposta.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwIMYS2biFL2"
   },
   "source": [
    "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLrQ48EXiFL2"
   },
   "source": [
    "**E) De posse da melhor ordem, treine um novo modelo considerando esta ordem e no final imprima o valor do erro quadrático médio para os conjuntos de treinamento e de teste.**\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Separe 80% do conjunto de dados para o treinamento e 20% para o conjunto de validação com o parâmetro `random_state=0`.\n",
    "+ Inclua o bias ao instanciar a classe `PolynomialFeatures` utilizando o parâmetro `include_bias=True`.\n",
    "+ Use a classe `StandardScaler` para normalizar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8I7Gxo9iFL3",
    "outputId": "7439de52-f733-481a-c52d-1a98b0c89c19"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-LHGda0iFL3"
   },
   "source": [
    "### 2) Prevendo a qualidade de vinhos.\n",
    "\n",
    "Neste exercício, você encontrará um modelo de regressão linear simples que, a partir das características fornecidas, determina a qualidade de um vinho dando uma nota de 0 a 10.\n",
    "\n",
    "O conjunto de dados é constituído por 1599 exemplos contendo 11 variáveis de entrada (*atributos*) e 1 variável de saída (*rótulos*). Todas essas variáveis estão descritas pela tabela abaixo.\n",
    "\n",
    "\n",
    "|   | Input variables (based on physicochemical tests) |\n",
    "|:-:|:------------------------------------------------:|\n",
    "| 1 |                  fixed acidity                   |\n",
    "| 2 |                volatile acidity                  |\n",
    "| 3 |                   citric acid                    |\n",
    "| 4 |                 residual sugar                   |\n",
    "| 5 |                    chlorides                     |\n",
    "| 6 |                free sulfur dioxide               |\n",
    "| 7 |                total sulfur dioxide              |\n",
    "| 8 |                     density                      |\n",
    "| 9 |                       pH                         |\n",
    "| 10 |                    sulphates                    |\n",
    "| 11 |                     alcohol                     |\n",
    "|    |    **Output variable (based on sensory data)**  |\n",
    "| 12 |          quality (score between 0 and 10)       |\n",
    "\n",
    "Fonte dos dados: [Referência dos dados sobre vinho](https://archive.ics.uci.edu/ml/datasets/wine+quality)\n",
    "\n",
    "\n",
    "**A) Execute a célula abaixo para importar os dados e as bibliotecas necessárias**.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Após a execução bem sucedida da célula abaixo, você visualizará as 5 primeiras linhas do arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "HPr_UdChiFL3",
    "outputId": "f73d4777-7d2e-4e70-8407-99e616dd0529"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importa os dados\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/zz4fap/t319_aprendizado_de_maquina/main/projeto/winequality-red.csv', sep=';')\n",
    "\n",
    "# Mostra uma tabela com os 5 primeiros exemplos \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__oSg-70iFL4"
   },
   "source": [
    "**B) Com os dados importados, execute a próxima célula para separar os atributos e os rótulos**.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ A primeira linha de comando remove do conjunto atributos desnecessários à regressão.\n",
    "+ A célula imprimirá as dimensões da matriz de atributos e do vetor de rótulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPIGm4mriFL4",
    "outputId": "5c599d0b-c013-480b-98a9-95f8482c78bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão da matriz de atributos: (1599, 11)\n",
      "Dimensão da matriz de rótulos: (1599,)\n"
     ]
    }
   ],
   "source": [
    "# Features/Atributos\n",
    "X = df.drop('quality', axis=1)\n",
    "print('Dimensão da matriz de atributos:', X.shape)\n",
    "\n",
    "# Label/Rótulo\n",
    "y = df['quality'].copy()\n",
    "print('Dimensão da matriz de rótulos:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRf5md57iFL4"
   },
   "source": [
    "**C) Separe 80% do conjunto de dados para o treinamento e 20% para a validação**.\n",
    "\n",
    "**DICAS**:\n",
    "\n",
    "+ Use a função `train_test_split` da biblioteca SciKit-Learn.\n",
    "+ Configure o parâmetro `random_state` da função `train_test_split` com o valor 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "n9C5Jq5piFL4"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWY8dpQiiFL5"
   },
   "source": [
    "**D) Normalize os dados utilizando a classe MinMaxScaler da biblioteca SciKit Learn**.\n",
    "\n",
    "**DICAS** \n",
    "\n",
    "+ O uso da classe `MinMaxScaler` é feito do mesmo modo que da classe `StandardScaler` utilizada nos laboratórios. \n",
    "+ Para saber mais sobre essa classe acesse sua documentação: [Documentação MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html).\n",
    "+ Lembre-se que os parâmetros para a normalização Min-Max são encontrados com o conjunto de treinamento e utilizados para normalizar ambos os conjuntos, ou seja, de treinamento e de validação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "asrYwY1_iFL6"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfC1BRyciFL6"
   },
   "source": [
    "**E) Utilizando a biblioteca SciKit-Learn, instancie um objeto da classe `LinearRegression`, faça o treinamento do modelo, faça a predição com os conjuntos de treinamento e de validação e imprima o erro quadrático médio para ambos os conjuntos**.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Perceba que você irá realizar neste item uma regressão simples, ou seja, sem o uso de um polinômio.\n",
    "+ Para calcular o erro quadrático médio de ambos os conjuntos, use a função `mean_squared_error` da biblioteca SciKit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEPgu-LBiFL6",
    "outputId": "5ff3a62f-30bf-486d-b257-10c56f408300"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fi2wIcjiFL7"
   },
   "source": [
    "**F) E se utilizássemos regressão polinomial? Utilize a técnica de validação cruzada do holdout para verificar polinômios de ordem 1 a 5, inclusive. Plote o gráfico dos erros de treinamento e validação em função da ordem do polinômio**.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Divida o conjunto de treinamento e validação na mesma proporção do item C deste exercício.\n",
    "+ Configure o parâmetro `random_state` da função `train_test_split` com o valor 0.\n",
    "+ Use um objeto da classe `MinMaxScaler` para fazer a normalização dos dados.\n",
    "+ Juntamente com objetos das classes `PolynomialFeatures` e `LinearRegression`, crie um pipeline de ações para o modelo.\n",
    "+ Ao plotar o gráfico de erro versus o grau do polinômio, use no eixo y a escala logarítmica. Para isto, use a seguinte linha de código:\n",
    "```python\n",
    "plt.yscale('log')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "-Hwq5xfTiFL7",
    "outputId": "192b90b9-0647-4cf4-a6e3-64874f364a11"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yrjUVA9iFL8"
   },
   "source": [
    "**G) Com base no gráfico apresentado no item anterior com o erro versus o grau do polinômio e seguindo o princípio da Navalha de Occam, qual seria a melhor ordem? Justifique sua resposta.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnRB4MxjiFL8"
   },
   "source": [
    "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3onJT4ariFL8"
   },
   "source": [
    "### 3) Comparando o desempenho de modelos de regressão.\n",
    "\n",
    "Nesse exercício, você fará o treinamento de dois modelos e ao final, comparará seus desempenhos.\n",
    "\n",
    "**A) Execute a célula abaixo para importar os dados e as bibliotecas necessárias**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "Vz4s9xUTiFL8",
    "outputId": "f8dbbc08-477b-4c70-e10b-0b3523a382e7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEbCAYAAADeeCN4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABAFElEQVR4nO3dd3hUVd7A8e9JIwECgQQChJLQCRCqghBCKCKvYkFsryiyFtZ1sa51ddeGuuKuoq+7i23Fjg1RdEVUEgLSDAIBQpXQkRpCEggkmfP+cSfJzDCTzEym5/d5njyTmblz55yZufd3T1daa4QQQogqYf5OgBBCiMAigUEIIYQVCQxCCCGsSGAQQghhRQKDEEIIKxIYhBBCWJHAIIQPKKUGK6W0UirZ32kRoi4SGIQwU0rNMZ+8tVKqXCl1WCmVpZT6o1Iq0t/pE8JXJDAIYe0HoC2QDIwDFgBPAkuVUk38mC4hfEYCgxDWzmitf9Na79dar9NavwhkAgOBBwGUUjcopX5WShWbSxWfKqWSLHeilBqvlNqilCpTSi0Futu+kVLqSqXUBqXUGaXUXqXUo0opZfN8nlLqtFLquFJqiVIq0au5FwIJDELUSWu9EVgITDI/FAU8DvQDJgAJwEdV2yulOgDzge+B/sD/ATMt96mUGgR8CswD+gIPA48A083PtwHmAu8AvYAM4D3P506Ic0X4OwFCBIl8YCyA1vo/Fo/vVEr9AdislGqvtd4H/AHYA9yljcnItiilugNPW7zuPmCJ1vpx8/1tSqluwEMYgaQdEAl8prXebd5mo5fyJoQVKTEI4RwFaACl1ECl1JdKqd1KqWIg17xNR/NtL2Cltp6hcoXN/noBP9k8tgxIUko1A9ZjtHdsVEp9rpT6g1KqlQfzI4RDEhiEcE4qRumgCfAdcAq4ETgPGG/eJsp8q859+TmqA40dWmtdidH4PQ7IA24Btiul+rmXfCGcJ4FBiDoopfpgnPw/A3pitCn8WWudo7XeArS2eUk+MMSyIRkYamebdJvH0oF9WutiMKKD1nqF1vpJjAB0ALjWE3kSojbSxiCEtUbmht8woBUwBvgzsAb4O9AYOANMV0r9E6NK6GmbfcwG/gTMUkr9C6Nx+Xabbf4B/KyUegL4EOPE/yfze6GUGorRpvEdcAgYAHTACChCeJWUGISwNhY4iNF4/CNwGcY4hgytdanW+ghwE3AFxkn6cYyG5Gpa6z3AlRiljPXAvRi9jiy3+QW4GqOn00bgb+a/V82bFAHDga+B7RiB5Gmt9fseza0QdihZwU0IIYQlKTEIIYSwIoFBCCGEFQkMQgghrEhgEEIIYSXou6smJCTo5ORkl19XWlpKkyYNb7JMyXfDIvluWFzJ95o1a45qre2Opg/6wJCcnExubm7dG9rIzs4mMzPT8wkKcJLvhkXy3bC4km+l1G5Hz0lVkhBCCCsSGIQQQliRwCCEEMKKT9sYlFK7gGKgEqjQWg92sN15wErgWq31Z66+T3l5Ofv27aOsrMzhNs2bN2fz5s2u7jroBXq+o6Ojad++PZGRssSyEP7ij8bnUVrro46eVEqFA89jTB7mln379hEbG0tycjLWE1zWKC4uJjY21t23CFqBnG+tNceOHWPfvn2kpKT4OzlCNFiBWJV0J/A5cNjdHZSVlREfH+8wKIjApJQiPj6+1pKeEA3esllQkGP9WEGO8biH+LrEoIFFSikNvKa1ft3ySfOC6hOB0RjTENullJoGTANITEwkOzvb6vnmzZtTUlJSa0IqKyspLi52IwvBLRjyXVZWds53Wl8lJSUe32cwkHyHnrjCMFKXTCY/9QFOtEgjrjCP1PwXyE99gJJID+Vba+2zP6Cd+bY1xnTEGTbPfwoMNf8/B7iqrn0OGjRI28rPzz/nMVsnT56sc5tQFAz5dub7c1VWVpbH9xkMJN8haucSrZ9P0frHGcbtziVaa9fyDeRqB+dVn1Ylaa0PmG8PA18A59tsMhiYa26kvgr4l1LqCl+m0VPCw8Pp379/9d+uXbs8tu9Dhw4xatQoxo8fz4wZMzy2X0u5ubncdddddW43bNgwt99j6tSpfPaZy30LhBApGTD4FsiZadymZHh09z6rSjKvlRumtS42/z8OeMpyG611isX2c4CvtdbzfZVGT4qJiWHdunVe2XdiYiJZWVle2TdARUUFgwcPZvBgu53GrCxfvtxr6RBCOFCQA7lvQcaDxm3KCI8GB1+WGBKBZUqp9cBq4But9UKl1O1KKdtlD0NScnIyR48aHbJyc3Orh64/8cQT3HzzzWRmZtK5c2deeeWV6te8++67pKWl0a9fP2699VYA3njjDc477zz69evHpEmTOHXqFAC7d+9mzJgxpKWlMWbMGPbs2XNOGo4fP84VV1xBWloaQ4cOJS8vrzoN06ZNY9y4cUyZMoXs7GwmTJgAwJEjR7jwwgsZOHAgv//97+nUqVN1Ppo2bQrUDMW/6qqr6NmzJ5MnT66qHuSpp57ivPPOo0+fPkybNq36cSGEGwpy4NOpcPUcGP2ocfvp1HMbpOvBZyUGrfVOoJ+dx2c72H6qJ973yQWbyD9w8pzHKysrCQ8Pd2ufqe2a8filvWvd5vTp0/Tv3x+AlJQUvvjii1q337JlC1lZWRQXF9OjRw/+8Ic/sG3bNp577jmWLVtGfHw8x48fB+DKK6/ktttuA+Cxxx7jrbfe4s4772T69OlMmTKFm266if/85z/cddddzJ8/3+p9nn32WQYMGMD8+fNZvHgxU6ZMqS7ZrFmzhmXLlhETE2PVgPXkk08yevRoHnnkERYuXMjrr1v1Gai2du1aNm3aRLt27Rg+fDg//fQT6enpTJ8+nb/+9a8A3HjjjXz99ddceumltX4eQggH9v9iBIOqEkJKhnF//y9Af4+8RdBPoheoXK1KuuSSS2jUqBGNGjWidevWHDp0iMWLFzNp0iTi4+MBaNmyJQAbN27kscce48SJE5SUlHDRRRcBsGLFCubNmwcYJ+AHH3zwnPdZuXJldZAaPXo0x44do6ioCIDLLruMmJiYc16zbNmy6teMHz+eFi1a2M3D+eefT/v27QGq21XS09PJyspi5syZnDp1iuPHj9O7d28JDEK4K/2ecx9LyTD+PNQTK+QDg6Mre38M9IqIiMBkMgGc01e/UaNG1f+Hh4dTUVHhsMpl6tSpzJ8/n379+jFnzhyH3dPsjeOwt8+q7RxN1+ts1Y+9PJSVlXHHHXeQm5tLhw4deOKJJ2ScghABLhAHuIWs5ORk1qxZA8Dnn39e5/Zjxozhs88+q65CqrotLi6mbdu2lJeX88EHH1RvP2zYMObOnQvABx98QHp6+jn7HDZsWPVrsrOzSUhIoFmzZrWmIz09nU8++QSARYsWUVhYWGfaq1QFgYSEBEpKSqQXkhBBQAKDDz3++OPcfffdjBgxwqn2jd69e/PII4+QkZFBUlISDz/8MABPP/00Q4YM4cILL6Rnz57V27/yyiu8/fbbpKWl8d577/Hyyy+fs89HHnmE3Nxc0tLSePjhh3nnnXecSveiRYsYOHAg3377LW3btnW6tBUXF8dtt91G3759ueKKKzjvPIfjFoUQgcLRAIdg+WsoA9xuvfVWbTKZ6r0fd/JdVlamy8vLtdZaL1++XPfr16/e6aiNDHDzHMl3w+KpAW4h38YQCjIyMjh58iQmk8ntnlT1sWfPHq655hpMJhNRUVG88cYbPk+DEMJ3JDAEgZwcz/VPdke3bt1Yu3atX9MghPAdaWMQQghhRQKDEEIIKxIYhBAiCJWcqfDaviUwCCFEkDGZNBkzs3h+4Rav7F8Cg5cE+7TbABdffDEnTpw45/EnnniCv//97157XyFE7fIPnuR46Vm6Jzb1yv6lV9KyWZA00HrK2oIcY0Iqe3OSOCkYpt2uqKggIsLxT+C///1vvd9DCOF5S7cbsxsP75rglf1LiSFpoPWUtVVT2iYN9PhbBcK0288++6zV9Npz5sxh+vTp1c9PmDCheu4ly/Q+88wz9OjRg7Fjx7J169bq7detW8fQoUNJS0tj4sSJ1dNlvPLKK6SmppKWlsZ1110HwOrVqxk2bBgDBgxg2LBhVvsRQjhv2Y4j9GwTS+vYaK/sXwJD1ZS1n06Fxc/UzHNez0Uvqqbd7t+/PxMnTqxz+y1btvDdd9+xevVqnnzyScrLy9m0aRPPPfccWVlZrF+/npkzZwLGtNs///wz69evp1evXrz11lsA1dNu5+XlMXnyZIcrsK1Zs4Yvv/ySDz/80Km8rFmzhrlz57J27VrmzZvHzz//XP3clClTeP7558nLy6Nv3748+eSTAPztb39j7dq15OXlMXu2MbN6z549ycnJYe3atTz11FP8+c9/dur9hRA1ysor+XlXIeleKi2AVCUZLJfJy3jQIyshBeq02+B4em1Hli5dysSJE2ncuHH16wGKioo4ceIEI0eOBOCmm27i6quvBiAtLY3JkydzxRVXcMUVV1Rvf9NNN7F9+3aUUpSXlzudBiGE4eddxzlbYSK9m/cCg5QY4Nxl8jy4EpIlT067/eqrr7JhwwYef/xxh9NY25t2G6yn17ZMk7101bUvR7755hv++Mc/smbNGgYNGkRFRQV/+ctfGDVqFBs3bmTBggUy/bYQbli2/ShR4WGcn9LSa+8hgcEHy+RVCYRpt+2lad26dZhMJvbu3cvq1avP2SYjI4MvvviC06dPU1xczIIFCwBo3rw5LVq0YOnSpQC89957jBw5snpfo0aNYubMmdUlm6KiIpKSkgCYM2dOnWkTQpxr6fajDOwUR+Mo71X4SFVSbcvkeXBxbTCmr77lllt49tlnGTJkSJ3bW067XVhYyCWXXMLrr79ePe12p06d6Nu3L8XFxYDR4HvzzTfzwgsv0KpVK95+++0632P48OGkpKTQt29f+vTpw8CB5za6Dxw4kGuvvZb+/fvTqVMnRowYUf3cO++8w+23386pU6fo3Lkzb7/9NpWVldxwww0UFRWhtebee+8lLi6OBx98kJtuuokXX3yR0aNHu/DJCSEAjpacIf/gSR64qId338jRtKvB8ifTbrsmGPIt0257juQ7tMxfu093euhrvW5Pod3nZdrtBsTf024LIQLDTzuO0jwmkj5Jzb36PhIYgoC/p90WQvif1ppl248yrEs84WGudQZxVcg2PmsnF7AXgUW+NyHMls2CBXdXd4TZebSUTsVruO/MP43nvCgkA0N0dDTHjh2Tk0yQ0Vpz7NgxoqO9M5pTiKCSNBA2zoO5k6Eghx2r/svsyBfpcuh7r8zMYCkkq5Lat2/Pvn37OHLkiMNtysrKGuQJKNDzHR0dTfv27f2dDCH8LyUDrvvACAwfXkNmuYlyFU7Y/37g8R6TtkIyMERGRpKSklLrNtnZ2QwYMMBHKQocDTXfQgSllAwYcjvkzKQR8FPiVEZ7OSiAj6uSlFK7lFIblFLrlFK5dp6frJTKM/8tV0r182X6hBAioBTkwKrZVIZHc0pHMeLY516bmcGSP9oYRmmt+2utB9t5rgAYqbVOA54GXvdt0oQQIkAU5BjVSMAXvV7ilvIHjN5I5jYHbwqoqiSt9XKLuysBqWwWQjRM+3+BPldCn0nMXRhBebuOhF0yFDZ87pWZGSwpX/bcUUoVAIWABl7TWjssESil7gd6aq1vtfPcNGAaQGJi4qCq+YFcUVJSQtOm3ln9KJBJvhsWyXfwO12h+eOPp7g4JZKrukfVuq0r+R41atQaBzU3vp0SA2hnvm0NrAcyHGw3CtgMxNe1T3tTYjgjVIfM10Xy3bBIvoPfdxsP6k4Pfa2X7zha57aemhLDp20MWusD5tvDwBfA+bbbKKXSgDeBy7XWx3yZPiGECDTZ247QJCqcQZ1a+Ow9fRYYlFJNlFKxVf8D44CNNtt0BOYBN2qtt/kqbUIIEYi01izZeoThXROIivDddbwvSwyJwDKl1HpgNfCN1nqhUup2pdTt5m3+CsQD/3LUpVUIIULesllQkMP2wyXsP3GazB6tjZ5IXp4Ko4rPeiVprXcC54xL0FrPtvj/VuCcxmYhhGhQkgbCp1PZ2uNZIJZxjbfCp7831orxgYDqriqEEILqBcNGvncDzzQfT8K3P1gvKOZlITmJnhBCBLsTiUN5p3wMk898DINv8VlQAAkMQggRkDYu+5rrw77nYP+7IPctn0yFUUUCgxBCBJqCHPqtuoc/h/+JxMueMqqRPp3qs+AggUEIIQJM5b413F15N81TRxMWpqrbHNj/i0/eXxqfhRAiwKxqeyOLy1bxWq/EmgdTMqTxWQghGqofNh8mKiKMEd0S/PL+EhiEECKAaK35YfMhhneJp3GUfyp1JDAIIUQA2XG4hD3HTzHGshrJxyQwCCFEAPlh82EAxvRq7bc0SGAQQogA8uPmQ/Ru14y2zWP8lgYJDEIIESCOlZzhlz2FjPVjNRJIYBBCiICRtfUIJo0EBiGEEIYfNx8isVkj+iQ182s6JDAIIUQAOFNRSc62I4zumYhSyq9pkcAghBCeZF5kx4oTi+ys+PUYpWcrGevH3khVJDAIIYQnmRfZqQ4OBTnG/aSBtb7su02HaBIVzvCu/hntbEnmShJCCE+qmvDu06nGOgq5b9W5yE6lSbNo029k9mxNdGS4r1LqkJQYhBDC01IyjKCQM9OpRXZWFxznWOlZLunb1kcJrJ0EBiGE8LSCHKOkkPGgU4vsfLvxINGRYWT2aOWjBNZOAoMQQnhSVZvC1XNg9KN1LrJjMmm+3fgbo3q09tukebYkMAghhCft/8W6TaGORXbW7CnkSPEZ/idAqpFAGp+FEMKz0u8597FaFtn574aDREWEMbqn/7upVpESgxBC+InJpFm48TdGdm9F00aBc50ugUEIIfxk3b4THCwq4+K+bfydFCsSGIQQwk++3XCQyHDl10V57PFpYFBK7VJKbVBKrVNK5dp5XimlXlFK7VBK5Smlah8qKIQQQcpk0ixYf5CMbq1oFh3p7+RY8UeJYZTWur/WerCd5/4H6Gb+mwb826cpE0IIH1lZcIzfTpZx+YAkt+dX8pZAq0q6HHhXG1YCcUqpwOnDJYQQHvLl2gM0iQrnwl6Jbs+v5C2+DgwaWKSUWqOUmmbn+SRgr8X9febHhBAiZJSVV/LfjQe5qE8bYqLCredXWvxMzQC5OqbS8BZf948arrU+oJRqDXyvlNqitbYsP9mbhFzbPmAOKtMAEhMTyc7OdjkhJSUlbr0u2Em+GxbJd2DK/a2C4rIKOocd5dd376I4tisnWqSR3GoMyTkz+S0xk9Kln7F3t8ml/Xoq3z4NDFrrA+bbw0qpL4DzAcvAsA/oYHG/PXDAzn5eB14HGDx4sM7MzHQ5LdnZ2bjzumAn+W5YJN+Bae57a0hoWsjtE0cTsSfKKCGk3wdHfoS0a2mT9wmMm0GXYZku7ddT+fZZVZJSqolSKrbqf2AcsNFms6+AKebeSUOBIq31QV+lUQghvK3oVDmLtxzm0n5tiQgPM6qL0u+DRY9B17Gw4wcYNwOWvVjn5Hve4ssSQyLwhXnJugjgQ631QqXU7QBa69nAf4GLgR3AKeB3PkyfEEJ43bcbD3K20sQV/S2aT00VkHYN5H1szMg6bDq0TTPmV/JDO4PPAoPWeifQz87jsy3+18AffZUmIYTwtfnr9pOS0IS09s1rHkwaCMtfqZmmO2VErfMreVugdVcVQoiQdbDoNKsKjnNF/yTMtScuT9PtCxIYhBDCR75adwCt4UbTFzUn/qppusEY0FbHNN2+IIFBCCF85Iu1++nfIY6W3YbWlAqqpum2HNCWkmF/+m4fCZx5XoUQIoRt/a2YLb8V88SlqZCSUlNlNPgWo13BjwPabEmJQQghfGD+uv2Ehykm9GtnPJCSYQSFnJnGbYAEBZDAIIQQXmcyab5ad4D0rgkkNG1kPFiQY5QUqnoi+bGx2ZYEBiGE8LKVBcfYf+I0EweYxy4EYE8kSxIYhBDCyz7+eS+x0RGM72Neqa2qJ1JV9VEA9ESyJIFBCCG86HTWPzi+6UcmDkgiOjLceDBp4LlBwM89kSxJYBBCCHc5scBOdkkHZoXN4uakfTXP+3GtBWdIYBBCCHfVscCO1ppZO9rwYvNHSF58R0CsteAMGccghBDuslxgx854hPX7ith6qJgpEydA6Qmja2rGgwEdFEBKDEIIUT+1jEf4+Oc9xESGMzHu14DtmmqPBAYhhKgPB+MRSs9U8NW6A9zd5SCNv7w1YLum2iNVSUII4S7L8QgpGcZ02eb7Xx9NpvRsJRMSDsLIOfa7pgZolZIEBiGEcFct4xHm5oXTrXVTki55BJTNcvZ+XGvBGRIYhBDCXfbGHaRksDGqH2u/XsZjl/SqWXchiEgbgxBCeNg7y3cRExnO1YM7+DspbpHAIIQQHnS89Cxfrj/ApEFJNI+J9Hdy3CKBQQghPOij1Xs4W2HipguS/Z0Ut0lgEEIID6moNPH+yt2kd02gW2Ksv5PjNgkMQgjhIYvyD3GwqIybhiX7Oyn1IoFBCCFc5WDyvOPfvUCHljGM7tnaL8nyFKcDg1JqvlJqglJKgokQomGzM3lexcc38c3xNkwZmkx4WPB1UbXkyjiGUuBjoEgpNQd4W2u93SupEkKIQGZn8ry32vyVdaVtmR2kXVQtOX31r7WeDLQFngbGAluVUjlKqSlKqRhvJVAIIfyirrUWLCbPO91vKv/Y0YYrBybRvHFwdlG15FK1kNb6pNb631rr84G+wBrgNeA3pdRrSqlede1DKRWulFqrlPraznPNlVILlFLrlVKblFK/cyV9IsA5saiJEAGjjrUWbCfPG2TaEPSNzlXcai9QSrUDLgcmABXAZ0AHIE8pdX8dL78b2OzguT8C+VrrfkAm8A+lVJQ7aRQBqK4DTYhAYlldZLvAjsXkeWUjHuZe0z28Fv0q3U+t9WuSPcWVxudIpdRVSqn/AruBK4CZQFut9S1a64uBycBjteyjPXAJ8KaDTTQQq4zJRZoCxzECjwgFtR1oQgQiR2stWEyeN3/tfhaWdmfP6H+eu45zkHKl8fkgoIAPgYe11nl2tvkeKKxlH7OABwFHIz9eBb4CDpi3uVZrbXIhjSLQWR5oQbCSlWjgbNdaSBlh/GbNk+eZTJrXc3bSN6k5vYcPP3cW1SCltNbObajUjcCnWusyt95IqQnAxVrrO5RSmcD9WusJNttcBQwH7gO6YASaflrrkzbbTQOmASQmJg6aO3euy+kpKSmhadOmbuQkuPk733GFeaTmv8CBduNpd2Ah+akPcKJFmtff19/59hfJt/uqfqtVv1Hb+wBrDlXwf2vPcEe/Rpzf1v+TVbuS71GjRq3RWg+2+6TW2id/wHPAPmAX8BtwCnjfZptvgBEW9xcD59e230GDBml3ZGVlufW6YOfXfO9covXzKcatvfteJN93w+KRfC996dzf5s4lxuNaa5PJpC9/dZke8fxiXV5RWf/38wBX8g3kagfnVZ8NVtNaP6K1bq+1TgauAxZrrW+w2WwPMAZAKZUI9AB2+iqNwstqWdREiICTfs+5VZ0W1UhLth1h3d4T/H5kZyLCQ2vcr9/LPkqp2wG01rMxxkjMUUptwGjPeEhrfdSf6RMe5GBRE2lnEMFGa82L32+jfYsYrh4U/APabPklMGits4Fs8/+zLR4/AIzzR5qEG5bNMrqaWp7YC3KMEoC9ICBEiPhx82Hy9hUxc1IaURGhVVoAmURP1IeMSxANkMlklBY6xTdm4sAkfyfHKyQwuENG8BpkXIJogBbl/0b+wZPcPaYbkSHWtlAlNHPlbXKlXMPRACAhQpDJpHnp++10btWEy/uHZmkBJDC4R66Ua9gOALItSQkRaOpR4v9mw0G2HirmnrHdg35q7dpIYHCXXClbzRfD6EdrgqUEBxHI3CzxV5o0s37YRvfEpkzo29bryfQnCQzukitlGZcggpObJf6v1u/n1yOl3Du2O2EhXFqAABjHEJQsr5RTMoz5UxpidZKMSxDBysU5uyoqTbz8w3Z6tW3GRb3b+CiR/iMlBnfIlbIQwc3FEv+8tfvZdewU910Y+qUFkBKDe+RKueGQQXyhx8US/9kKE6/8uJ2+Sc0Z26u1jxPrH1JiEKI20jU59LhY4v84dy/7Ck9z34XdUSEyrXZdJDD4mwyWC2zSNTlweOpYqWNyPEvFZeXM+n4b5ye3JLNHK9feJ4hJYPAUd3+0ckUa+KRrcmDwxLHi4nH60vfbOVZ6lkcv6dVgSgsggcFz3P3RyhVp4JOuyYHBE8eKC8dp3r4TzFlewA1DO9KvQ1x9Ux9UpPHZUyx/tINvMU4gzv5oZbnLwCVdkwNLfY8VJ4/TikoTD3++gYSmjXhwfE9PpT5oSInBk9ytcpAr0sAlXZMDiyeOFSeO0//8VED+wZM8eVlvmkVHeiDhwUUCgye586OVaSUCmwsNlcLLPHWs1HGc7j1+ihe/38bYXomM7xP6g9nskcDgKe7+aOWKVAjneOJYqeM41Vrz6PyNhCvFU5f3blANzpakjcFTavvR1lalJIPlhHCOJ46VOo7Tr9YfIGfbEZ64NJV2cTEeSHRwksDgKc7+aGUkrXvkcxOeUMtxeuLUWZ5akE+/DnHceEGyr1MWUKQqyddk3IJ7vPG5yeBCYeHZ/26m6HQ5f7uyb0ivteAMCQzO8OQJRMYtuMcbn5sEaWG2/NejfJK7j1tHdKZX22b+To7fSWBwhjsnkNqCiYykdY+nPzcJ0qFp2SziCvOsH6vlQq6svJJHv9hIx5aNuXtMN++nLwhIYHCGOyeQ2oKJjFtwjzc+NwnSoSdpIKn5Lzh9IfevrB0UHC3lmYl9iIkK9106A5gEBme5egJxFEzA/b7YDblO3FvjPSRIh56UDPJTH3DqQm7boWL+veRXrhyQxIhuFpPkNeRjDQkMznPnBGIvmNSnL7a9UsiH10KYTecyb/2A/XmweGO8hwwuDFknWqTVeSFnMmkembeBpo0iePSSXtZPNvD2p4YXGGo7uTl67qu73TuB2AsmliNpq97PciRtbSdae6WQUY/Cshd98wP258FS9blZfkf7f6mpmqv6zFwJVDK4MGTFFebVeSH34eo9rNldyGOXpBLftJH1kw29/UlrHdR/gwYN0i7ZuUTr51P02nkvW93XO5dY/2/53Fd31TxmuZ+lL9X5Pufsy3I/zmxjz48ztH68mXFr+bofZ9T5+qysrNr3XRcX3ssrbL+vZ9sbf/a+Pwv1zneQapD53rlEn5nRvtbjatfREt37rwv19W+s0CaTyfG+bI+1AOfK9w3kagfnVZ8PcFNKhQO5wH6t9QQ7z2cCs4BI4KjWeqRHE2C+Ekj9cDI0Lz53dkVnZ0ita8SlMyOh3ZmR1bYUkjLCt7Oz+nsmWNvPrErBUtdmtBWha/8v5Kc+QH8Hx96Zikru/GgtYQpmXtXP8bQXjo61BsAfI5/vBjYD53QWVkrFAf8Cxmut9yilvLPAakoG+9uOJyVnJpUjHsDUMR0qTcZzHdMJH3QzYTkzMY14AN1pBMqkUQrX5k1xdiS0KydaR1NAp99n/uGOhFWzrX/Anh4dHAgHi+1nBqE9ZbmM+nZN+j2cyM62fszi2HtqQT55+4qYfcMgkhxNe9HAp1v3aWBQSrUHLgGeAe6zs8n1wDyt9R4ArfVhrySkIIfE/Qt5uWIiN+TMZvqPUaww9QbggrBNvBo5m/crz30OIExBmFKEKYUy/x8epghTEBEeRniYIiJMERGuiAwLIyJcEREWRmREGFHhiqiIMBpFhNMoIoxGEWGknlnP5L2vszbpZgYuf52s4q4UtbmAJo3CaRwVQZOocJo0iiA2OoLEgtVEXvkfoiyvhNLvg6xn4PqPjcfmTjb+rvvAuG/ZG8oDn5tTB4u3T2SWwWnVbOOxUL6qq2rbqfqcLb8H4ZLP1uzjg1V7+P3IzrXPnOru3GchQhlVTT56M6U+A54DYoH7bauSlFKzMKqQepu3eVlr/a6d/UwDpgEkJiYOmjt3rtNpiCvMIzX/Bb5vN50fTQPoWraRKcde5N14I05V/b+9UR+6lm3kpuMvMqelcV8DWlN9a8JoozFpqv8qzbcVWmMyGfcrqm815SbjfrlJk1a5iWdML3Of6S6WVfTmPLWJVyNfYXr5XVbByFZEGDSJVDSJhN+xgD1RXdgV05fYKEU/0yZuOjKTwzFdaH1mN7nd7+dsqzTCzKWdkpISmjZt6vTnZanDnnkUx3Y1enxYfJ6xxTsAqp+r+oz3dJyE0iaKY7uSmv8C+akPWL22rn3u7Xilw+8vP/UBAPpsfA4NbOrzCIDD96lPvgNBVb4PtBtPuwML7ebRnmDPt7vs5Xv3yUpmrCyja1wY9w+ODslpL1z5vkeNGrVGaz3Y3nM+CwxKqQnAxVrrO8ztCPYCw6vAYGAMEAOsAC7RWm9ztN/Bgwfr3Nxc5xNivprN3m0iMzPTeKzqahbsX+n+9AoMv8vzV8A2V9YVlSbO7simct8vHEm7nVNnKyk5U0HpmQqKyyo4WVZefVt0qpwTp8o5cfosJ06VU3jqLIWl5ZytNHFvxKfcHfEFL1dM5KWKqwlTEN+0EYnNGhFxtpQ+XZJo2zyGNs2i6RjfmE7xjWnVtFH9phi2LU0sfxUWPQZp18COHxwXwW1fZ3u/ts+s6n+o+S4cfC/Z2dk133ewWvxMTZXZ6EedeklI5NsNtvkuOlXOhFeXUl6hWXBnOq1iGzl+cRBz5ftWSjkMDL6sShoOXKaUuhiIBpoppd7XWt9gsc0+jAbnUqBUKZUD9AMcBgaXVZ0wdmfXPFbV7bG2E783ivI2J6+I8DAieoyGHqOJdWN3WmtObcsi+oslHOhxJ3/Y/D690i5mY1Q/Dp08w6HiMn49UELC+tksO9PJqlSSGbWZ9MZ7+TnpRpLjm9AxvrFx27Ix7eJi6r66steQnnYN5H1ce92/qw3wlp+Z5f+WRf5QLOoHQttOIHGhutJk0tz7yTp+Kypj7rQLQjYoeJLPAoPW+hHgEajueXS/TVAA+BJ4VSkVAUQBQ4CXvJ64uupw3ek9VF9u1NOrXUtp8tlkGPUo7YZNh/7jGPfpVMal3weNK+Cqe4wrik7Xoj+ZyoFx/2Zb4wGc2ZbNiPX/xz+bP8aOwyVkbTnC2arGeCAyXNGhhVGy6BTfhE7xjUlJaEL3xFjaNo+uKWlYNgqnXWuUFCxPZLUFYFnz2rEG3hBqlwvtLs8v3MLiLYd5+vLeDOrUwscJDU5+X49BKXU7gNZ6ttZ6s1JqIZCHUYX/ptZ6o9cT4cyJ39fdNAsLYOk/jEbkqh/+3MnQ59x692r7f6kZ8NY2zX7jtDkv6po5JH06laTBt8Dmt2DyezyYksGDQKVJ89vJMnYfK2XPsVPsOnaKPcdL2XX0FD/vKqTkTEX1rmIbRdA1sSk9EmPJjNrCmI1volOvJirvExg3A4ZNh9LDRtpHPmR98G74HLYsqOlVJVfD9jXwhlC7nLxY+2j1Hl7L2cmNQztxw9BO/khpUPJLYNBaZwPZ5v9n2zz3AvCCzxNV14nf10X5PpNg4zzjhDrk9preN30mOX5NVUmibVrNAbPiVSNYuHCVHh6mSIqLISkuhmFdrN9Ca82x0rP8eriEbYdL2H6omG2Hijm68QfOM73IlPK7uG3D15yIHMeFP8xk0YF4UlqNpr/pE8I2zjMO3rmTobIcwiONYLHsxcC4Gg7UbqH1WLmsw555UBAWeHnyhDqO2SXbjvDY/I2M7N6Kxy9NbbDLdLqj4U2J4UhtcyHZm1Pnw2uNBtYqy2YZ9y2nY6hrqo3apm5IyTBKC6Zy44dvKq8pPdTF8oDpcL7VlBnt986vmV/JjcnjlFIkNG3EkM7x3Di0E09d3oe50y7gjTFhqKvn8PubplI88A4uVCt5L/xKtq9bwgvfbaX4rKb4wGYWfPkx5eVnoOI0ZwbdBqYK6HWpddqvnmOUJnw9YVkIzo9THNs15PJUrZZjdmdRJX94fw3dE2N59foBRITLqc4V8mlB3ZOp2SvKj3rUqKKp2iYswuiFUzWhneUBWJ8Tjra5dTY/uW8Z9fw7l0DqFcb7zZtGl1/nQL//rblK99DkcSr9Hlr2GUtmj9ZcPvE6Ym94nzsiv+K+kUm8G/tvlg18mZ/ir+LSE+9TXql5uWIiJT+9zgMrwnnt2ADKPprC/rULMZnMGd2ywPcnrxCcH+dEi7SQyxNQ6zG7/VAxL+WWEd80ind+dx6x0ZH+TWsQ8nsbQ0Coqw7XXpF72HTrKpvct4w69WUvQlmR+1NtVKlqUwiPhGF3GlVJVQPXXBkd3SbNCFite0HexxxKzKRNXEfv11mbSy1R5mL+JSltIX8+RMYQrSLJHHEl2Ycu4i/5D3HfrnvIPnsHr86/lTe+HMf1YT+wpN8LdIhIo3elybdXe/6e8sMbQjFPDo7ZI1tW8L9rzhAepnj35iG0bhbt12QGKwkM4H4dru0BN2y6ERTsHYCuHpwbPjduqwJByggjMGz4vPbX2h4ww6bDju9hZzZ0vICWB3+BpD/Zn5rDkycM29HJq2YbDed9JhEG9Pt0Kv2ungONJvKG3s3OC57ht0XH+P322XynMtmwOovpK5rSJCqcgZ1aMLRzPOentCStfXMaRXhxMZVQ7BYaCnmybf+pGrOybFb18bslpj+Tc88QEa64//xoUhKa+CmxwU8CQ33YHnDRzR0fgLUdnPYaPRXQ+0rrK6LrPqh7SmjbILf8VaM6ydx9dE/HSXT1dnWCbaml9LDRkN5nknUJav8v0GcS6tOpdEnoBvs/hbRruSjvEy4Y8zh94gewuuA4qwuO88J3WwFoFBHGoE4tuKBzPMO6xpPWPo5IT5UoQrBbaFxhHqyeFfx5Ou6gl15vo5de/oGT3PDWKqLCw/ho2lB2b/zZzwkObhIY3FW1SM6oR42r8ujmRpXN4JshqklN1ZHtqm32Dk57fbI3Lzi3T7arV/UFOUY7SFW30YIcOn44GUY95N2ujrallktfNoKC7cyy1Vd/91mPkh43g2bLXuTSqwdx6RXGNoWlZ/l513FW7jzOip3H+Mf32/jH99C0UQRDUloyvGsCI7ol0LV1U/d7n4Rgt9DY4h2hkae+k2CTnV56fSex6UARk99cRUxkOB/dNpTkhCbs9m9qg54EBnfZjhkwVRhBYf1HxpgBywMQaj84vTWAbv8vNWkxv29+6gP0N1V4t6uiq1VzpgrrUdJV7TcWJ68WTaIY17sN43obE58dLz3Lyp3H+GnHUX7acZQftxjzLbZpFs3wrglkdE9gRLdWtGwS5b10B4G9Ha+ki7erDX2hqsT8wTVGdWxEDEz+hLzING58YxVNG0Xw0W1D6Rjf2N8pDQkSGNxlb8xA/vxzTsQOD0Db57zRQFiVRouqqhMt0iA9M7D6sicNhOWvnFvNVstn0LJJFBf3bcvFfdsCsK/wFMu2H2Xp9qP8uOUQn/+yD6UgrX0cmd1bEVtayQiTDsmJ06z4ciyGP8Z9qJrbNbsLueHHlcQ3jeKj24bSoaUEBU+R7qr1ZXlCd7C2rFO8uSh9IPfP99C6y+1bNOa68zvyz8kDWfPYhcz/43DuGdOdMAWvLN7OjJVlDJ7xPXd9tJbP1+zjSPEZL2QmANh813GFeaGx1GtVm0JYJGQ8yFlTON2ybufKFr8y745hEhQ8TEoM9eWJHh/ebvS0qKpKbjUGVv8YOI2PXqjXDw9T9O8QR/8Ocdw9thuFpWd57ascDocnkLPtCF+tPwBAn6RmZHZvTWaPVvTvEOf/QVCeuAK3qZZMzZ8N1zs5MNJVzlSBOsqTqzMWbzR66VVc8z5Pb4xn2+lI3mo0iyc6byEyVrqkepqUGOrDQ1e7PlmU3lyySd79Sf1KNp6Wfo/9rrMerIpo0SSKoW0jePGa/qz+81i+vjOd+8d1JyYynH8v+ZWrZq9g4NPfc+dHa/li7T6Ol5712Hu7xFNX4Bal2APtxnv3u66rxOwoT50zXctrixSOX/o21/8QxTsrdtN72AQa3fARkQld7G8v6kVKDPXhqatdXzR6mks2uzpdQ3Kw9mX3gLAwRZ+k5vRJas700d0oOlXOT78eJWvLYbK2HmHB+gMoBQM6xDG6Z2tG9WxNattmvplnx1OdECxKse1WzDbue7Nrcm0lZnt56nWp0TZn+fiq2dbds21ktbqeP32yntNni3jp2n5MHNDeeKJLHUvCB+r8VwFOAkN9BEsvFouSza7dJpIzbwzOvuxe0LxxZHUjtsmk2XigiMVbDrN4y2H+vmgbf1+0jTbNohnVsxWjerQmvVsCjaNqOWzqeyKqbycEm2rJ/KJY+nvru3a2CtQ2T1Wz7V73Qc3j4VE1DcsWysoreen7bbyWs5OebYx5j7q2dmG1ElkW1S0SGBoCy5LN7uzg7cvuZWFhirT2caS1j+Oesd05XFxG9tYjZG05zIL1B/lo9V6iIsIY2jme0T1aMbpn4rndI+t7Iqpvm5VNKbZ6riRvfNfOlpht85R+n/H4h9cC2ggKleUQ3636JVprvtt0iBnf5LOv8DTXD+nIXyekEh3p4qh3b3UFD3ESGBqCYCnZBJjWsdFcM7gD1wzuwNkKEz/vOs7iLYfJ2nKYJxbk88SCfLq0asKoHkaV03nJLYmqz4nIE50QfPldO/NejvLU92rjswGIjIExj1ePCdrRZABPfJXPsh1H6dkmlo9uG8oFXeLdT6c3uoKHOAkMQjghKiKM4V0TGN41gb9MSGXX0VIjSGw9zLsrdvPmsgKaRIUzvGsCo3omM6HvFGIdnYhq66kTCqOULTkqVXz/BIRFgemsMXNw2zROXf4mK35YyO8LSmgcFc4Tl6Zyw9BO9e8tFgpzRfmYBAYh3JCc0ISb01O4OT2FU2crWL7jGFlbD5O99QjFWxYzLvJN3o++lonLX2dHZF96DL2kphqktuqmUBilbMlRu8qx7RAZDUPuQa+aTfkH/8u9pvtZdHo4153XnvvH9SC+qQfWZg7B+a98QQJDqJFeGD7XOCqCsamJjE1NRO9cQuUn/+bbXn/n2yPJfLerO7N+uINpi+5BJ49gZPdWjOg2gO5XvY3ydr33slnEFYYBmTWPufpb8MbvyWLm4PURaXyW14IHCp/mypiV/PHm35HWPs69/doTgvNf+YIEhmDizEEqvTD8Sh1YS8S173BpSgaXAqfPnseWld25cesKni8qY8Y3m4HNtIptxIxml3BRzkyKzr+XZskj7HXKqZ+kgaQumQz9+7v/W/DC78nUIoV1w17l5axolmz7iYSm3Rk77FUubLyXME8GBZD2NTdJYAgmzhyk0gvDv2xORDFR4QzIuAwyLuNCYP+J0/y0/Si/5X3P+Xvn83LFRG5Y9SZ3ro0jqmsmQzq3ZEhKPJ3iG9d/7ESKedJEd0YmV11sePD3dLTkDJ/k7uWDlWnsP3GaVrEn+dOF3Zk6PFlWWQswEhiCibMHaUPthVHbSY7+fkqUtaS4GK5JKIBjM9BT3md844Hk5n7Lc2vv5/6tmofWdgcgsVkjBndqyYCOcQzo2ILe7Zq53lUTc3fV2n4Lzl5suPl7OlNRSc62o8xft59Fm36jvFIztHNL/nxxL8b1TnR+LQ1nq7SqtrMkVakuk8AQbJw5SBtqL4zaTnK7Tf5NmyVzvbdKyaAH0GPCNdC7DbP3/8Kv3TNYsfM4PxccZ83uQr7ZcBCAyHBFarvm9GnXjJ5tYunRphk92sTSPKb2K+24wjzY7uLIZNuLDRd+T5UmzaYDRfy04xjLfz3Kz7uOU1ZuokXjSCYP6cTkIR3plujCALUqzlZpmbeL63YPkClVqW6SwBBs6jpIQ7EXhrNXi7Wd5HZn+zLFtXNQ761SMugKdG0dy41DOwFw+GQZa/eeYO2eE6zdU8iC9Qf4YFVF9cvaNo+mR5tYerSJpZc5WHRp1ZSoiDAoyCE1/4WaSfScHZnswu+p5EwFBUdKWbP7OMt/PcbKncc4WWakr0diLNed15HMHq0Y3jXB9ZX2LL/3qu927mRoNwAObXRcWr56DqkfTobmxVKV6iYJDMHEmZN+KPbCcKUBNMSq0Vo3i+ai3m24yLxAkdaa306WseW3Yraa/zYfPMlPO45SXqkBY3bZdnHR/CHia3bF3EP09kQSD++mdWwPOo74P+K3rUAnDCE2OoKo8DDCdi+1utio7JROadIwTp+tJHL7SopG/ZOjqg/HNh6k4GgSYa3/SpPP5/PymbNW05d3aBnDxX3bckGXeIZ1SaBVbD27m9p+72CMkC5YUvt3m5LBgXbjSQ6R34A/SGAIJs6c9EOxF4YrDaD+rkbz1DTTDiilaNs8hrbNYxjVo3X14+WVJgqOlrLlt2K2Hypm97FTfHJ8ErsOF1GUtQOtLffSB7J+AOCCsE38M/IV/qTv4ZelaaRVNGLWu5OZXn4XK0y9gd6ACVhR/eqEpkmkJHRnVHITkhOa0DmhCb3bNff8mgi23/uq2RAeCcPurP27Lcih3YGFDa8q1YMkMASTUDzpO8vZthVHJSpfcVS6Sb/Pq92II8PD6J4YS3eb+vvs7GyGj8jgaMkZjhafpfDUWU6cLufEqbOUnKmg764VLIr5G52bDKRjpYnoqA5klyZxb9lmJnTrQ+OocBpHRdA4Kpy4mCg6JTSmmS97EFl+75ExcP0ntVeLmT/X/NQH6D/6rtCoSvUDnwcGpVQ4kAvs11pPcLDNecBK4Fqt9We+TB8gg8QCkTMlgVrXtejvm3TWVrqxXAbWh3XfkeFh1aWMc82w81gvAM73aqqcVPW9p4yEA2trHndURWr+DZyo6mwQClWpfuCPhXruBjY7etIcOJ4HvvNZimwF8lKYDZGzCyL5YNEfp1he5VouXuPocU9aNuvcz6Ugx3g82Fh+7zd9ZUzTbfm92/tuA+U3EOR8GhiUUu2BS4A3a9nsTuBz4LBPEmWP5VXf4mekKOpvvljhzpMcrd/tzXW9q/hyzWdvC7bvPYQobd0q5d03U+oz4DkgFrjftipJKZUEfAiMBt4CvrZXlaSUmgZMA0hMTBw0d+5cl9NSUlJC06ZNa90mueADknd/wq5O17ArZbLL7xGInMl3KPJkvjvsmUdxbFdj8JhZXGEescU7KI7tSmr+C+SnPsCJFmnEFeaRmv8CezpOouOez895vOq+J1Xt+0C78bTd/y2bez/o8fcIdPI7r9uoUaPWaK0H231Sa+2TP2AC8C/z/5kYJ33bbT4Fhpr/nwNcVdd+Bw0apN2RlZVV+wY7l2j9fIrWP84wbncucet9Ak2d+Q5RHs131W+j6jdheX/pS+f+VnYu0fq9SfYfX/qS59Jl6ccZWj/eTBf851bv7D/Aye+8bkCudnBe9WXj83DgMqXUxUA00Ewp9b7W+gaLbQYDc81zxCQAFyulKrTW832YztAcJCY8p7YGZnu/D1cfry9frvksQpLP2hi01o9ordtrrZOB64DFNkEBrXWK1jrZvM1nwB0+DwogdZueFkoNolV80ZDsDpuG+vzUB+w31AtRC3/0SrKilLpdKXW7v9NhRXo2eFag9/JyJ3D5oiHZHbWt+SyEk/wSGLTW2drc8Ky1nq21nm1nm6naH2MYhOcFei8vVwOXs91n3eFu6arqdZYXNQU5dNgzTy5qhMv8XmIQDUSgVr2A64GrvlWNtZ383S1dOXhdcWxX59IkhAUJDMI3ArXqpYorgau+VY21nfzdLV05eF1D66YqPEMCg/A+b1a9eIovA1ddJ393S1eBXCoTQUUCg/C+QO/l5Y/AVdtJ3N0gFeilMhE0ZHZV4X2BPiusP9awcDQpoLtjaBy8rnolMyFcICUGIXzdPbm2Eoq7pSsHr4st3uGdPNQlFMeuNCBSYhDC12o7+btbunLwur27TXSpX2rd48qqeyLgSGAQwtcCvWrNE/b/UrM4UdW0Ien3yboIQUKqkoTwJV9UsQRCNU7SQFj2InQdazSwdx1r3A+U0e6iVhIYhPAlX0wPEghTkKRkGCWEvE+g4wXGbfp9UloIElKVJIQv1TYzqxfeI7nVGFj9o++nICnIMUoIaddA3seQdq1xv22aBIcgICUGIXzNFwPRzO+RvPsT/wx2q2pj2PGD0SV3xw81bQwi4ElgEMLXfDEQzfweuzpd45/BblVtDJZdcqWNIWhIYBDCl3wxytriPXalTPbPFCSBPtpd1EoCgxC+5IsTZiCclGVNk6Amjc9C+JIvxjDU9h5VU3vbzs3kaHCdaJCkxCBEQxIIXVlFwJMSgxANiS+6y4qgJyUGIRoaWbdB1EECgxANjazbIOoggUGIhiQYVtMTfieBQYiGJBC6soqAJ43PQjQkDWHKb1FvUmIQQghhRQKDEEIIKxIYhBBCWJHAIIQQwooEBiGEEFaU1trfaagXpdQRYLcbL00Ajno4OcFA8t2wSL4bFlfy3Ulr3creE0EfGNyllMrVWg/2dzp8TfLdsEi+GxZP5VuqkoQQQliRwCCEEMJKQw4Mr/s7AX4i+W5YJN8Ni0fy3WDbGIQQQtjXkEsMQggh7JDAIIQQwkpIBwal1Hil1Fal1A6l1MN2nldKqVfMz+cppUJi4Vsn8j3ZnN88pdRypVQ/f6TT0+rKt8V25ymlKpVSV/kyfd7iTL6VUplKqXVKqU1KqSW+TqM3OPE7b66UWqCUWm/O9+/8kU5PU0r9Ryl1WCm10cHz9T+vaa1D8g8IB34FOgNRwHog1Wabi4FvAQUMBVb5O90+yvcwoIX5//9pKPm22G4x8F/gKn+n20ffdxyQD3Q032/t73T7KN9/Bp43/98KOA5E+TvtHsh7BjAQ2Ojg+Xqf10K5xHA+sENrvVNrfRaYC1xus83lwLvasBKIU0q19XVCPazOfGutl2utC813VwLtfZxGb3Dm+wa4E/gcOOzLxHmRM/m+Hpintd4DoLUOhbw7k28NxCqlFNAUIzBU+DaZnqe1zsHIiyP1Pq+FcmBIAvZa3N9nfszVbYKNq3m6BePqItjVmW+lVBIwEZjtw3R5mzPfd3eghVIqWym1Rik1xWep8x5n8v0q0As4AGwA7tZam3yTPL+q93ktlFdwU3Yes+2b68w2wcbpPCmlRmEEhnSvpsg3nMn3LOAhrXWlcREZEpzJdwQwCBgDxAArlFIrtdbbvJ04L3Im3xcB64DRQBfge6XUUq31SS+nzd/qfV4L5cCwD+hgcb89xpWDq9sEG6fypJRKA94E/kdrfcxHafMmZ/I9GJhrDgoJwMVKqQqt9XyfpNA7nP2dH9ValwKlSqkcoB8QzIHBmXz/DvibNiredyilCoCewGrfJNFv6n1eC+WqpJ+BbkqpFKVUFHAd8JXNNl8BU8yt+EOBIq31QV8n1MPqzLdSqiMwD7gxyK8aLdWZb611itY6WWudDHwG3BHkQQGc+51/CYxQSkUopRoDQ4DNPk6npzmT7z0YpSSUUolAD2CnT1PpH/U+r4VsiUFrXaGUmg58h9GD4T9a601KqdvNz8/G6JlyMbADOIVxhRHUnMz3X4F44F/mq+cKHeQzUTqZ75DjTL611puVUguBPMAEvKm1ttvVMVg4+X0/DcxRSm3AqF55SGsd9FNxK6U+AjKBBKXUPuBxIBI8d16TKTGEEEJYCeWqJCGEEG6QwCCEEMKKBAYhhBBWJDAIIYSwIoFBCCGEFQkMQgghrEhgEEIIYUUCgxBCCCsSGITwIKVUK6XUQaXUXy0eS1NKlYXKwkAi9MnIZyE8TCl1EbAAGIkxu2cusFprHfRTroiGQQKDEF6glJoFXAYsAUYA/bXWJX5NlBBOksAghBcopRphLDfZDRimtV7l5yQJ4TRpYxDCO5Ix5sTXGOsSCxE0pMQghIcppSKBFcB2YBXwBJBWteayEIFOAoMQHqaU+htwPZAGFGGsqR0DjGogaw6LICdVSUJ4kFJqJPAnYIrW+oR5WcmpGIvSP+TPtAnhLCkxCCGEsCIlBiGEEFYkMAghhLAigUEIIYQVCQxCCCGsSGAQQghhRQKDEEIIKxIYhBBCWJHAIIQQwsr/A3BzkUKi9MYsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Reset PN sequence generator.\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Números de amostras.\n",
    "N = 100\n",
    "\n",
    "# Dados\n",
    "x = np.sort(np.random.rand(N, 1), axis=0)\n",
    "w = np.random.randn(N, 1)\n",
    "y = 2.5*x**5 - 1.7*x**3 + 4.6\n",
    "y_noisy = y + 0.1*w\n",
    "\n",
    "# Visualização dos dados\n",
    "plt.plot(x.ravel(), y.ravel(), label='Função original')\n",
    "plt.plot(x.ravel(), y_noisy.ravel(), 'x', label='Função ruidosa')\n",
    "plt.xlabel('x', fontsize=14) \n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.title('Dados', fontsize=14)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fy3zjob9iFL9"
   },
   "source": [
    "**B) Após analisar o gráfico do item anterior, responda. Uma reta teria capacidade/flexibilidade suficiente para gerar um modelo que se aproxime bem dos dados originais? Se sim, justifique. Caso sua resposta seja não, apresente uma possível alternativa.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKtkjAo6iFL9"
   },
   "source": [
    "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3z5U8HRiFL9"
   },
   "source": [
    "**C) Sabe-se que o modelo ideal para esses dados é obtido por meio da regressão linear com polinômio de ordem igual a 5. Suponha que você não saiba da informação anterior e tenha escolhido um polinômio de ordem igual a 40 para treinar o modelo. Qual problema você encontraria? Seu modelo iria sobreajustar ou subajustar? Como esse problema poderia ser mitigado? (Justifique todas as respostas)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNrpgZVViFL9"
   },
   "source": [
    "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAlHAPuDiFL9"
   },
   "source": [
    "**D) Com base em sua resposta do item anterior, treine três modelos:**\n",
    "\n",
    "1. Treine um modelo de regressão polinomial com ordem igual a 5, calcule o erro quadrático médio e compare as funções original, ruidosa e aproximada:\n",
    " - Inclua o bias ao instanciar a classe `PolynomialFeatures` utilizando o parâmetro `include_bias=True`.\n",
    " - Padronize os dados com o uso da classe `StandardScaler`.\n",
    " - Como sempre, use um **pipeline** para sequencializar a aplicação das ações. Use um objeto da classe `Pipeline`.\n",
    " - Imprima o erro quadrático médio. O erro deve ser calculado com o **conjunto total de amostras**.\n",
    " - Ao final, plote uma figura que compare as funções original, ruidosa e aproximada.\n",
    " - Observe que o modelo treinado se aproxima bastante da função original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "e5d-Wm-4iFL9",
    "outputId": "0883e9d3-4301-41c6-b177-9211fd379111"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui. (Modelo 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6ACxJJ5iFL-"
   },
   "source": [
    "2. Treine um modelo de regressão polinomial com ordem igual a 40, calcule o erro quadrático médio e compare as funções original, ruidosa e aproximada:\n",
    " - Inclua o bias ao instanciar a classe `PolynomialFeatures` utilizando o parâmetro `include_bias=True`.\n",
    " - Padronize os dados com o uso da classe `StandardScaler`.\n",
    " - Como sempre, use um **pipeline** para sequencializar a aplicação das ações. Use um objeto da classe `Pipeline`.\n",
    " - Imprima o erro quadrático médio. O erro deve ser calculado com o **conjunto total de amostras**.\n",
    " - Ao final, plote uma figura que compare as funções original, ruidosa e aproximada.\n",
    " - Verifique que está ocorrendo o fenômeno mencionado por você no item C deste exercício."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "y4mIzXEriFL-",
    "outputId": "3dc47642-a6f2-4a16-f664-f83fc05b3f3a"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui. (Modelo 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iGnwheViFL-"
   },
   "source": [
    "3. Encontre o valor ótimo do **fator de regularização**, $\\lambda$, para um modelo de regressão polinomial com regularização L2, ou seja, **regressão Ridge**, com ordem igual a 40. Ao final, imprima o valor ótimo encontrado para o **fator de regularização**.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Você precisará encontrar o valor ótimo do **fator de regularização**, $\\lambda$.\n",
    "+ Para isso, use um objeto da classe `RidgeCV` passando para o parâmetro de entrada `alphas` (que aqui é o fator de regularização) um sequência de 1000 valores retirados de um intervalo logarítmico entre -1 e 2. Veja o exemplo abaixo:\n",
    "```python\n",
    "np.logspace(-1,2,M)\n",
    "```\n",
    "+ Para mais informações sobre a classe `RidgeCV`, acesse sua documentação através do seguinte link: [Documentação RidgeCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html?highlight=ridgecv#sklearn.linear_model.RidgeCV).\n",
    "+ Inclua o atributo de bias ao instanciar a classe `PolynomialFeatures` utilizando o parâmetro `include_bias=True`.\n",
    "+ Padronize os dados com o uso da classe `StandardScaler`.\n",
    "+ Como sempre, use um pipeline para sequencializar a aplicação das ações. Use um objeto da classe `Pipeline`.\n",
    "+ Após o treinamento do objeto da classe `RidgeCV`, o valor ótimo do **fator de regularização** pode ser acessado como mostrado abaixo. No exemplo abaixo, o objeto da classe `Pipeline` se chama `clf` e o nome dado ao objeto da classe `RidgeCV` é `reg`.\n",
    "```python\n",
    "clf['reg'].alpha_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PY3Mt4cmiFL_",
    "outputId": "18afd211-bf5a-462a-e9d3-513e4e693e62"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNfRgwDkiFL_"
   },
   "source": [
    "4. De posse do valor ótimo do **fator de regularização**, treine um modelo de regressão polinomial com ordem igual a 40 e:\n",
    "\n",
    " - Utilize regularização L2 (use a classe `Ridge`) para aproximar o modelo 1.\n",
    " - Instancie um objeto da classe `Ridge` com o valor ótimo do **fator de regularização** encontrado no item anterior.\n",
    " - Inclua o atributo de bias ao instanciar a classe `PolynomialFeatures` utilizando o parâmetro `include_bias=True`.\n",
    " - Padronize os dados com o uso da classe `StandardScaler`.\n",
    " - Como sempre, use um pipeline para sequencializar a aplicação das ações. Use um objeto da classe `Pipeline`.\n",
    " - Imprima o erro quadrático médio. O erro deve ser calculado com o conjunto total de amostras.\n",
    " - Ao final, plote uma figura que compare as funções original, ruidosa e aproximada.\n",
    " - Analise o resultado mostrado na figura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "xmJDaQTjiFL_",
    "outputId": "e32144c9-739b-459b-c5eb-0e90744ea12d"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui. (Modelo 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06uoTcGGiFL_"
   },
   "source": [
    "**E) Plote as funções original, ruidosa e as aproximações obtidas com os modelos 1, 2 e 3.**\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Use cores diferentes para cada função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "_D-0ntsiiFL_",
    "outputId": "9c5cbd45-fb74-4cca-8a09-370a809c11a0"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_33SAMnNiFL_"
   },
   "source": [
    "**F) Após analisar a figura do item anterior, responda: o modelo 3 (modelo utilizando regressão Ridge) se aproximou do modelo ideal (modelo com a mesma complexidade da função original), ou seja, do modelo 1? (Justifique sua resposta).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U22EnS3KiFMA"
   },
   "source": [
    "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRiUgM4-iFMA"
   },
   "source": [
    "### 4) Escolha do passo de aprendizagem.\n",
    "\n",
    "A biblioteca SciKit-Learn disponibiliza alguns conjuntos de dados que podemos usar para o treinamento de modelos. Um desses conjuntos é o [Iris flower data set](https://scikit-learn.org/stable/datasets/toy_dataset.html) que contém informações sobre 3 tipos de flores, são elas Iris-Setosa, Iris-Versicolour e Iris-Virginica. Existem 50 exemplos de cada tipo de flor em que temos identificado o comprimento e a largura da sépala, o comprimento e a largura da pétala. Suponha que seja necessário prever a largura da pétala com o uso de um modelo de regressão linear a partir das medidas da sépala, ou seja, comprimento e largura. Encontre um modelo através da equação normal e outro através do algoritmo do **gradiente descendente estocástico** e ao final compare os resultados.\n",
    "\n",
    "**A) Execute a célula abaixo para definir algumas funções necessárias para o treinamento.**\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Veja que a função `gradientDescent` utiliza **decaimento temporal** do passo de aprendizagem para tornar o aprendizado do algoritmo mais comportado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hT9wuckGiFMA"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# learning schedule: Temporal decay.\n",
    "def timeBasedDecay(alpha_init, k, t):\n",
    "    '''Temporal decay.'''\n",
    "    return alpha_init / (1.0 + k*t)\n",
    "\n",
    "# learning schedule: Exponential decay.\n",
    "def exponentialDecay(alpha_init, k, t):\n",
    "    '''Exponential decay.'''\n",
    "    return alpha_init * np.exp(-k*t)\n",
    "\n",
    "# learning schedule: Gradual decay.\n",
    "def stepDecay(alpha_init, t, epochs_drop=8.0):\n",
    "    '''Gradual decay.'''\n",
    "    drop = 0.5\n",
    "    alpha = alpha_init * math.pow(drop, math.floor((1+t)/epochs_drop))\n",
    "    return alpha\n",
    "\n",
    "def learning_schedule(typels, alpha_init, k, t):\n",
    "    '''Funtion used to choose among some learning schedules'''\n",
    "    if(typels=='exp'):\n",
    "        alpha = exponentialDecay(alpha_init, k, t)\n",
    "    elif(typels=='time'):\n",
    "        alpha = timeBasedDecay(alpha_init, k, t)\n",
    "    elif(typels=='step'):\n",
    "        alpha = stepDecay(alpha_init, t)\n",
    "    else:\n",
    "        alpha = alpha_init\n",
    "    return alpha\n",
    "\n",
    "def gradientDescent(X, y_noisy, n_epochs, alpha_init, k):\n",
    "    '''\n",
    "    Function implementing the stochastic version of the gradient descent.\n",
    "    Os parâmetros de entrada da função são:\n",
    "    * X          - Matriz de atributos\n",
    "    * y          - vetor de rótulos\n",
    "    * n_epochs   - número de épocas\n",
    "    * alpha_init - valor inicial do passo de aprendizagem\n",
    "    * k          - taxa de decaimento\n",
    "    '''\n",
    "\n",
    "    # Number of examples.\n",
    "    N = len(y_noisy)\n",
    "    \n",
    "    # Reshape y to be a column vector.\n",
    "    y_noisy = y_noisy.reshape(N,1)\n",
    "    \n",
    "    # Initialization of parameters.\n",
    "    a = np.array([-10.0, -10.0]).reshape(2, 1)\n",
    "\n",
    "    # Create vector for parameter history.\n",
    "    a_hist = np.zeros((2, n_epochs*N+1))\n",
    "    # Initialize history vector.\n",
    "    a_hist[:, 0] = a.reshape(2,)\n",
    "\n",
    "    # Create vector to store eta history.\n",
    "    alpha_hist = np.zeros((n_epochs*N))\n",
    "\n",
    "    update_prev = np.zeros((2, 1))\n",
    "\n",
    "    # Create array for storing error values.\n",
    "    Jgd = np.zeros(n_epochs*N+1)\n",
    "\n",
    "    Jgd[0] = (1.0/N)*sum(np.power(y_noisy - X.dot(a), 2))\n",
    "\n",
    "    update_hist = np.zeros((2, n_epochs*N))\n",
    "\n",
    "    gradient_hist = np.zeros((2, n_epochs*N))\n",
    "\n",
    "    # Stocastic gradient-descent loop.\n",
    "    iteration = 0\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # Shuffle the whole dataset before every epoch.\n",
    "        shuffled_data_set_indexes = random.sample(range(0, N), N)    \n",
    "\n",
    "        for i in range(N):\n",
    "            random_index = shuffled_data_set_indexes[i]\n",
    "            xi = X[random_index:random_index+1]\n",
    "            yi = y_noisy[random_index:random_index+1]\n",
    "\n",
    "            # Decaimento temporal do passo de aprendizagem.\n",
    "            alpha = learning_schedule('time', alpha_init, k, epoch*N + i)\n",
    "\n",
    "            gradient = -2.0*xi.T.dot(yi - xi.dot(a))\n",
    "            update = alpha*gradient\n",
    "            a = a - update\n",
    "\n",
    "            a_hist[:, epoch*N+i+1] = a.reshape(2,)\n",
    "            alpha_hist[epoch*N+i] = alpha\n",
    "            update_hist[:, epoch*N+i] = update.reshape(2,)\n",
    "            gradient_hist[:, epoch*N+i] = gradient.reshape(2,)\n",
    "\n",
    "            Jgd[epoch*N+i+1] = (1.0/N)*sum(np.power((y_noisy - X.dot(a)), 2))\n",
    "            \n",
    "            iteration = epoch*N+i\n",
    "            \n",
    "    return a, Jgd, a_hist, alpha_hist, update_hist, gradient_hist, iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mky0xdmiFMA"
   },
   "source": [
    "**B) Execute a célula abaixo para importar os dados do conjunto e as bibliotecas necessárias**\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ A célula imprimirá as dimensões da matriz de atributos e do vetor de rótulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8pPIfBiiFMA",
    "outputId": "e1cd992c-6e6f-4d83-8bb2-f29f4e564047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão da matriz de atributos: (150, 2)\n",
      "Dimensão do vetor de rótulos: (150,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Importando os dados.\n",
    "x = load_iris()['data']\n",
    "\n",
    "# Features/atributos.\n",
    "X = np.c_[x[:, 0], x[:, 1]]\n",
    "# Labels/rótulos.\n",
    "y = x[:, 3]\n",
    "\n",
    "# Imprimindo as dimensões dos dados.\n",
    "print('Dimensão da matriz de atributos:', X.shape)\n",
    "print('Dimensão do vetor de rótulos:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5mVOZICiFMA"
   },
   "source": [
    "**C) Treine um modelo por meio da equação normal. Ao final, imprima o erro quadrático médio obtido pelo modelo para todo o conjunto de exemplos.**\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Você pode utilizar a classe `LinearRegression` da biblioteca SciKit-Learn para resolver este item ou implementar a equação normal manualmente.\n",
    "+ Use a função `mean_squared_error` da biblioteca SciKit-Learn para calcular o erro quadrático médio.\n",
    "+ O erro quadrático médio deve ser calculado para todo o conjunto de exemplos, ou seja, para as 150 amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3FbCl31DiFMB",
    "outputId": "1d24b2a3-efbe-4957-c596-8c4c9de2f2b7"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-L3lvfmiFMB"
   },
   "source": [
    "**D) Treine o modelo com o uso da técnica do gradiente descendente estocástico com decaimento temporal do passo de aprendizagem. Siga os seguintes passos:**\n",
    "\n",
    "1. Normalize os atributos com o uso da classe `StandardScaler`.\n",
    "2. Treine o modelo usando a função `gradientDescent` para os seguintes valores de **passo de aprendizagem**: 0.1, 0.03, 0.01, 0.003, e 0.001.\n",
    "3. Para cada valor do **passo de aprendizagem** armazene o vetor de erros ao longo das iterações, `Jgd`, o qual é retornado pela função `gradientDescent`.\n",
    "4. Após o treinamento do modelo para cada valor do **passo de aprendizagem**, plote uma **única figura** que mostre os valores de erro, `Jgd`, ao longo das iterações, para cada um dos 5 valores do **passo de aprendizagem**.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Os atributos são padronizados com o método `fit_transform` da classe `StandardScaler`.\n",
    "+ Os parâmetros de entrada da função `gradientDescent` são descritos em seu cabeçalho. Veja a definição da função.\n",
    "+ Configure a **taxa de decaimento**, `k` com o valor `0.001`.\n",
    "+ Configure o **número de épocas**, `n_epochs`, com o valor `2`, ou seja, cada modelo será treinado por 2 épocas.\n",
    "+ Use escala logarítmica para eixo y da figura. Para isso, use o comando abaixo.\n",
    "```python\n",
    "plt.yscale('log')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "QGkLVfmniFMB",
    "outputId": "d67d0c72-4b58-4546-cf55-3088e66a10be"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsIXZUFbiFMB"
   },
   "source": [
    "**E) Analise a figura acima e escolha o passo de aprendizagem ideal. De posse do passo de aprendizagem ideal, treine novamente o modelo com este valor e imprima o erro quadrático médio obtido.**\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Os atributos devem ser padronizados com o método `fit_transform` da classe `StandardScaler`.\n",
    "+ Os parâmetros de entrada da função `gradientDescent` são descritos em seu cabeçalho. Veja a definição da função.\n",
    "+ Configure a **taxa de decaimento**, `k` com o valor `0.001`.\n",
    "+ Configure o **número de épocas**, `n_epochs`, com o valor `2`, ou seja, cada modelo será treinado por 2 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78herNBFiFMB",
    "outputId": "19a543df-9fee-49f9-8dc3-5793357bfa98"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOyUJXsHiFMB"
   },
   "source": [
    "**F) Qual foi o valor do passo de aprendizagem escolhido? Justifique sua resposta.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQBjyawJiFMB"
   },
   "source": [
    "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4iLzwy-FiFMC"
   },
   "source": [
    "**G) Compare o desempenho final do modelo utilizando a equação normal e com o gradiente descendente estocástico com o melhor valor para o passo de aprendizagem. Se houve diferença, explique quais foram e as justifique.**\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Compare os valores do erro quadrático médio obtido por cada um dos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxdWdxl3iFMC"
   },
   "source": [
    "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "projeto_final_2S2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
