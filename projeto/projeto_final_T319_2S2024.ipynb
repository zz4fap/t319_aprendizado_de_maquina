{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da867ff1",
   "metadata": {},
   "source": [
    "# Projeto Final - T319 (2S2024)\n",
    "\n",
    "### Instruções\n",
    "\n",
    "1. Quando você terminar os exercícios do projeto, vá até o menu do Colab ou Jupyter e selecione a opção para fazer download do notebook.\n",
    "    * Os notebooks tem extensão .ipynb. \n",
    "    * Este deve ser o arquivo que você irá entregar.\n",
    "    * No Colab vá até a opção **File** -> **Download .ipynb**.\n",
    "    * No Jupyter vá até a opção **File** -> **Download as** -> **Notebook (.ipynb)**.\n",
    "2. Após o download do notebook, vá até a aba de tarefas do MS Teams, localize a tarefa referente a este projeto e faça o upload do seu notebook. Veja que há uma opção para anexar arquivos à tarefa.\n",
    "3. Atente-se ao prazo de entrega definido na tarefa do MS Teams. Entregas fora do prazo não serão consideradas.\n",
    "4. **O projeto pode ser resolvido em grupos de no MÁXIMO 3 alunos**.\n",
    "5. Todas as questões têm o mesmo peso.\n",
    "6. Questões copiadas de outros grupos serão anuladas em todos os grupos com a mesma resposta.\n",
    "7. Não se esqueça de colocar seu(s) nome(s) e número(s) de matrícula no campo abaixo. Coloque os nomes dos integrantes do grupo no campo de texto abaixo.\n",
    "8. Você pode consultar todo o material de aula e laboratórios.\n",
    "9. A interpretação faz parte do projeto. Leia o enunciado de cada questão atentamente!\n",
    "10. Boa sorte!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587a29e",
   "metadata": {},
   "source": [
    "**Nomes e matrículas**:\n",
    "\n",
    "1. Nome do primeiro aluno - Matrícula do primeiro aluno\n",
    "2. Nome do segundo aluno - Matrícula do segundo aluno\n",
    "3. Nome do terceiro aluno - Matrícula do terceiro aluno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972fea32",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557c0a17",
   "metadata": {},
   "source": [
    "### 1) Exercício sobre a escolha do passo de aprendizagem\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466c47e",
   "metadata": {},
   "source": [
    "1. Execute a célula de código abaixo para importar as bibliotecas necessárias e definir algumas funções necessárias para o treinamento de um modelo de regressão linear.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ A função `gradientDescent` implementa a versão **estocástica** do gradiente descendente.\n",
    "+ Note que a função `gradientDescent` utiliza **decaimento temporal** do passo de aprendizagem para tornar o aprendizado do algoritmo mais comportado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries.\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reseta os gerados de sequências pseudo-aleatórias.\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "def calculateErrorSurface(x, y):\n",
    "    \"\"\"Generate data points for plotting the error surface.\"\"\"\n",
    "\n",
    "    # Retrieve number of examples.\n",
    "    N = len(y)\n",
    "\n",
    "    # Generate values for parameter space.\n",
    "    M = 200\n",
    "    a0 = np.linspace(-3.025, -2.975, M)\n",
    "    a1 = np.linspace(-2.025, -1.975, M)\n",
    "\n",
    "    # Generate matrices with combinations between a0 and a1 values.\n",
    "    A0, A1 = np.meshgrid(a0, a1)\n",
    "\n",
    "    # Generate points for plotting the cost-function surface.\n",
    "    J = np.zeros((M,M))\n",
    "    for iter1 in range(0, M):\n",
    "        for iter2 in range(0, M):\n",
    "            # Hypothesis function (a second degree function).\n",
    "            yhat = A0[iter1, iter2] + A1[iter1, iter2]*x**2\n",
    "            # Calculate the mean squared error (MSE) for each pair of values.\n",
    "            J[iter1, iter2] = (1.0/N)*np.sum(np.square(y - yhat))\n",
    "\n",
    "    return J, A0, A1\n",
    "\n",
    "def timeBasedDecay(alpha_init, k, t):\n",
    "    '''Decaimento temporal.'''\n",
    "    return alpha_init / (1.0 + k*t)\n",
    "\n",
    "def gradientDescent(X, y, n_epochs, alpha_init, k):\n",
    "    '''\n",
    "    Função que implementa a versão estocástica do gradiente descendente.\n",
    "    Os parâmetros de entrada da função são:\n",
    "    * X          - Matriz de atributos\n",
    "    * y          - vetor de rótulos\n",
    "    * n_epochs   - número máximo de épocas de treinamento\n",
    "    * alpha_init - valor inicial do passo de aprendizagem\n",
    "    * k          - taxa de decaimento da redução temporal do passo de aprendizagem\n",
    "    '''\n",
    "\n",
    "    # Number of examples.\n",
    "    N = len(y)\n",
    "    \n",
    "    # Reshape y to be a column vector.\n",
    "    y = y.reshape(N,1)\n",
    "    \n",
    "    # Inicialização do vetor de pesos.\n",
    "    a = np.array([-5.0, -4.0]).reshape(2, 1)\n",
    "\n",
    "    # Create vector for parameter history.\n",
    "    a_hist = np.zeros((2, n_epochs*N+1))\n",
    "    # Initialize history vector.\n",
    "    a_hist[:, 0] = a.reshape(2,)\n",
    "\n",
    "    # Create vector to store eta history.\n",
    "    alpha_hist = np.zeros((n_epochs*N))\n",
    "\n",
    "    # Create array for storing error values.\n",
    "    Jgd = np.zeros(n_epochs*N+1)\n",
    "\n",
    "    # Calcule o MSE para o primeiro conjunto de pesos.\n",
    "    Jgd[0] = (1.0/N)*np.sum(np.power(y - X.dot(a), 2))\n",
    "\n",
    "    # Cria arrays para armazenar vetores de atualização e gradiente.\n",
    "    update_hist = np.zeros((2, n_epochs*N))\n",
    "    gradient_hist = np.zeros((2, n_epochs*N))\n",
    "\n",
    "    # Stocastic gradient-descent loop.\n",
    "    iteration = 0\n",
    "    # Época de treinamento, apresenta todas os exemplos de treinamento ao modelo.\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # Shuffle the whole dataset before every epoch.\n",
    "        shuffled_data_set_indexes = random.sample(range(0, N), N)    \n",
    "\n",
    "        # Iteração de treinamento, apenas um exemplo é apresentado ao modelo.\n",
    "        for i in range(N):\n",
    "            # Retrieve one pair of atribute vector and label.\n",
    "            random_index = shuffled_data_set_indexes[i]\n",
    "            xi = X[random_index:random_index+1]\n",
    "            yi = y[random_index:random_index+1]\n",
    "\n",
    "            # Decaimento temporal do passo de aprendizagem.\n",
    "            alpha = timeBasedDecay(alpha_init, k, epoch*N + i)\n",
    "\n",
    "            # Cálculo da estimativa do vetor gradiente com apenas uma amostra.\n",
    "            gradient = -2.0*xi.T.dot(yi - xi.dot(a))\n",
    "            update = alpha*gradient\n",
    "            a = a - update\n",
    "\n",
    "            # Armazena o histórico de valores.\n",
    "            a_hist[:, epoch*N+i+1] = a.reshape(2,)\n",
    "            alpha_hist[epoch*N+i] = alpha\n",
    "            update_hist[:, epoch*N+i] = update.reshape(2,)\n",
    "            gradient_hist[:, epoch*N+i] = gradient.reshape(2,)\n",
    "\n",
    "            # Calcula o MSE por itereção de treinamento.\n",
    "            Jgd[epoch*N+i+1] = (1.0/N)*np.sum(np.power((y - X.dot(a)), 2))\n",
    "            \n",
    "            # Incrementa o contador de iterações.\n",
    "            iteration = epoch*N+i\n",
    "            \n",
    "    return a, Jgd, a_hist, alpha_hist, update_hist, gradient_hist, iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a63858",
   "metadata": {},
   "source": [
    "2. Execute a célula de código abaixo para criar o conjunto de dados que será usado neste exercício.\n",
    "\n",
    "+ A função objetivo utilizada neste exercício é dada por \n",
    "$$y = -3 + -2x^2,$$\n",
    "onde $a_0=-3$ e $a_1=-2$.\n",
    "\n",
    "+ A função hipótese que utilizaremos tem o mesmo formato da função objetivo, \n",
    "$$\\hat{y} = \\hat{a}_0 + \\hat{a}_1 x^2,$$\n",
    "sendo o objetivo do algoritmo do gradiente descendente estocástico encontrar aproximações, $\\hat{a}_0$ e $\\hat{a}_1$, para os valores de ${a}_0$ e ${a}_1$.\n",
    "+ Para representarmos a função hipótese em formato matricial, i.e., $\\textbf{y} = \\textbf{X}\\textbf{a}$, precisamos criar a matriz de atributos concatenando os vetores de atributos de *bias* (i.e., vetor com valores iguais a 1) e $x^2$.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Na célula de código abaixo, o vetor do atributo de *bias* é concatenado ao vetor de atributo, $x^2$, formando a matriz de atributos, $\\textbf{X}$.\n",
    "+ Essa concatenação é feita de forma manual, pois a implementação da versão estocática do gradiente descendente fornecida acima não faz isso automaticamente como no caso das classes fornecidas pela bilbioteca SciKit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ea057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de amostras\n",
    "N = 1000\n",
    "\n",
    "# Vetor de atributos.\n",
    "x = np.linspace(-1, 1, N).reshape(N, 1)\n",
    "\n",
    "# Função objetivo.\n",
    "y = -3 + -2*x**2\n",
    "\n",
    "# Ruído.\n",
    "w = np.sqrt(0.01)*np.random.randn(N, 1)\n",
    "\n",
    "# Função observável.\n",
    "y_noisy = y + w\n",
    "\n",
    "# Cria matriz de atributos.\n",
    "X = np.c_[np.ones((N, 1)), x**2]\n",
    "\n",
    "# Figura comparando as duas funções.\n",
    "plt.plot(x, y_noisy, label='Função observável')\n",
    "plt.plot(x, y, label='Função objetivo')\n",
    "plt.xlabel('x', fontsize=14)\n",
    "plt.ylabel('y', fontsize=14)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3b7310",
   "metadata": {},
   "source": [
    "3. Analise a geração das amostras da função observável no item anterior, qual é o menor erro (i.e., erro quadrático médio - EQM) possível com um regressor linear treinado com essas amostras?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac38904d",
   "metadata": {},
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f2a708",
   "metadata": {},
   "source": [
    "4. Divida o conjunto total de amostras em conjuntos de treinamento e validação. O conjunto de treinamento deve conter 75% do total de amostras e o conjunto de validação os 25% restantes.\n",
    "\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Use a função `train_test_split` e a configure com os seguintes parâmetros `test_size=0.25` e `random_state=seed`. A função divide o conjunto original de amostras em dois subconjuntos, um para treinamento e outro para validação (i.e., para avaliar a capacidade de generalização do modelo). Veja o código abaixo.\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_noisy, test_size=0.25, random_state=seed)\n",
    "```\n",
    "+ Para que o próximo item do exercício funcione, chame as matrizes de treinamento e de validação de `X_train` e `X_test`, respectivamente, e os vetores de rótulos de treinamento e de validação de `y_train` e `y_test`, respectivamente, como no exemplo acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6148b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2611f0a",
   "metadata": {},
   "source": [
    "5. Execute a célula de código abaixo e analise as figuras.\n",
    "\n",
    "A célula abaixo treina o modelo de regressão usando a função `gradientDescent` com os seguintes valores: \n",
    "+ **taxa de decaimento ($k$)**: 0.1, 0.01, e 0.001.\n",
    "+ **passo de aprendizagem ($\\alpha$)**: 0.1, 0.03, 0.01, 0.003, e 0.001.\n",
    "\n",
    "Cada figura mostra o erro de treinamento em função das iterações de treinamento para um valor específico da taxa de decaimento ($k$) e vários valores para o passo de aprendizagem ($\\alpha$). O valor de taxa de decaimento ($k$) é mostrado no título (i.e., topo) da figura, enquanto os diferentes valores de passo de aprendizagem ($\\alpha$) são mostrados com cores diferentes na legenda de cada figura.\n",
    "\n",
    "**DICA**:\n",
    "\n",
    "+ Lembrem-se que o menor valor do EQM tende ao valor da variância do ruído adicionado às amostras da função objetivo quando encontra-se os valores ótimos dos pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ee9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de épocas.\n",
    "n_epochs = 2\n",
    "# Lista de taxas de decaimento.\n",
    "k_list = [0.1, 0.01, 0.001]\n",
    "# Lista de passos de aprendizagem.\n",
    "alpha_list = [0.1, 0.03, 0.01, 0.003, 0.001]\n",
    "\n",
    "# Lista para armazenar os erros das combinações de taxa de decaimento e passo de aprendizagem.\n",
    "error = []\n",
    "for k in k_list:\n",
    "    error_hist = []\n",
    "    for alpha in alpha_list:\n",
    "        a, Jgd, a_hist, alpha_hist, update_hist, gradient_hist, iteration = gradientDescent(X_train, y_train, n_epochs, alpha_init=alpha, k=k)\n",
    "        error_hist.append(Jgd)\n",
    "    error.append(error_hist)\n",
    "\n",
    "# Visualização do erro durante o treinamento de cada passo de aprendizagem.\n",
    "plt.figure(figsize=(15,5))\n",
    "for i in range(len(k_list)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title('k = '+str(k_list[i]))\n",
    "    for j in range(len(alpha_list)):\n",
    "        plt.plot(np.arange(error[i][j].shape[0]), error[i][j], label=('alpha = '+f'{alpha_list[j]}'))\n",
    "        plt.yscale('log')\n",
    "    plt.xlabel('Iterações')\n",
    "    plt.ylabel('EQM')\n",
    "    plt.legend()\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.ylim([0.008, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd1148",
   "metadata": {},
   "source": [
    "6. Analise as figuras do item anterior e responda: Quais são os valores ideais para a taxa de decaimento ($k$) e o passo de aprendizagem ($\\alpha$)? (**Justifique sua resposta**).\n",
    "\n",
    "**DICA**\n",
    "\n",
    "+ A ideia é que o aprendizado seja rápido, ou seja, convirja rapidamente (erro praticamente constante), mas sem muita oscilação no erro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a65678d",
   "metadata": {},
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1c0757",
   "metadata": {},
   "source": [
    "7. De posse dos valores ideais para a taxa de decaimento ($k$) e passo de aprendizagem ($\\alpha$), treine novamente o modelo com estes valores e imprima os erros quadráticos médios (EQMs) obtidos para os conjuntos de treinamento de validação e o valor dos pesos $\\hat{a}_0$ e $\\hat{a}_1$.\n",
    " \n",
    "**DICAS**\n",
    "\n",
    "+ Configure a função `gradientDescent` com os melhores valores para a taxa de decaimento ($k$) e passo de aprendizagem ($\\alpha$) obtidos no item anterior.\n",
    "+ Os parâmetros de entrada da função `gradientDescent` são descritos em seu cabeçalho. Veja a definição da função.\n",
    "+ Treine o modelo com o conjunto de treinamento.\n",
    "+ Configure o **número de épocas**, `n_epochs`, com o valor `2`, ou seja, o modelo será treinado por 2 épocas.\n",
    "+ Lembre-se que a função hipótese é expressa no formato vetorial como $\\hat{\\textbf{y}}=\\textbf{X}\\textbf{a}$, onde $\\textbf{X}$ é a matriz de atributos e $\\textbf{a}$ é o vetor de pesos. Portanto, para fazer predições com as matrizes de atributos de treinamento e validação, você precisa utilizar a função hipótese no formato vetorial.\n",
    "+ Você pode usar a função `mean_squared_error` da biblioteca SciKit-Learn para calcular o EQM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc59d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a4c5cb",
   "metadata": {},
   "source": [
    "8. Treine um modelo usando a **equação normal** (i.e., a equação que dá a solução ótima para o conjunto de treinamento fornecido). Ao final, imprima o erro quadrático médio (EQM) obtido pelo modelo para os conjuntos de treinamento e validação. Além disso, imprima o valor dos pesos $\\hat{a}_0$ e $\\hat{a}_1$ obtidos com a **equação normal**.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Você pode utilizar a classe `LinearRegression` da biblioteca SciKit-Learn para resolver este item ou implementar a equação normal manualmente.\n",
    "+ Caso você use a classe `LinearRegression`, a configure com o parâmetro `fit_intercept=False`, pois a matriz de atributos criada no item 2 do exercício, já contém a coluna do atributos de bias, ou seja, a coluna com todos os valores iguais a 1.\n",
    "+ Usando a classe `LinearRegression`:\n",
    "  * A predição é feita com o método `predict()`.\n",
    "  * Os pesos do modelo podem ser acessados através do atributo `coef_` da classe `LinearRegression`. Por exemplo, dado que o nome do objeto da classe `LinearRegression` é `reg`, então `reg.coef_[0,0]` acessa o valor ótimo encontrado para o peso $\\hat{a}_0$ e `reg.coef_[0,1]` acessa o valor ótimo encontrado para o peso $\\hat{a}_1$.\n",
    "+ Você pode usar a função `mean_squared_error` da biblioteca SciKit-Learn para calcular o EQM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e570e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2200d2c2",
   "metadata": {},
   "source": [
    "9. Compare os pesos ($\\hat{a}_0$ e $\\hat{a}_1$) e os erros, i.e., EQMs, (para os conjuntos de treinamento e validação) obtidos com os modelos usando a equação normal (item 8) e o gradiente descendente estocástico com os melhores valores para a taxa de decaimento e passo de aprendizagem (item 7).\n",
    "\n",
    "Os valores são diferentes? Se sim, explique o motivo da diferença. (**Justifique sua resposta**).\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Lembre-se que a equação normal dá a solução ótima, ou seja, ela fornece os pesos que minimizam o EQM. Não existem outros pesos que resultem em um EQM menor para o conjunto de treinamento usado.\n",
    "+ As estimativas do vetor gradiente com o gradiente descendente estocástico, mesmo com os melhores valores para a taxa de decaimento e passo de aprendizagem, continuam sendo ruidosas, consequentemente, as atualizações dos pesos também serão ruidosas.\n",
    "+ Além disso, os valores encontrados para a taxa de decaimento e passo de aprendizagem podem não ser os ótimos.\n",
    "+ Reveja o material de aula e os exemplos onde discutimos as versões do gradiente descendente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1637c2",
   "metadata": {},
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b0523",
   "metadata": {},
   "source": [
    "10. Plote a superfície de contorno desta função hipótese e mostre que os pesos encontrados com a equação normal e gradiente descendente são próximos, mas não idênticos.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Use a função `calculateErrorSurface` definida no item 1 deste exercício.\n",
    "+ A função `calculateErrorSurface` restringe o eixo de $\\hat{a}_0$ entre os valores $-3.025$ e $-2.975$.\n",
    "+ A função `calculateErrorSurface` restringe o eixo de $\\hat{a}_1$ entre os valores $-2.025$ e $-1.975$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369d33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e0b3e6",
   "metadata": {},
   "source": [
    "### 2) Exercício sobre validação cruzada\n",
    "\n",
    "Neste exercício, você irá utilizar uma estratégia de **validação cruzada** para encontrar a ordem ideal para uma função hipótese que será usada para aproximar um conjunto de dados ruidosos.\n",
    "\n",
    "A **função observável** deste exercício é gerada utilizando-se a função `generateDataSetv3` do módulo `util_functions_aux`.\n",
    "\n",
    "A **função hipótese** para este exercício é **polinomial** em uma únicavariável, $x$, e tem a seguinte forma\n",
    "\n",
    "$$h(n) = a_0 + a_1 x(n) + a_2 x(n)^2 + \\cdots + a_M x(n)^M,$$\n",
    "\n",
    "onde $n$ é o número da amostra e $M$ a ordem do polinômio.\n",
    "\n",
    "A tarefa aqui é encontrar o valor ideal para $M$, ou seja, a ordem da função hipótese polinomial de tal forma que ela consiga aproximar bem os dados observados.\n",
    "\n",
    "**DICAS**:\n",
    "\n",
    "+ Para gerar os valores de $x$, $y$ e $y_{noisy}$ usaremos a função `generateDataSetv3` passando como parâmetro de entrada o número de matrícula de um dos alunos do grupo e o número de amostras que devem ser geradas (o número de amostras já é definido no item 1).\n",
    "+ Para resolver as questões deste exercício, se baseie no código do seguinte exemplo: [validacao_cruzada.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/master/notebooks/regression/validacao_cruzada.ipynb).\n",
    "+ Todas as funções usadas neste exercício estão definidas no arquivo `util_functions.py`, que se encontra na mesma pasta que este notebook. \n",
    "+ **SOB NENHUMA HIPÓTESE ALTERE O ARQUIVO `util_functions_aux.py`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1710dbc1",
   "metadata": {},
   "source": [
    "1. Execute o trecho de código abaixo e analise os resultados gerados.\n",
    "\n",
    "**DICA**\n",
    "\n",
    "+ Não se esqueça de definir o número de matrícula de qualquer um dos integrantes do grupo na célula abaixo e executá-la a fim de atribuir o valor à variável `groupNumber`.\n",
    "\n",
    "<span style=\"color:red\">Atribua o número de matrícula de qualquer um dos integrantes do grupo à variável abaixo.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67239d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupNumber = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9625cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import urllib\n",
    "urllib.request.urlretrieve('https://raw.githubusercontent.com/zz4fap/t319_aprendizado_de_maquina/main/projeto/util_functions.py', 'util_functions_aux.py')\n",
    "import util_functions_aux as util\n",
    "\n",
    "# Reset PN sequence generator.\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Number of examples.\n",
    "N = 2000\n",
    "\n",
    "# Generate datase.\n",
    "x, y, y_noisy = util.generateDatasetsv3(groupNumber, N)\n",
    "\n",
    "# Plot comparison between true and noisy model.\n",
    "plt.plot(x, y_noisy, '.', label='Função observável')\n",
    "plt.plot(x, y, label='Função objetivo', linewidth=4)\n",
    "plt.xlabel('$x$', fontsize=14)\n",
    "plt.ylabel('$y$', fontsize=14)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e078ec",
   "metadata": {},
   "source": [
    "2. Usando a estratégia de validação cruzada **k-Fold**, encontre a ordem ideal para que uma função hipótese polinomial aproxime bem o conjunto de dados gerado no item anterior. Para avaliar qual é a ordem ideal para o polinômio aproximador, plote gráficos com a média e o desvio padrão do erro quadrático médio (MSE) em função dos graus de polinômio considerados. Para isso:\n",
    "\n",
    "   1. Use o **k-Fold** com **k** igual a 10.\n",
    "   2. Configure o parâmetro `shuffle` da classe `KFold` como `True`, ou seja, `shuffle=True`.\n",
    "   3. Faça a análise de polinômios de ordem 1 até 30, **inclusive**.\n",
    "   4. Desabilite a inclusão da coluna do atributo de bias ao instanciar a classe `PolynomialFeatures` utilizando o parâmetro `include_bias=False`.\n",
    "   5. Use a classe `StandardScaler` para padronizar os atributos.\n",
    "\n",
    "**DICAS** \n",
    "\n",
    "+ Para resolver este item, se baseie no seguinte exemplo: [validacao_cruzada.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/main/notebooks/regression/validacao_cruzada.ipynb).\n",
    "+ **Atenção, não basta apenas copiar o código do exemplo dado, você precisa alterá-lo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6970821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdcb45a",
   "metadata": {},
   "source": [
    "3. Após analisar os resultados obtidos com a validação cruzada **k-Fold**, responda qual é a melhor ordem de polinômio para aproximar os dados. **Justifique sua resposta.**\n",
    "\n",
    "**DICA**\n",
    "\n",
    "* Lembre-se do princípio da navalha de Occam para escolher a melhor ordem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f5fae8",
   "metadata": {},
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10695727",
   "metadata": {},
   "source": [
    "4. De posse da melhor ordem, treine um novo modelo de regressão considerando esta ordem e plote um gráfico que compare a função objetivo com as funções observável (i.e., ruidosa) e hipótese.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Inclua o termo de bias ao instanciar a classe `PolynomialFeatures` utilizando o parâmetro `include_bias=False`.\n",
    "+ Use a classe `StandardScaler` para padronizar os atributos.\n",
    "+ Use o conjunto total de amostras para calcular o erro.\n",
    "+ Para resolver este item, se baseie no seguinte exemplo: [validacao_cruzada.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/main/notebooks/regression/validacao_cruzada.ipynb).\n",
    "+ **Atenção, não basta apenas copiar o código do exemplo dado, você precisa alterá-lo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5562b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24719cd",
   "metadata": {},
   "source": [
    "5. O que aconteceria se a ordem do modelo aproximador fosse bem maior do que a que você escolheu (por exemplo, vinte vezes maior)? **Justifique sua resposta.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65737762",
   "metadata": {},
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8a4197",
   "metadata": {},
   "source": [
    "6. Escolha uma ordem bem maior do que a que você usou no item 4 (por exemplo, vinte vezes maior) e apresente uma figura comparando a predição feita por esse modelo com ordem bem menor com os dados originais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1caac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9da06a",
   "metadata": {},
   "source": [
    "7. O que aconteceria se a ordem do modelo aproximador fosse igual a 1, ou seja, uma reta? **Justifique sua resposta.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56502c77",
   "metadata": {},
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0289e50b",
   "metadata": {},
   "source": [
    "8. Faça a ordem do modelo aproximador igual a 1 e apresente uma figura comparando a predição feita por esse modelo com ordem igual a 1 com os dados originais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee794b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54339e4",
   "metadata": {},
   "source": [
    "### 3) Regressão polinomial para previsão de temperatura\n",
    "\n",
    "Neste exercício, você utilizará técnicas de **validação cruzada** para encontrar um modelo que prejeva a temperatura de uma cidade na Hungria com base em dados coletados sobre o clima da cidade no intervalo 2006 a 2016. As informações das **colunas** contidas no conjunto de dados seguem abaixo.\n",
    "\n",
    "|   |      Colunas     |\n",
    "|:-:|:----------------:|\n",
    "| 1 |  Formatted Date  |\n",
    "| 2 |    Summary       |\n",
    "| 3 |   Precip Type    |\n",
    "| 4 |Apparent Temperature (C)|\n",
    "| 5 |     Humidity     |\n",
    "| 6 | Wind Speed (km/h)|\n",
    "| 7 |Wind Bearing (degress)|\n",
    "| 8 |  Visibility (km) |\n",
    "| 9 |   Loud Cover    |\n",
    "| 10 |Pressure (millibars)|\n",
    "| 11 |  Daily Summary  |\n",
    "|    |    **Output variable (target/label)**  |\n",
    "| 12 |  Temperature (C)  |\n",
    "\n",
    "Fonte dos dados: [Referência dados do Clima de Szeged](https://www.kaggle.com/budincsevity/szeged-weather?select=weatherHistory.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc9e590",
   "metadata": {},
   "source": [
    "1. Execute a célula abaixo para importar os dados e as bibliotecas necessárias.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Após a execução bem sucedida da célula abaixo, você visualizará as 5 primeiras linhas do arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9129931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define uma semente para inicializar os gerados pseudo-aleatórios.\n",
    "seed = 42\n",
    "\n",
    "# Importa os dados\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/zz4fap/t319_aprendizado_de_maquina/main/projeto/data_weather.csv')\n",
    "\n",
    "# Mostra uma tabela com os 5 primeiros exemplos \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890715ca",
   "metadata": {},
   "source": [
    "2. A célula abaixo cria a matriz de atributos e separa o rótulo dos atributos numéricos. Execute-a para realizar essa separação.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ A função `drop` remove do conjunto atributos desnecessários à regressão.\n",
    "+ As colunas (i.e., atributos) que usaremos para o processo de regressão são: `Humidity`, `Wind Speed`, `Wind Bearing`, `Visibility` e `Pressure`.\n",
    "+ A célula imprimirá as dimensões da matriz de atributos e do vetor de rótulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dddede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features/atributos\n",
    "X = df.drop(['Formatted Date', 'Summary', 'Precip Type', 'Daily Summary', 'Temperature (C)', 'Loud Cover', 'Apparent Temperature (C)'], axis=1)\n",
    "print('Dimensão da matriz de atributos:', X.shape)\n",
    "\n",
    "# Label/rótulo\n",
    "y = df['Temperature (C)'].copy()\n",
    "print('Dimensão da matriz de rótulos:',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe1b203",
   "metadata": {},
   "source": [
    "3. Usando a estratégia de validação cruzada **k-Fold**, encontre a ordem ideal para que uma função hipótese polinomial aproxime bem o conjunto de dados. Para avaliar qual é a ordem ideal para o polinômio aproximador, plote gráficos com a média e o desvio padrão do erro quadrático médio (EQM) em função dos graus de polinômio considerados. Para isso:\n",
    "\n",
    "   1. Use o **k-Fold** com **k** igual a 10.\n",
    "   2. Configure o parâmetro `shuffle` da classe `KFold` como `True`, ou seja, `shuffle=True`.\n",
    "   3. Faça a análise de polinômios de ordem 1 até 7, **inclusive**.\n",
    "   4. Desabilite a inclusão da coluna do atributo de bias ao instanciar a classe `PolynomialFeatures` utilizando o parâmetro `include_bias=False`.\n",
    "   5. Use a classe `StandardScaler` para padronizar os atributos.\n",
    "\n",
    "**DICAS** \n",
    "\n",
    "+ Crie um pipeline de ações com objetos das classes `PolynomialFeatures`,  `StandardScaler` e `LinearRegression`.\n",
    "+ O tempo de execução desse exercício é de aproximadamente 10 minutos, mas pode variar de computador para computador, portanto, pegue um café e tenha paciência.\n",
    "+ Para resolver este item, se baseie no seguinte exemplo: [validacao_cruzada.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/main/notebooks/regression/validacao_cruzada.ipynb).\n",
    "+ **Atenção, não basta apenas copiar o código do exemplo dado, você precisa alterá-lo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f6d886",
   "metadata": {},
   "source": [
    "4. Após analisar os resultados obtidos com a validação cruzada **k-Fold**, responda qual é a melhor ordem de polinômio para aproximar os dados. **Justifique sua resposta.**\n",
    "\n",
    "**DICA**\n",
    "\n",
    "* Lembre-se do princípio da navalha de Occam para escolher a melhor ordem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7733e7e2",
   "metadata": {},
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d39f827",
   "metadata": {},
   "source": [
    "5. Analisando os resultados obtidos com a validação cruzada **k-Fold**, o que aconteceria se a ordem do modelo de regressão polinomial fosse maior do que 5? **Justifique sua resposta.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d538fbc4",
   "metadata": {},
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85900162",
   "metadata": {},
   "source": [
    "6. De posse da melhor ordem, treine um novo modelo considerando esta ordem e no final imprima o valor do erro quadrático médio para os conjuntos de treinamento e de teste.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Separe 70% do conjunto de dados para o treinamento e 30% para o conjunto de teste.\n",
    "+ Desabilite a inclusão da coluna do atributo de bias ao instanciar a classe `PolynomialFeatures` utilizando o parâmetro `include_bias=False`.\n",
    "+ Use a classe `StandardScaler` para normalizar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5fa157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f028a0e",
   "metadata": {},
   "source": [
    "7. Após analisar os valores de EQM do item anterior, podemos dizer que o modelo treinado generaliza bem? (**justifique sua resposta**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f97063",
   "metadata": {},
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
