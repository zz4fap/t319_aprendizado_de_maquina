{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da867ff1",
   "metadata": {
    "id": "da867ff1"
   },
   "source": [
    "# Projeto Final - T319 (2S2023)\n",
    "\n",
    "### Instruções\n",
    "\n",
    "1. Antes de começar, você deve clicar na opção \"Copiar para o Drive\" na barra superior do Colab. Depois de clicar nela, verifique se você está trabalhando nessa versão do notebook para que seu trabalho seja salvo.\n",
    "2. Quando você terminar os exercícios do projeto, vá até o menu do Jupyter ou Colab e selecione a opção para fazer download do notebook.\n",
    "    * Os notebooks tem extensão .ipynb.\n",
    "    * Este deve ser o arquivo que você irá entregar.\n",
    "    * No Colab vá até a opção **File** -> **Download .ipynb**.\n",
    "    * No Jupyter vá até a opção **File** -> **Download as** -> **Notebook (.ipynb)**.\n",
    "3. Após o download do notebook, vá até a aba de tarefas do MS Teams, localize a tarefa referente a este projeto e faça o upload do seu notebook. Veja que há uma opção para anexar arquivos à tarefa.\n",
    "4. Se certifiquem que o notebook sendo entregue contém todas as resoluções feitas por vocês. \n",
    "5. Atente-se ao prazo de entrega definido na tarefa do MS Teams. Entregas fora do prazo não serão consideradas.\n",
    "6. **O projeto pode ser resolvido em grupos de no MÁXIMO 3 alunos**.\n",
    "7. Todas as questões têm o mesmo peso.\n",
    "8. Não se esqueça de colocar seu(s) nome(s) e número(s) de matrícula no campo abaixo. Coloque os nomes dos integrantes do grupo no campo de texto abaixo.\n",
    "9. Você pode consultar todo o material de aula.\n",
    "10. A interpretação faz parte do projeto. Leia o enunciado de cada questão atentamente!\n",
    "11. Boa sorte!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587a29e",
   "metadata": {
    "id": "0587a29e"
   },
   "source": [
    "**Nomes e matrículas**:\n",
    "\n",
    "1. Nome do primeiro aluno - Matrícula do primeiro aluno\n",
    "2. Nome do segundo aluno - Matrícula do segundo aluno\n",
    "3. Nome do terceiro aluno - Matrícula do terceiro aluno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972fea32",
   "metadata": {
    "id": "972fea32"
   },
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557c0a17",
   "metadata": {
    "id": "557c0a17"
   },
   "source": [
    "### 1) Exercício sobre a escolha do passo de aprendizagem\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466c47e",
   "metadata": {
    "id": "d466c47e"
   },
   "source": [
    "1. Execute a célula de código abaixo para importar as bibliotecas e definir algumas funções necessárias para o treinamento de um modelo de regressão.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ A função `gradientDescent` implementa a versão estocástica do gradiente descendente.\n",
    "+ Veja que a função `gradientDescent` utiliza **decaimento temporal** do passo de aprendizagem para tornar o aprendizado do algoritmo mais comportado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66ae6a",
   "metadata": {
    "id": "8d66ae6a"
   },
   "outputs": [],
   "source": [
    "# Importa todas as bibliotecas, classes e funções necessárias.\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reseta o gerador de sequências pseudo-aleatórias.\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "def timeBasedDecay(alpha_init, k, t):\n",
    "    '''\n",
    "    Função que implementa o decaimento temporal.\n",
    "    Os parâmetros de entrada da função são:\n",
    "    * alpha_init - valor inicial do passo de aprendizagem\n",
    "    * k          - taxa de decaimento do passo de aprendizagem\n",
    "    * t          - iteração corrente\n",
    "    A função retorna o novo valor do passo de aprendizagem\n",
    "    '''\n",
    "    return alpha_init / (1.0 + k*t)\n",
    "\n",
    "def gradientDescent(X, y_noisy, n_epochs, alpha_init, k):\n",
    "    '''\n",
    "    Função que implementa a versão estocástica do gradiente descendente.\n",
    "    Os parâmetros de entrada da função são:\n",
    "    * X          - Matriz de atributos\n",
    "    * y          - vetor de rótulos\n",
    "    * n_epochs   - número de épocas\n",
    "    * alpha_init - valor inicial do passo de aprendizagem\n",
    "    * k          - taxa de decaimento da redução temporal do passo de aprendizagem\n",
    "    '''\n",
    "\n",
    "    # Obtém o número de exemplos de treinamento\n",
    "    N = len(y_noisy)\n",
    "\n",
    "    # Faz um redimensionamento do vetor de rótulos y para que se torne um vetor coluna.\n",
    "    # OBS.: Fazemos isso para poder executar cálculos vetoriais.\n",
    "    y_noisy = y_noisy.reshape(N, 1)\n",
    "\n",
    "    # Inicialização do vetor de pesos.\n",
    "    a = np.array([-10.0, -10.0]).reshape(2, 1)\n",
    "\n",
    "    # Cria vetor para armazenar o histórico de pesos ao longo do treinamento.\n",
    "    a_hist = np.zeros((2, n_epochs*N+1))\n",
    "    # Incializa o vetor de histórico de pesos com os pesos iniciais.\n",
    "    a_hist[:, 0] = a.reshape(2,)\n",
    "\n",
    "    # Cria vetor para armazenar o histórico de valores do passo de aprendizagem.\n",
    "    alpha_hist = np.zeros((n_epochs*N))\n",
    "\n",
    "    # Cria vetor para armazenar os erros de treinamento.\n",
    "    Jgd = np.zeros(n_epochs*N+1)\n",
    "\n",
    "    # Cálculo do MSE para o vetor de pesos inicial.\n",
    "    Jgd[0] = (1.0/N)*sum(np.power(y_noisy - X.dot(a), 2))\n",
    "\n",
    "    # Criando matrizes de zeros para armazenar os históricos de atualizações e vetores gradiente.\n",
    "    # OBS.: As matrizes tês duas linhas, pois os vetores de peso tem 2 elementos, ou seja, dois pesos.\n",
    "    update_hist = np.zeros((2, n_epochs*N))\n",
    "    gradient_hist = np.zeros((2, n_epochs*N))\n",
    "\n",
    "    # Laço de repetição do gradiente descendente estocástico.\n",
    "    iteration = 0\n",
    "    # Época de treinamento, apresenta todas os exemplos de treinamento ao modelo.\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # Embaralhe todo o conjunto de dados de treinamento antes de cada época.\n",
    "        shuffled_data_set_indexes = random.sample(range(0, N), N)\n",
    "\n",
    "        # Iteração de treinamento, apenas um exemplo é apresentado ao modelo para a atualização de seus pesos.\n",
    "        for i in range(N):\n",
    "            # Obtém um par ALEATÓRIO de vetor de atributos e seu respectivo rótulo.\n",
    "            random_index = shuffled_data_set_indexes[i]\n",
    "            xi = X[random_index:random_index+1]\n",
    "            yi = y_noisy[random_index:random_index+1]\n",
    "\n",
    "            # Decaimento temporal do passo de aprendizagem.\n",
    "            alpha = timeBasedDecay(alpha_init, k, epoch*N + i)\n",
    "\n",
    "            # Cálculo da estimativa do vetor gradiente com apenas uma amostra.\n",
    "            gradient = -2.0*xi.T.dot(yi - xi.dot(a))\n",
    "            update = alpha*gradient\n",
    "            a = a - update\n",
    "\n",
    "            # Armazena o histórico de pesos.\n",
    "            a_hist[:, epoch*N+i+1] = a.reshape(2,)\n",
    "            # Armazena o histórico de passos de aprendizagem.\n",
    "            alpha_hist[epoch*N+i] = alpha\n",
    "            # Armazena o histórico de vetores de atualização.\n",
    "            update_hist[:, epoch*N+i] = update.reshape(2,)\n",
    "            # Armazena o histórico de vetores gradiente.\n",
    "            gradient_hist[:, epoch*N+i] = gradient.reshape(2,)\n",
    "\n",
    "            # Calcula o MSE por itereção de treinamento.\n",
    "            Jgd[epoch*N+i+1] = (1.0/N)*sum(np.power((y_noisy - X.dot(a)), 2))\n",
    "\n",
    "            # Incrementa o contador de iterações.\n",
    "            iteration = epoch*N+i\n",
    "\n",
    "    return a, Jgd, a_hist, alpha_hist, update_hist, gradient_hist, iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a63858",
   "metadata": {
    "id": "69a63858"
   },
   "source": [
    "2. Execute a célula de código abaixo para criar o conjunto de dados que será usado neste exercício.\n",
    "\n",
    "+ A função objetivo utilizada neste exercício é dada por $y = 1 + 2x$, onde $a_0=1$ e $a_1=2$.\n",
    "+ A função hipótese que utilizaremos tem o mesmo formato da função objetivo, $\\hat{y} = \\hat{a}_0 + \\hat{a}_1 x$, sendo o objetivo do algoritmo do gradiente descendente encontrar aproximações, $\\hat{a}_0$ e $\\hat{a}_1$, para os valores de ${a}_0$ e ${a}_1$.\n",
    "+ Para representarmos a função hipótese em formato matricial, i.e., $\\textbf{y} = \\textbf{X}\\textbf{a}$, precisamos criar a matriz de atributos concatenando os vetores de atributos de *bias* (i.e., vetor com valores iguais a 1) e $x$.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Na célula de código abaixo, o vetor do atributo de *bias* é concatenado ao vetor de atributo, $x$.\n",
    "+ Essa concatenação é feita de forma manual, pois a implementação da versão estocática do gradiente descendente fornecida acima não faz isso automaticamente como no caso das classes fornecidas pela bilbioteca SciKit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ea057e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "42ea057e",
    "outputId": "f10eeedc-f1c5-4d08-cc86-dcef4892c6a1"
   },
   "outputs": [],
   "source": [
    "# Número de amostras\n",
    "N = 1000\n",
    "\n",
    "# Vetor de atributos.\n",
    "x = np.linspace(0, 1, N).reshape(N, 1)\n",
    "\n",
    "# Função objetivo.\n",
    "y = 1 + 2*x\n",
    "\n",
    "# Ruído.\n",
    "w = np.sqrt(0.1)*np.random.randn(N, 1)\n",
    "\n",
    "# Função observável.\n",
    "y_noisy = y + w\n",
    "\n",
    "# Cria matriz de atributos.\n",
    "X = np.c_[np.ones((N, 1)), x]\n",
    "\n",
    "# Figura comparando as duas funções.\n",
    "plt.plot(x, y_noisy, label='Função observável')\n",
    "plt.plot(x, y, label='Função objetivo')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f2a708",
   "metadata": {
    "id": "a9f2a708"
   },
   "source": [
    "3. Divida o conjunto total de amostras em conjuntos de treinamento e validação. O conjunto de treinamento deve conter 75% do total de amostras e o conjunto de validação os 25% restantes.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Use a função `train_test_split` e a configure com os seguintes parâmetros `test_size=0.25` e `random_state=seed`. A função divide o conjunto original de amostras em dois subconjuntos, um para treinamento e outro para validação (i.e., para avaliar a capacidade de generalização do modelo). Veja o código abaixo.\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_noisy, test_size=0.25, random_state=seed)\n",
    "```\n",
    "+ Para que o próximo item do exercício funcione, chame as matrizes de treinamento e de validação de `X_train` e `X_test`, respectivamente, e os vetores de rótulos de treinamento e de validação de `y_train` e `y_test`, respectivamente, como no exemplo acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6148b3d",
   "metadata": {
    "id": "f6148b3d"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2611f0a",
   "metadata": {
    "id": "c2611f0a"
   },
   "source": [
    "4. Execute a célula de código abaixo e analise as figuras geradas.\n",
    "\n",
    "A célula abaixo treina o modelo de regressão usando a função `gradientDescent` com os seguintes valores:\n",
    "+ **taxa de decaimento ($k$)**: 0.1, 0.01, e 0.001.\n",
    "+ **passo de aprendizagem ($\\alpha$)**: 0.1, 0.03, 0.01, 0.003, e 0.001.\n",
    "\n",
    "Cada figura mostra o erro quadrático médio (EQM) de treinamento em função das iterações de treinamento para um valor específico da taxa de decaimento ($k$) e vários valores para o passo de aprendizagem ($\\alpha$).\n",
    "<br/>\n",
    "\n",
    "O valor da taxa de decaimento ($k$) é mostrado no título (i.e., topo) da figura, enquanto os diferentes valores de passo de aprendizagem ($\\alpha$) são mostrados com cores diferentes na legenda de cada figura.\n",
    "\n",
    "**DICAS**:\n",
    "\n",
    "+ Lembrem-se que o menor valor do EQM tende ao valor da variância do ruído adicionado às amostras da função objetivo quando encontra-se os valores ótimos dos pesos. Neste exemplo, a variância é de $0.1$ e, consequentemente, o EQM tenderá a esse valor quando o algoritmo do gradiente descendente estocástico se aproximar dos pesos ótimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ee9fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "d54ee9fa",
    "outputId": "f04a3cd3-89cf-4543-bd16-1a8e44f4660b"
   },
   "outputs": [],
   "source": [
    "# Número de épocas.\n",
    "n_epochs = 2\n",
    "\n",
    "# Lista de taxas de decaimento.\n",
    "k_list = [0.1, 0.01, 0.001]\n",
    "\n",
    "# Lista de passos de aprendizagem.\n",
    "alpha_list = [0.1, 0.03, 0.01, 0.003, 0.001]\n",
    "\n",
    "# Lista para armazenar os erros das combinações de taxa de decaimento e passo de aprendizagem.\n",
    "error = []\n",
    "for k in k_list:\n",
    "    error_hist = []\n",
    "    for alpha in alpha_list:\n",
    "        a, Jgd, a_hist, alpha_hist, update_hist, gradient_hist, iteration = gradientDescent(X_train, y_train, n_epochs, alpha_init=alpha, k=k)\n",
    "        error_hist.append(Jgd)\n",
    "    error.append(error_hist)\n",
    "\n",
    "# Visualização do erro durante o treinamento de cada passo de aprendizagem.\n",
    "plt.figure(figsize=(15,5))\n",
    "for i in range(len(k_list)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title('k = '+str(k_list[i]))\n",
    "    for j in range(len(alpha_list)):\n",
    "        plt.plot(np.arange(error[i][j].shape[0]), error[i][j], label=('alpha = '+f'{alpha_list[j]}'))\n",
    "        plt.yscale('log')\n",
    "    plt.xlabel('Iterações')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.ylim([0.05, 400])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd1148",
   "metadata": {
    "id": "97fd1148"
   },
   "source": [
    "5. Analise as figuras do item anterior e responda: Quais são os melhores valores para a taxa de decaimento ($k$) e o passo de aprendizagem ($\\alpha$)? (**Justifique sua resposta**).\n",
    "\n",
    "**DICAS**:\n",
    "\n",
    "+ Qual curva atinge o menor EQM de forma mais rápida e sem muitas oscilações?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a65678d",
   "metadata": {
    "id": "5a65678d"
   },
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1c0757",
   "metadata": {
    "id": "cb1c0757"
   },
   "source": [
    "6. De posse dos melhores valores para a taxa de decaimento ($k$) e passo de aprendizagem ($\\alpha$), obtidos no item anterior, treine novamente o modelo com estes valores e imprima os erros quadráticos médios (EQMs) obtidos para os conjuntos de treinamento e de validação e o valor dos pesos $\\hat{a}_0$ e $\\hat{a}_1$.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Configure a função `gradientDescent` com os melhores valores para a taxa de decaimento ($k$) e passo de aprendizagem ($\\alpha$) obtidos no item anterior.\n",
    "+ Os parâmetros de entrada da função `gradientDescent` são descritos em seu cabeçalho. Veja a definição da função.\n",
    "+ Treine o modelo com o conjunto de treinamento.\n",
    "+ Configure o **número de épocas**, `n_epochs`, com o valor `2`, ou seja, o modelo será treinado por 2 épocas.\n",
    "+ Lembre-se que a função hipótese é expressa no formato vetorial como $\\hat{\\textbf{y}}=\\textbf{X}\\textbf{a}$, onde $\\textbf{X}$ é a matriz de atributos e $\\textbf{a}$ é o vetor de pesos. Portanto, para fazer predições com as matrizes de atributos de treinamento e validação, você precisa utilizar a função hipótese no formato vetorial.\n",
    "+ Você pode usar a função `mean_squared_error` da biblioteca SciKit-Learn para calcular o EQM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc59d31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afc59d31",
    "outputId": "9e96d0f0-c0fb-4af8-841e-2cc18cfe25df"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a4c5cb",
   "metadata": {
    "id": "a2a4c5cb"
   },
   "source": [
    "7. Treine um modelo usando a **equação normal**. Ao final, imprima o erro quadrático médio (EQM) obtido pelo modelo para os conjuntos de treinamento e validação. Além disso, imprima o valor dos pesos $\\hat{a}_0$ e $\\hat{a}_1$ obtidos com a **equação normal**.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Você pode utilizar a classe `LinearRegression` da biblioteca SciKit-Learn para resolver este item ou implementar a equação normal manualmente.\n",
    "+ Caso você use a classe `LinearRegression`, a configure com o parâmetro `fit_intercept=False`, pois a matriz de atributos criada no item 1 do exercício, já contém a coluna do atributos de bias, ou seja, a coluna com todos os valores iguais a 1.\n",
    "+ Usando a classe `LinearRegression`:\n",
    "  * A predição é feita com o método `predict()`.\n",
    "  * Os pesos do modelo podem ser acessados através do atributo `coef_` da classe `LinearRegression`. Por exemplo, dado que o nome do objeto da classe `LinearRegression` é `reg`, então `reg.coef_[0,0]` acessa o valor ótimo encontrado para o peso $\\hat{a}_0$ e `reg.coef_[0,1]` acessa o valor ótimo encontrado para o peso $\\hat{a}_1$.\n",
    "+ Você pode usar a função `mean_squared_error` da biblioteca SciKit-Learn para calcular o EQM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e570e05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1e570e05",
    "outputId": "878ff9e1-9948-4f87-b815-02a1bc925c5f"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2200d2c2",
   "metadata": {
    "id": "2200d2c2"
   },
   "source": [
    "8. Compare os pesos ($\\hat{a}_0$ e $\\hat{a}_1$) e os EQMs (para os conjuntos de treinamento e validação) obtidos com os modelos usando a equação normal (item 7) e o gradiente descendente estocástico com os melhores valores para a taxa de decaimento e passo de aprendizagem (item 6).\n",
    "\n",
    "Os valores são diferentes? Se sim, explique o motivo da diferença. (**Justifique sua resposta**).\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Lembre-se que a equação normal dá a solução ótima, ou seja, ela fornece os pesos que minimizam o EQM. Não existem outros pesos que resultem em um EQM menor para o conjunto de treinamento usado.\n",
    "+ As estimativas do vetor gradiente com o gradiente descendente estocástico, mesmo com os melhores valores para a taxa de decaimento e passo de aprendizagem, continuam sendo ruidosas, consequentemente, as atualizações dos pesos também serão ruidosas.\n",
    "+ Além disso, os valores encontrados para a taxa de decaimento e passo de aprendizagem podem não ser os ótimos.\n",
    "+ Reveja o material de aula e os exemplos onde discutimos as versões do gradiente descendente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1637c2",
   "metadata": {
    "id": "ae1637c2"
   },
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfdc669",
   "metadata": {
    "id": "8cfdc669"
   },
   "source": [
    "### 2) Exercício sobre regressão polinomial para aproximação de FDPs desconhecidas.\n",
    "\n",
    "Em diversas áreas, inclusive em telecomunicações, podemos encontrar, em determinados problemas, variáveis aleatórias que não possuem formas conhecidas para suas funções densidade de probabilidade (FDP). Nestes casos, podemos recorrer à aproximação de funções como uma forma de encontrar uma função que aproxime os valores observados desta variável aleatória. Portanto, neste exercício, você deve encontrar uma função que aproxime a FDP dos dados observados de uma variável aleatória.\n",
    "\n",
    "1. As observações da variável aleatória com FDP desconhecida são geradas com o trecho de código abaixo. Portanto, execute código abaixo e analise o resultado.\n",
    "\n",
    "**Dicas**\n",
    "\n",
    "+ Sempre que possível, usem a semente (`seed`) definida na célula de código abaixo.\n",
    "+ Este exercício consume muita memória RAM. Portanto, para que você não encontre problemas durante sua execução, use o Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b69a978",
   "metadata": {
    "id": "9b69a978",
    "outputId": "1c697c8f-da04-4023-ef39-e5ead10ccdb8"
   },
   "outputs": [],
   "source": [
    "# Importando todas as bibliotecas necessárias.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "\n",
    "# Reset do gerador de sequências pseudo-aleatórias.\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Número de amostras.\n",
    "N = 10000000\n",
    "\n",
    "# Distribuição Normal a.\n",
    "mu_a = -1      # Média de a.\n",
    "sigma_a = 0.5  # Desvio padrão de a.\n",
    "\n",
    "# Distribuição Normal b.\n",
    "mu_b = 2       # Média de b.\n",
    "sigma_b = 1    # Desvio padrão de b.\n",
    "\n",
    "# Distribuição Bimodal.\n",
    "h = np.c_[sigma_a*np.random.randn(1, N) + mu_a, sigma_b*np.random.randn(1, N) + mu_b]\n",
    "h = h.reshape(2*N,)\n",
    "\n",
    "# Número de divisões do histograma.\n",
    "bins = 1000\n",
    "y, X, p = plt.hist(h, bins=bins, density=True)\n",
    "plt.ylabel('Probabilidade')\n",
    "plt.xlabel('y')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Redimensionando o vetor de atributos.\n",
    "X = X[0:len(X)-1].reshape(bins, 1)\n",
    "\n",
    "# Imprimindo as dimensões.\n",
    "print('X.shape:', X.shape)\n",
    "print('y.shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da711581",
   "metadata": {
    "id": "da711581"
   },
   "source": [
    "2. Com a matriz de atributos, $\\textbf{X}$, e o vetor de rótulos, $y$, obtidos no item anterior, utilize a técnica de validação cruzada **$k$-Fold** para escolher a melhor ordem para o modelo de aproximação da FDP. Plote gráficos com a média e o desvio padrão do erro quadrático médio (MSE) em função dos graus de polinômio considerados.\n",
    "\n",
    "Para isso, faça o seguinte:\n",
    "\n",
    "1. Use um objeto da classe **$k$-Fold** instanciado com os seguintes parâmetros `n_splits=10`, `shuffle=True` e `random_state=seed`.\n",
    "2. Faça a análise de **polinômios** de ordem 1 até 50, **inclusive**.\n",
    "3. Use a classe `PolynomialFeatures` para criar a matriz de atributos polinomial de acordo com a ordem desejada. Instancie o objeto desta classe com o parâmetro `include_bias` igual a `False`, i.e., `include_bias=False` para desabilitar a inclusão da coluna do atributo de bias e evitar que o modelo tenha um desempenho ruim.\n",
    "4. Use a classe `StandardScaler` para padronizar os dados da matriz de atributos polinomial.\n",
    "5. Use a classe `LinearRegression` para realizar a regressão propriamente dita.\n",
    "6. Para realizar a validação cruzada com o objeto da classe **$k$-Fold**, use a função `cross_val_score` com o seguinte parâmetro `scoring='neg_mean_squared_error'`.\n",
    "7. Após o término da validação cruzada, plote gráficos com a média e o desvio padrão do erro quadrático médio em função do grau do polinômio.\n",
    "\n",
    "\n",
    "**Dicas**\n",
    "\n",
    "+ Para ajudar a resolver este item, veja o seguinte exemplo: [validacao_cruzada.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/main/notebooks/regression/validacao_cruzada.ipynb).\n",
    "+ Use escala logarítmica no eixo y das figuras, assim como feito no exemplo acima.\n",
    "+ **Atenção, não basta apenas copiar o código do exemplo dado, você precisa alterá-lo.**\n",
    "+ O tempo de execução dese exercício é longo. Portanto, pegue um café e tenha paciência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd4b44",
   "metadata": {
    "id": "45dd4b44"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e84c51e",
   "metadata": {
    "id": "0e84c51e"
   },
   "source": [
    "3. Após analisar os resultados do item anterior, responda: Qual a melhor ordem do polinômio para esse problema? **Justifique sua resposta.**\n",
    "\n",
    "**Dicas**\n",
    "\n",
    "+ Use o princípio da navalha de Occam para escolher a ordem do polinômio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970deb91",
   "metadata": {
    "id": "970deb91"
   },
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd505c2",
   "metadata": {
    "id": "5bd505c2"
   },
   "source": [
    "4. De posse da melhor ordem, treine um novo modelo de regressão considerando esta ordem e, no final, calcule e imprima o valor do erro quadrático médio para (MSE).\n",
    "\n",
    "Para isso, faça o seguinte\n",
    "\n",
    "1. Crie um **pipeline** (i.e., um objeto da classe `Pipeline`) com as seguintes ações:\n",
    "    + `PolynomialFeatures` com a ordem escolhida e com o parâmetro `include_bias` igual a `False`, i.e., `include_bias=False`.\n",
    "    + `StandardScaler` para padronizar os dados.\n",
    "    + `LinearRegression` para encontrar os pesos da função hipótese polinomial.\n",
    "2. Treine o modelo com o **conjunto total de amostras**.\n",
    "3. Faça predições com o modelo treinando usando o **conjunto total de amostras**.\n",
    "4. Calcule e imprima o MSE entre as predições feitas pelo modelo e os rótulos do **conjunto total de amostras**.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Para ajudar a resolver este item, veja o seguinte exemplo: [validacao_cruzada.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/main/notebooks/regression/validacao_cruzada.ipynb).\n",
    "+ **Atenção, não basta apenas copiar o código do exemplo dado, você precisa alterá-lo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95421117",
   "metadata": {
    "id": "95421117"
   },
   "outputs": [],
   "source": [
    "# Digite aqui o código do exercício."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c144140",
   "metadata": {
    "id": "9c144140"
   },
   "source": [
    "5. Apresente uma figura comparando a predição feita pelo melhor regressor com os dados originais.\n",
    "\n",
    "**Dicas**\n",
    "\n",
    "+ Para ajudar a resolver este item, veja o seguinte exemplo: [validacao_cruzada.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/main/notebooks/regression/validacao_cruzada.ipynb).\n",
    "+ **Atenção, não basta apenas copiar o código do exemplo dado, você precisa alterá-lo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d70f30",
   "metadata": {
    "id": "c4d70f30"
   },
   "outputs": [],
   "source": [
    "# Digite aqui o código do exercício."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a211c23",
   "metadata": {
    "id": "1a211c23"
   },
   "source": [
    "6. O que aconteceria se a ordem do modelo fosse bem menor do que a que você escolheu (por exemplo, dez vezes menor)? **Justifique sua resposta.**\n",
    "\n",
    "**Dica**:\n",
    "+ Pense sobre a flexibilidade do modelo com uma ordem dez vezes menor do que a ideal. Ele teria graus de liberdade suficientes para se contorcer e capturar o comportamento da função objetivo? Qual é o nome dado a esse efeito ou problema?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008ac570",
   "metadata": {
    "id": "008ac570"
   },
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1a0641",
   "metadata": {
    "id": "2c1a0641"
   },
   "source": [
    "7. Escolha uma ordem bem menor do que a que você usou no item 4 (por exemplo, dez vezes menor) e apresente uma figura comparando a predição feita por esse modelo com ordem bem menor com os dados originais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6401b98a",
   "metadata": {
    "id": "6401b98a"
   },
   "outputs": [],
   "source": [
    "# Digite aqui o código do exercício."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2246024",
   "metadata": {
    "id": "e2246024"
   },
   "source": [
    "### 3) Usando regressão para estimar calorias queimadas.\n",
    "\n",
    "Neste exercício, você utilizará uma técnica de **validação cruzada** para encontrar um modelo que estime a quantidade de calorias queimadas após uma atividade física com base em um conjunto de dados coletados. As informações das **colunas** contidas no conjunto de dados seguem abaixo. O objetivo é utilizar os atributos para estimar a quantidade de calorias queimadas.\n",
    "\n",
    "|            |                   **Atributos**                   |\n",
    "|:----------:|:-------------------------------------------------:|\n",
    "|   User_ID  |              Identificação do usuário             |\n",
    "|   Gender   |                       Gênero                      |\n",
    "|     Age    |                       Idade                       |\n",
    "|   Height   |                       Altura                      |\n",
    "|   Weight   |                        Peso                       |\n",
    "|  Duration  |            Duração da atividade física            |\n",
    "| Heart_Rate | Média de batimentos cardíacos durante a atividade física |\n",
    "|  Body_Temp | Média da temperatura coporal durante a atividade física |\n",
    "|            |                     **Rótulo**                    |\n",
    "|  Calories  |       Calorias queimadas durante a atividade física       |\n",
    "\n",
    "1. Execute a célula abaixo para importar o conjunto de dados e as bibliotecas necessárias.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Após a execução bem sucedida da célula abaixo, você visualizará as 5 primeiras linhas do arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57553e27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "57553e27",
    "outputId": "e59a9feb-8175-4696-b67e-16960f62c77a"
   },
   "outputs": [],
   "source": [
    "# Importe todas as bibliotecas necessárias.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import urllib\n",
    "\n",
    "# Reseta o gerador de sequências pseudo aleatórias.\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Baixa as bases de dados do dropbox.\n",
    "urllib.request.urlretrieve('https://www.dropbox.com/s/1zka46bw4f4z5xq/exercise.csv?dl=1', 'exercise.csv')\n",
    "urllib.request.urlretrieve('https://www.dropbox.com/s/45gtml94o97bhz8/calories.csv?dl=1', 'calories.csv')\n",
    "\n",
    "# Importa os arquivos CSV.\n",
    "exercise_data = pd.read_csv('./exercise.csv')\n",
    "calories_data = pd.read_csv('./calories.csv')\n",
    "\n",
    "# Une as duas bases de dados.\n",
    "df = exercise_data.join( calories_data.set_index('User_ID'), on='User_ID', how='left')\n",
    "\n",
    "# Mostra uma tabela com as 5 primeiras linhas.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0055667",
   "metadata": {
    "id": "d0055667"
   },
   "source": [
    "2. Execute a célula de código abaixo para aplicar um pré-processamento aos dados do conjunto.\n",
    "\n",
    "+ Como os modelos de regressão esperam valores numéricos, devemos alterar os valores textuais da coluna `Gender` em valores numéricos. A string `male` é alterada para o valor 0 e a string `female` é alterada para o valor 1.\n",
    "+ Na sequência, a coluna `User_ID` é removida, pois ela não é um atributo e, portanto, não traz informação útil para a regressão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4deb62",
   "metadata": {
    "id": "cc4deb62",
    "outputId": "29b11bbf-3fa7-4089-ea34-cee7998a2ae0"
   },
   "outputs": [],
   "source": [
    "# Mapeia as strings em valores numéricos.\n",
    "df.replace({'Gender':{'male':0, 'female':1}}, inplace=True)\n",
    "\n",
    "# Remove a coluna 'User_ID'.\n",
    "del df[ 'User_ID' ]\n",
    "\n",
    "# Mostra uma tabela com as 5 primeiras linhas.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e79e0f",
   "metadata": {
    "id": "92e79e0f"
   },
   "source": [
    "3. Execute a próxima célula de código para criar a matriz de atributos, $\\textbf{X}$, e o vetor de rótulos, $\\textbf{y}$.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ A primeira linha de comando remove da matriz de atributos a coluna `Calories`, pois ela será nosso rótulo.\n",
    "+ A segunda linha cria o vetor de rótulos contendo apenas a coluna `Calories`.\n",
    "+ A célula imprimirá as dimensões da matriz de atributos e do vetor de rótulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a531736d",
   "metadata": {
    "id": "a531736d",
    "outputId": "2d175960-880b-4155-cb5a-92403e025f9f"
   },
   "outputs": [],
   "source": [
    "# Criando a matriz de atributos e o vetor de rótulos.\n",
    "X = df.drop('Calories', axis=1)\n",
    "y = df['Calories']\n",
    "\n",
    "# Atributos.\n",
    "print('Dimensão da matriz de atributos:', X.shape)\n",
    "# Rótulos.\n",
    "print('Dimensão do vetor de rótulos:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ad95de",
   "metadata": {
    "id": "c9ad95de"
   },
   "source": [
    "4. Com a matriz de atributos, $\\textbf{X}$, e o vetor de rótulos, $\\textbf{y}$, obtidos no item anterior, utilize a técnica de validação cruzada **$k$-Fold** para escolher a melhor ordem para um modelo de regressão polinomial.\n",
    "\n",
    "Para isso, faça o seguinte:\n",
    "\n",
    "1. Use um objeto da classe **$k$-Fold** instanciado com os seguintes parâmetros `n_splits=10`, `shuffle=True` e `random_state=seed`.\n",
    "2. Faça a análise de **polinômios** de ordem 1 até 7, **inclusive**.\n",
    "3. Use a classe `PolynomialFeatures` para criar a matriz de atributos polinomial de acordo com a ordem desejada. Instancie o objeto desta classe com o parâmetro `include_bias` igual a `False`, i.e., `include_bias=False` para desabilitar a inclusão da coluna do atributo de bias e evitar que o modelo tenha um desempenho ruim.\n",
    "4. Use a classe `StandardScaler` para padronizar os dados da matriz de atributos polinomial.\n",
    "5. Use a classe `LinearRegression` para realizar a regressão propriamente dita.\n",
    "6. Para realizar a validação cruzada com o objeto da classe **$k$-Fold**, use a função `cross_val_score` com o seguinte parâmetro `scoring='neg_mean_squared_error'`.\n",
    "7. Após o término da validação cruzada, plote gráficos com a média e o desvio padrão do erro quadrático médio em função do grau do polinômio.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ O tempo de execução desse exercício é de aproximadamente 10 minutos, mas pode variar de computador para computador, portanto, pegue um café e tenha paciência.\n",
    "+ Use o **princípio da navalha de Occam** para escolher a ordem do polinômio.\n",
    "+ Para ajudar a resolver este item, veja o seguinte exemplo: [validacao_cruzada.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/main/notebooks/regression/validacao_cruzada.ipynb).\n",
    "+ **Atenção, não basta apenas copiar o código do exemplo dado, você precisa alterá-lo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a468a72",
   "metadata": {
    "id": "4a468a72"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4da78d",
   "metadata": {
    "id": "8d4da78d"
   },
   "source": [
    "5. Após analisar os resultados do item anterior responda: Qual a melhor ordem do polinômio para esse problema? **Justifique sua resposta**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cb1315",
   "metadata": {
    "id": "19cb1315"
   },
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1703da7f",
   "metadata": {
    "id": "1703da7f"
   },
   "source": [
    "6. De posse da melhor ordem, treine um novo modelo considerando esta ordem e no final imprima o valor do erro quadrático médio (MSE) para os conjuntos de treinamento e de validação.\n",
    "\n",
    "Para isso, faça o seguinte\n",
    "\n",
    "1. Separe 75% do conjunto total de dados para o treinamento e 25% para a validação do modelo usando a função `train_test_split` com o parâmetro `random_state=seed`.\n",
    "2. Crie um **pipeline** (i.e., um objeto da classe `Pipeline`) com as seguintes ações:\n",
    "    + `PolynomialFeatures` com a ordem escolhida e com o parâmetro `include_bias` igual a `False`, i.e., `include_bias=False`.\n",
    "    + `StandardScaler` para padronizar os dados.\n",
    "    + `LinearRegression` para encontrar os pesos da função hipótese polinomial.\n",
    "3. Treine o modelo com o conjunto de treinamento.\n",
    "4. Faça predições com o modelo treinando usando os conjuntos de treinamento e validação.\n",
    "5. Calcule e imprima o MSE entre as predições feitas pelo modelo e os rótulos dos conjuntos de treinamento e validação.\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Para ajudar a resolver este item, veja o seguinte exemplo: [validacao_cruzada.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/main/notebooks/regression/validacao_cruzada.ipynb).\n",
    "+ **Atenção, não basta apenas copiar o código do exemplo dado, você precisa alterá-lo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441d349f",
   "metadata": {
    "id": "441d349f"
   },
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a6247",
   "metadata": {
    "id": "853a6247"
   },
   "source": [
    "7. Comparando os dois erros obtidos no item anterior, ou seja, os erros de treinamento e validação. Você diria que o modelo está subajustando, sobreajustando ou encontrou uma relação de compromisso entre capacidade de generalização e flexibilidade (ou complexidade)? **Justifique sua resposta**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a07454",
   "metadata": {
    "id": "43a07454"
   },
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e04a8f",
   "metadata": {
    "id": "a9e04a8f"
   },
   "source": [
    "## Exercício Extra\n",
    "\n",
    "#### O exercício abaixo é opcional, mas vale nota extra ou substitui um dos exercícios anteriores caso você não tenha resolvido algum deles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e443cb53",
   "metadata": {
    "id": "e443cb53"
   },
   "source": [
    "### 4) Exercício sobre gradiente descendente estocástico com função hipótese não-linear.\n",
    "\n",
    "Neste exercício usaremos a implementação do gradiente descendente (GD) em mini-batches configurada para funcionar como a versão estocástica juntamente com uma função hipótese não-linear.\n",
    "\n",
    "O objetivo do exercício é demonstrar que o gradiente descendente estocástico (GDE) com uma função hipótese não linear em relação aos pesos pode ser usada para resolver um outro tipo de problema de aprendizado supervisionado que discutimos rapidamente durante a nossa primeira aula.\n",
    "\n",
    "A função hipótese que iremos usar é não-linear no sentido em que os valores de saída da função não podem ser expressos como combinações lineares dos valores de entrada (i.e., rótulos) em relação aos pesos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3706b99",
   "metadata": {
    "id": "a3706b99"
   },
   "source": [
    "1. Execute a célula de código abaixo e analise os valores impressos e a figura.\n",
    "\n",
    "**Dicas**\n",
    "\n",
    "+ A matriz $\\textbf{X}$ é uma matriz de dimensões $N \\times 2$, onde cada coluna representa um dos dois atributos, $x_1$ e $x_2$, mostrados na figura.\n",
    "+ Veja que os rótulos assumem apenas dois valores: 0 ou 1.\n",
    "+ Perceba que as amostras assumem cores diferentes dependendo do valor do seu rótulo. Amostras com rótulo igual a 0 são plotadas na cor azul e amostras com rótulo igual a 1 são plotadas na cor laranja.\n",
    "+ Perceba também que duas **distribuições** distintas de dados são plotadas.\n",
    "+ Note que os rótulos são discretos, assumindo apenas 2 valores, 0 ou 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a93f1b",
   "metadata": {
    "id": "74a93f1b",
    "outputId": "7dd379f7-0522-4f0d-e7c8-efa3856f24e8"
   },
   "outputs": [],
   "source": [
    "# Import the libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "import urllib\n",
    "\n",
    "# Reset PN sequence generator.\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Retrieve the dataset from dropbox.\n",
    "urllib.request.urlretrieve('https://www.dropbox.com/s/wt2aurqb70uoa1i/projeto_T319_clf_2S2023.csv?dl=1', 'projeto_T319_clf_2S2023.csv')\n",
    "\n",
    "# Read the CSV file.\n",
    "df = pd.read_csv('projeto_T319_clf_2S2023.csv', header=None)\n",
    "\n",
    "# Convert dataFrames into numpy arrays.\n",
    "X = df.iloc[:, :2].to_numpy()\n",
    "y = df[2].to_numpy().reshape(X.shape[0], 1)\n",
    "\n",
    "# Print the dimension of the arrays.\n",
    "print('Dimensões de X:', X.shape)\n",
    "print('Dimensões de y:', y.shape)\n",
    "print('Alguns valores do vetor de rótulos, y:', y[0:10])\n",
    "\n",
    "# Plot the samples.\n",
    "idx0 = np.argwhere(y==0)[:,0]\n",
    "idx1 = np.argwhere(y==1)[:,0]\n",
    "plt.plot(X[idx0,0], X[idx0,1],'.', label='Amostras com rótulo igual a 0')\n",
    "plt.plot(X[idx1,0], X[idx1,1],'.', label='Amostras com rótulo igual a 1')\n",
    "plt.xlabel('$x_1$', fontsize=14)\n",
    "plt.ylabel('$x_2$', fontsize=14)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d808d2",
   "metadata": {
    "id": "76d808d2"
   },
   "source": [
    "2. Implemente uma função chamada `hypothesis` que implementa a seguinte função hipótese:\n",
    "\n",
    "$$\\hat{y} = f ( g(x_1, x_2) ),$$\n",
    "\n",
    "onde $f$ é a função degrau unitário, a qual é definida como\n",
    "$$f(z) = \\begin{cases}\n",
    "\t\t\t0, & \\text{se $z$ < 0}\\\\\n",
    "            1, & \\text{se $z$ = 0}\\\\\n",
    "            1, & \\text{se $z$ > 0}\n",
    "\t\t \\end{cases},$$\n",
    "e a função $g(x_1, x_2)$ é definida como\n",
    "$$g(x_1, x_2) = \\hat{a}_0 + \\hat{a}_1 x_1 + \\hat{a}_2 x_2.$$\n",
    "\n",
    "Perceba que esta função hipótese não é linear, pois sua saída é o resultado de passar a função linear $g(x_1, x_2)$ através da função degrau unitário, $f(z)$.\n",
    "\n",
    "**Dicas**\n",
    "\n",
    "+ Sua função deve ter obrigatoriamente o nome `hypothesis`.\n",
    "+ Sua função deve ter dois parâmetros de entrada, a matriz de atributos, $\\textbf{X}$, e o vetor de pesos, $\\textbf{a}$.\n",
    "+ Passe os argumentos para a função na seguinte ordem: $\\textbf{X}$ e depois $\\textbf{a}$.\n",
    "+ A função deve retornar o vetor $\\hat{y}$, que é a saída da função degrau.\n",
    "+ Você pode implementar a função degrau manualmente ou usar a função `heaviside` da biblioteca numpy (https://numpy.org/doc/stable/reference/generated/numpy.heaviside.html).\n",
    "+ Veja abaixo um template da função que você precisa implementar. Note que você ainda precisa implementar a função da forma como especificada acima.\n",
    "```python\n",
    "def hypothesis(X, a):\n",
    "    # escreva aqui o código que implementa a função degrau unitário.\n",
    "    return y_chapeu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e2168",
   "metadata": {
    "id": "a26e2168"
   },
   "outputs": [],
   "source": [
    "# Defina aqui a função hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22933297",
   "metadata": {
    "id": "22933297"
   },
   "source": [
    "3. Execute a célula de código abaixo e analise a implementação da função `gradientDescentMiniBatch`.\n",
    "\n",
    "A célula abaixo apresenta a implementação do gradiente descendente (GD) em mini-batches com a função hipótese linear trocada pela função hipótese não-linear (`hypothesis`) implementada no item anterior.\n",
    "\n",
    "A função linear foi trocada pela função não-linear, `hypothesis`, nos pontos do código onde:\n",
    "  + Ocorrem os cálculos do erro quadrático médio (MSE).\n",
    "  + Ocorre o cálculo do vetor gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a3341",
   "metadata": {
    "id": "990a3341"
   },
   "outputs": [],
   "source": [
    "def gradientDescentMiniBatch(X, y, alpha, n_epochs, mb_size):\n",
    "    '''\n",
    "    Mini-batch gradient descent.\n",
    "    Entrada:\n",
    "        X:        matriz de atributos\n",
    "        y:        vetor de rótulos\n",
    "        alpha:    passo de aprendizagem\n",
    "        n_epochs: número de épocas\n",
    "        mb_size:  tamanho do mini-batch\n",
    "    Saída:\n",
    "        a:         vetor de pesos\n",
    "        Jgd:       vetor de erro ao longo das iterações de treinamento\n",
    "        a_hist:    histórico de vetores de peso\n",
    "        grad_hist: histórico de vetores gradiente\n",
    "        inc:       contador de iterações de treinamento\n",
    "    '''\n",
    "\n",
    "    # Number of samples.\n",
    "    N = len(y)\n",
    "\n",
    "    # Number of attributes.\n",
    "    attr = X.shape[1]\n",
    "\n",
    "    # Random initialization of parameters.\n",
    "    a = np.random.randn(attr, 1)\n",
    "\n",
    "    # Create vector for parameter history.\n",
    "    a_hist = np.zeros((attr, n_epochs*(N//mb_size)+1))\n",
    "    # Initialize history vector.\n",
    "    a_hist[:, 0] = a.reshape(attr,)\n",
    "\n",
    "    # Create array for storing error values.\n",
    "    Jgd = np.zeros(n_epochs*(N//mb_size)+1)\n",
    "\n",
    "    # Calcute the MSE for the very first weight vector.\n",
    "    Jgd[0] = (1.0/N)*sum(np.power(y - hypothesis(X, a), 2))\n",
    "\n",
    "    # Create array for storing gradient values.\n",
    "    grad_hist = np.zeros((attr, n_epochs*(N//mb_size)))\n",
    "\n",
    "    # Mini-batch gradient-descent loop.\n",
    "    inc = 0\n",
    "    for e in range(n_epochs):\n",
    "\n",
    "        # Shuffle the whole dataset before every epoch.\n",
    "        shuffled_data_set_indexes = random.sample(range(0, N), N)\n",
    "\n",
    "        for i in range(0, N//mb_size):\n",
    "\n",
    "            start = i*mb_size\n",
    "            end = mb_size*(i+1)\n",
    "            batch_indexes = shuffled_data_set_indexes[start:end]\n",
    "\n",
    "            xi = X[batch_indexes]\n",
    "            yi = y[batch_indexes]\n",
    "\n",
    "            gradients = -(2.0/mb_size)*xi.T.dot(yi - hypothesis(xi, a))\n",
    "            a = a - alpha*gradients\n",
    "\n",
    "            Jgd[inc+1] = (1.0/N)*sum(np.power((y - hypothesis(X, a)), 2))\n",
    "\n",
    "            grad_hist[:, inc] = gradients.reshape(attr,)\n",
    "            a_hist[:, inc+1] = a.reshape(attr,)\n",
    "\n",
    "            inc = inc + 1\n",
    "\n",
    "    return a, Jgd, a_hist, grad_hist, inc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45764460",
   "metadata": {
    "id": "45764460"
   },
   "source": [
    "4. Configure a versão do GD em mini-batches definida na célula de código acima para funcionar como a **versão estocástica** (GDE) e encontre os pesos da função hipótese.\n",
    "\n",
    "**Dicas**\n",
    "\n",
    "+ Não é necessário implementar código algum neste item. Mude apenas um dos parâmetros de entrada da função `gradientDescentMiniBatch`.\n",
    "+ Não se esqueça de criar a matriz de atributos seguindo o formato especificado para a função $g(x_1, x_2)$, o qual foi definido no item 2.\n",
    "   * Como a função $g(x_1, x_2)$ possui o peso de *bias*, $a_0$, você precisará criar a matriz de atributos concatenando **manualmente** o vetor de atributo de *bias*, $x_0$, (i.e., vetor com valores iguais a 1) com a matriz, $\\textbf{X}$, a qual contém os vetores de atributos $x_1$ e $x_2$. O exemplo abaixo mostra como isso pode ser feito.\n",
    "   ```python\n",
    "   # Attribute matrix.\n",
    "   Xnew = np.c_[np.ones((len(y),1)), X]\n",
    "   ```\n",
    "   * A concatenação é feita de forma manual, pois a implementação do gradiente descendente em mini-batches fornecida acima não faz isso automaticamente como no caso das classes fornecidas pela bilbioteca SciKit-Learn.\n",
    "+ Encontre os melhores valores para o número de épocas e passo de aprendizagem de forma que o algoritmo convirja.\n",
    "+ **O erro deve convergir para o valor 0, ou seja, ao final do treinamento o erro deve ser igual a 0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d963f",
   "metadata": {
    "id": "917d963f"
   },
   "outputs": [],
   "source": [
    "# Digite aqui o código do item."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b1b521",
   "metadata": {
    "id": "77b1b521"
   },
   "source": [
    "5. Plote a figure do erro em função das iterações de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c737c67",
   "metadata": {
    "id": "7c737c67"
   },
   "outputs": [],
   "source": [
    "# Digite aqui o código do item."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1121357c",
   "metadata": {
    "id": "1121357c"
   },
   "source": [
    "6. Execute a célula de código abaixo e analise o resultado.\n",
    "\n",
    "**Dicas**\n",
    "\n",
    "+ O código abaixo só irá funcionar caso você tenha implementado a função `hypothesis` corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79f68bd",
   "metadata": {
    "id": "c79f68bd",
    "outputId": "93334d7b-0ac2-48a2-e965-0ff39534e4c1"
   },
   "outputs": [],
   "source": [
    "# Point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "# Step size in the mesh\n",
    "h = .02\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "Z = hypothesis(np.c_[np.ones((len(xx.ravel()), 1)), xx.ravel(), yy.ravel()], a).reshape(len(xx.ravel()),)\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.pcolormesh(xx, yy, Z, cmap='Greys')\n",
    "\n",
    "# Plot also the training points\n",
    "plt.plot(X[idx0,0], X[idx0,1],'.b', label='Amostras com rótulo igual a 0')\n",
    "plt.plot(X[idx1,0], X[idx1,1],'.r', label='Amostras com rótulo igual a 1')\n",
    "plt.xlabel('$x_1$', fontsize=14)\n",
    "plt.ylabel('$x_2$', fontsize=14)\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c99d0",
   "metadata": {
    "id": "3b2c99d0"
   },
   "source": [
    "7. Execute a célula de código abaixo, analise os valores de saída das funções $g(x_1, x_2)$ e $f(z)$, respectivamente, para alguns pontos distintos (i.e., pares de atributos $x_1$ e $x_2$) e a figura com estes respectivos pontos.\n",
    "\n",
    "**Dicas**\n",
    "\n",
    "+ Os vetores de pontos são vetores linha com 3 elementos, $x_0$, $x_1$ e $x_2$, respectivamente, onde $x_0$ é sempre igual a 1.\n",
    "+ Perceba que se o ponto está à esquerda da mudança abrupta de cores (branco/preto) o valor de $g(x_1, x_2)$ é negativo e, consequentemente, $f(z)$ será igual a 0, de acordo com o que foi definido no item 2.\n",
    "+ Perceba que se o ponto está à direita da mudança abrupta de cores (branco/preto) o valor de $g(x_1, x_2)$ é positivo e, consequentemente, $f(z)$ será igual a 1, de acordo com o que foi definido no item 2.\n",
    "+ Perceba que se o ponto está praticamente em cima da mudança abrupta de cores (branco/preto) o valor de $g(x_1, x_2)$ é próximo de 0 e, consequentemente, $f(z)$ será igual a 1 devido à definição de $f(z)$ no item 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6761a2ac",
   "metadata": {
    "id": "6761a2ac",
    "outputId": "046aaa2d-440d-451d-f4b5-2420b4a67746"
   },
   "outputs": [],
   "source": [
    "# Ponto 1.\n",
    "p1 = np.array([[1, -3, -1]])\n",
    "print('Ponto 1: x0 = 1, x1 = -3, x2 = -1')\n",
    "g1 = p1.dot(a)[0,0]\n",
    "print('g(x1, x2):', g1)\n",
    "print('f(g(x1, x2)):', np.heaviside(g1, 1))\n",
    "print('\\n')\n",
    "\n",
    "# Ponto 2.\n",
    "p2 = np.array([[1, 8, 8]])\n",
    "print('Ponto 2: x0 = 1, x1 = 8, x2 = 8')\n",
    "g2 = p2.dot(a)[0,0]\n",
    "print('g(x1, x2):', g2)\n",
    "print('f(g(x1, x2)):', np.heaviside(g2, 1))\n",
    "print('\\n')\n",
    "\n",
    "# Ponto 3.\n",
    "p3 = np.array([[1, 6, -0.06]])\n",
    "print('Ponto 3: x0 = 1, x1 = 6, x2 = -0.06')\n",
    "g3 = p3.dot(a)[0,0]\n",
    "print('g(x1, x2):', g3)\n",
    "print('f(g(x1, x2)):', np.heaviside(g3, 1))\n",
    "\n",
    "# Put the result into a color plot\n",
    "plt.pcolormesh(xx, yy, Z, cmap='Greys')\n",
    "\n",
    "# Plot the points\n",
    "plt.plot(p1[0, 1], p1[0, 2], '*r', markersize=10, label='Ponto 1')\n",
    "plt.plot(p2[0, 1], p2[0, 2], '<b', markersize=10, label='Ponto 2')\n",
    "plt.plot(p3[0, 1], p3[0, 2], 'og', markersize=10, label='Ponto 3')\n",
    "plt.xlabel('$x_1$', fontsize=14)\n",
    "plt.ylabel('$x_2$', fontsize=14)\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e52ce",
   "metadata": {
    "id": "9f5e52ce"
   },
   "source": [
    "8. Após analisar os resultados anteriores, responda:\n",
    "\n",
    "+ O que você pode concluir após observar os resultado anteriores (as perguntas abaixo vão te ajudar a chegar a uma conclusão)?\n",
    "    + A função hipótese encontrada com o GDE se aproxima das distribuições das amostras, ou seja, ela explica as amostras coletadas ou separa as distribuições?\n",
    "    + Veja que as duas figuras anteriores (itens 6 e 7) apresentam uma mudança (divisão) abrupta de cores (branco/preto). Quem define essa mudança abrupta de cores (a definição da função hipótese no item 2 e os pontos/valores plotados no item 7 vão te ajudar a responder esta pergunta)?\n",
    "    + Lembrando da nossa primeira aula, onde discutimos o paradigma do aprendizado supervisionado, que tipo de problema está sendo resolvido neste exercício (reveja o slide sobre aprendizado supervisionado)?\n",
    "\n",
    "**Justifique todas as suas respostas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df175d",
   "metadata": {
    "id": "a3df175d"
   },
   "source": [
    "**Resposta**\n",
    "\n",
    "<span style=\"color:blue\">Digite abaixo a resposta do exercício.</span>\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
