{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final (1S2021)\n",
    "\n",
    "### Instruções\n",
    "\n",
    "1. Quando você terminar os exercícios do projeto, vá até o menu do Jupyter ou Colab e selecione a opção para fazer download do notebook.\n",
    "    * Os notebooks tem extensão .ipynb. \n",
    "    * Este deve ser o arquivo que você irá entregar.\n",
    "    * No Jupyter vá até a opção **File** -> **Download as** -> **Notebook (.ipynb)**.\n",
    "    * No Colab vá até a opção **File** -> **Download .ipynb**.\n",
    "2. Após o download do notebook, vá até a aba de tarefas do MS Teams, localize a tarefa referente a este projeto e faça o upload do seu notebook. Veja que há uma opção de anexar arquivos à tarefa.\n",
    "3. Atente-se ao prazo de entrega definido na tarefa do MS Teams. Entregas fora do prazo não serão aceitas.\n",
    "4. **O projeto pode ser resolvido em grupos de no MÁXIMO 3 alunos**.\n",
    "5. Todas as questões têm o mesmo peso.\n",
    "6. Não se esqueça de colocar seu(s) nome(s) e número(s) de matrícula no campo abaixo. Substitua os nomes que já estão no campo abaixo.\n",
    "7. Você pode consultar todo o material de aula.\n",
    "8. A interpretação faz parte do projeto. Leia o enunciado de cada questão atentamente!\n",
    "9. Boa sorte!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nomes e matrículas**:\n",
    "\n",
    "1. Nome do primeiro aluno - Matrícula do primeiro aluno\n",
    "2. Nome do segundo aluno - Matrícula do segundo aluno\n",
    "3. Nome do terceiro aluno - Matrícula do terceiro aluno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1)  Neste exercício, você irá utilizar estratégias de validação cruzada para encontrar a ordem ideal para uma função hipótese que será usada para aproximar um conjunto de dados ruidoso.\n",
    "\n",
    "A **função observável** deste exercício é gerada utilizando-se a função `generateDataSet` do módulo `util_functions`.\n",
    "\n",
    "A **função hipótese** para este exercício é **polinomial** e tem a seguinte forma\n",
    "\n",
    "$$h(n) = a_0 + a_1 x(n) + a_2 x(n)^2 + \\cdots + a_M x(n)^M.$$\n",
    "\n",
    "A tarefa aqui é encontrar o valor ideal para $M$, ou seja, a ordem da função hipótese polinomial de tal forma que ela consiga aproximar bem os dados observados.\n",
    "\n",
    "**DICAS**:\n",
    "\n",
    "+ Para gerar os valores de $x$, $y$ e $y_{noisy}$ use a função `generateDataSet` passando como parâmetro de entrada o número do seu grupo.\n",
    "+ Para resolver as questões deste exercício, se baseie no código do seguinte exemplo: [validacao_cruzada.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/master/notebooks/regression/validacao_cruzada.ipynb).\n",
    "+ Todas as funções usadas neste laboratório estão definidas no arquivo `util_functions.py`, que se encontra na mesma pasta que este notebook. **SOB NENHUMA HIPÓTESE, O ALTERE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De posse destas informações, faça o seguinte:\n",
    "\n",
    "1. Execute o trecho de código abaixo e analise os resultados gerados.\n",
    "\n",
    "**DICA**\n",
    "+ Não se esqueça de definir o número do seu grupo na célula abaixo e executá-la a fim de atribuir o valor à variável `groupNumber`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Atribua o número do seu grupo à variável abaixo.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupNumber = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "!git clone https://github.com/zz4fap/t319_aprendizado_de_maquina.git\n",
    "import sys\n",
    "sys.path.insert(0,'./t319_aprendizado_de_maquina/projeto/')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeavePOut\n",
    "import util_functions as util\n",
    "\n",
    "# Reset PN sequence generator.\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Number of examples.\n",
    "N = 1000\n",
    "\n",
    "# Generate datase.\n",
    "x, y, y_noisy = util.generateDataSet(groupNumber, N)\n",
    "\n",
    "# Plot comparison between true and noisy model.\n",
    "plt.plot(x, y_noisy, '.', label='Noisy signal')\n",
    "plt.plot(x, y, label='True signal', linewidth=4)\n",
    "plt.xlabel('$x$', fontsize=14)\n",
    "plt.ylabel('$y$', fontsize=14)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Usando a estratégia de validação cruzada conhecida como **holdout**, encontre a ordem ideal para que uma função hipótese polinomial aproxime bem o conjunto de dados gerado no exercício anterior. Para avaliar qual é a ordem ideal para o polinômio aproximador, plote a curva do erro quadrático médio (MSE) versus a ordem do polinômio.\n",
    "\n",
    "**DICAS**\n",
    "+ Use o **holdout** com 70% do conjunto original para treinamento e 30% para validação.\n",
    "+ Analise polinômios com ordens variando de 1 até e **incluindo** 30.\n",
    "+ Configure o parâmetro `include_bias` da classe `PolynomialFeatures` para `True`, ou seja, `include_bias=True`.\n",
    "+ Use a função `plotHoldOutResults` do módulo `util_functions` que foi importado como `util` para plotar os resultados obtidos com o **holdout**. A função espera 3 parâmetros de entrada, na seguinte sequência: \n",
    "    * **poly_orders**: lista com as ordens dos polinômios sendo testados.\n",
    "    * **mse_train_vec**: vetor com os valores do MSE obtido com o conjunto de treinamento para cada uma das ordens testadas.\n",
    "    * **mse_val_vec**: vetor com os valores do MSE obtido com o conjunto de validação para cada uma das ordens testadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Usando a estratégia de validação cruzada conhecida como **k-Fold**, encontre a ordem ideal para que uma função hipótese polinomial aproxime bem o conjunto de dados gerado no exercício anterior. Para avaliar qual é a ordem ideal para o polinômio aproximador, plote as curvas da média do erro quadrático médio (MSE) versus a ordem do polinômio e do desvio padrão versus a ordem do polinômio.\n",
    "\n",
    "**DICAS**\n",
    "+ Use o **k-Fold** com **k** igual a 10.\n",
    "+ Configure o parâmetro `shuffle` da classe `KFold` como `True`, ou seja, `shuffle=True`.\n",
    "+ Analise polinômios com ordens variando de 1 até e **incluindo** 30.\n",
    "+ Configure o parâmetro `include_bias` da classe `PolynomialFeatures` para `True`, ou seja, `include_bias=True`.\n",
    "+ Use a função `plotKFoldResults` do módulo `util_functions` que foi importado como `util` para plotar os resultados obtidos com o **holdout**. A função espera 3 parâmetros de entrada, na seguinte sequência: \n",
    "    * **poly_orders**: lista com as ordens dos polinômios sendo testados.\n",
    "    * **kfold_mean_vec**: vetor com os valores da média do MSE obtidos para cada ordem testada.\n",
    "    * **kfold_std_vec**: vetor com os valores do desvio padrão do MSE obtidos para cada ordem testada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Usando a estratégia de validação cruzada conhecida como **leave-p-out**, encontre a ordem ideal para que uma função hipótese polinomial aproxime bem o conjunto de dados gerado no exercício anterior. Para avaliar qual é a ordem ideal para o polinômio aproximador, plote as curvas da média do erro quadrático médio (MSE) versus a ordem do polinômio e do desvio padrão versus a ordem do polinômio.\n",
    "\n",
    "**DICAS**\n",
    "+ Use o **leave-p-out** com **p** igual a 1.\n",
    "+ Analise polinômios com ordens variando de 1 até e **incluindo** 30.\n",
    "+ Configure o parâmetro `include_bias` da classe `PolynomialFeatures` para `True`, ou seja, `include_bias=True`.\n",
    "+ Use a função `plotLeavePOutResults` do módulo `util_functions` que foi importado como `util` para plotar os resultados obtidos com o **holdout**. A função espera 3 parâmetros de entrada, na seguinte sequência: \n",
    "    * **poly_orders**: lista com as ordens dos polinômios sendo testados.\n",
    "    * **lpo_mean_vec**: vetor com os valores da média do MSE obtidos para cada ordem testada.\n",
    "    * **lpo_std_vec**: vetor com os valores do desvio padrão do MSE obtidos para cada ordem testada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Após analisar os resultados obtidos com as validações cruzadas do **holdout**, **k-Fold** e **leave-p-out**, reponda qual é a melhor ordem de polinômio para aproximar os dados. **Justifique sua resposta.**\n",
    "\n",
    "**Dica**\n",
    "* Lembre-se do princípio da navalha de Occam para escolher a melhor ordem.\n",
    "* Comente sobre a flexibilidade e grau de generalização do modelo escolhido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Em seguida, de posse da melhor ordem de polinômio que aproxima os dados observados, faça:\n",
    "+ Treine um modelo, \n",
    "+ Realize predições (ou seja, use o modelo treinado para **predizer** os valores de $y$ com os valores de $x$.) com todos os dados observados, ou seja, $x$.\n",
    "+ Plote um gráfico que compare o mapeamento verdadeiro com as versões ruidosa e predita dos dados.\n",
    "\n",
    "**Dica:**\n",
    "\n",
    "* Utilize **padronização de atributos** com a classe `StandardScaler` da biblioteca SciKit-Learn.\n",
    "* Crie uma sequência de ações (`PolynomialFeatures`, `StandardScaler` e `LinearRegression`) utilizando a classe `Pipeline` da biblioteca SciKit-Learn para realizar a regressão. Veja o notebook de exemplo.\n",
    "+ Configure o parâmetro `include_bias` da classe `PolynomialFeatures` para `True`, ou seja, `include_bias=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2)  Neste exercício, você irá utilizar regressão com regularização L1, ou seja, regressão LASSO,  para encontrar uma função hipótese regularizada que aproxime um conjunto de dados ruidoso.\n",
    "\n",
    "A **função observável** deste exercício é gerada utilizando-se a função `generateDataSet2` do módulo `util_functions`.\n",
    "\n",
    "A **função hipótese** para este exercício é **polinomial** e tem a seguinte forma\n",
    "\n",
    "$$h(n) = a_0 + a_1 x(n) + a_2 x(n)^2 + \\cdots + a_M x(n)^M,$$\n",
    "\n",
    "onde $M = 30$.\n",
    "\n",
    "Os pesos da função hipótese acima são encontrados minimizando-se o seguinte problema de regularização\n",
    "\n",
    "$$\\min_{\\textbf{a}~\\in~\\mathbb{R}}(\\|y_{noisy} - h \\|^2 + \\lambda\\| \\textbf{a} \\|_{1}).$$\n",
    "\n",
    "A tarefa aqui é encontrar o valor ideal para $\\lambda$, ou seja, o fator de regularização, de tal forma que a função hipótese consiga aproximar bem os dados observados.\n",
    "\n",
    "**DICAS**:\n",
    "\n",
    "+ Para gerar os conjuntos de treinamento e teste use a função `generateDatasets2` passando como parâmetro de entrada o número do seu grupo.\n",
    "+ Para resolver as questões deste laboratório, se baseie no código do seguinte exemplo: [regressao_lasso.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/master/notebooks/regression/regressao_lasso.ipynb).\n",
    "+ Todas as funções usadas para gerar gráficos neste laboratório estão definidas no arquivo `util_functions.py`, que se encontra na mesma pasta que este notebook. **SOB NENHUMA HIPÓTESE, O ALTERE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De posse destas informações, faça o seguinte:\n",
    "\n",
    "1. Execute o trecho de código abaixo e analise os resultados gerados.\n",
    "\n",
    "**DICA**\n",
    "+ Não se esqueça de definir o número do seu grupo na célula abaixo e executá-la a fim de atribuir o valor à variável `groupNumber`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Atribua o número do seu grupo à variável abaixo.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupNumber = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "!git clone https://github.com/zz4fap/t319_aprendizado_de_maquina.git\n",
    "import sys\n",
    "sys.path.insert(0,'./t319_aprendizado_de_maquina/projeto/')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeavePOut\n",
    "from sklearn.linear_model import Lasso\n",
    "import util_functions as util\n",
    "\n",
    "# Reset PN sequence generator.\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Number of examples.\n",
    "N = 100\n",
    "\n",
    "# Generate dataset.\n",
    "x_train, y_train, y_train_noisy, x_test, y_test_noisy = util.generateDatasets2(groupNumber, N)\n",
    "\n",
    "# Plot comparison between true and noisy model.\n",
    "plt.plot(x_train, y_train_noisy, '.', label='Noisy signal')\n",
    "plt.plot(x_train, y_train, label='True signal', linewidth=4)\n",
    "plt.xlabel('$x$', fontsize=14)\n",
    "plt.ylabel('$y$', fontsize=14)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Utilizando as classes `PolynomialFeatures`, `StandardScaler` e `LinearRegression` da biblioteca SciKit-Learn, treine um modelo de regressão linear com uma função hipótese polinomial de ordem igual a **30**. Em seguida, crie um gráfico comparando as versões original, ruidosa e as obtidas com o modelo treinado tanto com a base de treinamento quanto com a de teste (ou validação).\n",
    "\n",
    "**DICAS**\n",
    "+ Perceba que esta será uma regressão linear sem regularização.\n",
    "+ Crie uma sequência de ações (`PolynomialFeatures`, `StandardScaler` e `LinearRegression`) utilizando a classe `Pipeline` da biblioteca SciKit-Learn para realizar a regressão. Veja o notebook de exemplo.\n",
    "+ Configure o parâmetro `include_bias` da classe `PolynomialFeatures` para `True`, ou seja, `include_bias=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Após analisar o gráfico acima, responda:\n",
    "\n",
    "* O que você conclui sobre o comportamento do modelo? \n",
    "* O que pode ser feito para melhorar este comportamento, caso ele não seja o comportamento ideal?\n",
    "\n",
    "**Justifique todas as suas respostas**.\n",
    "\n",
    "**DICA**\n",
    "+ Verifique se o modelo está subajustando, sobreajustando ou se encontrou um balanço entre grau de generaliação e flexibilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Neste item, você irá realizar a busca logarítmica pelo valor ideal de $\\lambda$. Faça o seguinte:\n",
    "    * Crie um vetor com $M = 1000$ valores no intervalo de 1e-10 até 100 em **escala logarítmica**. \n",
    "    * Use um laço de repetição para treinar modelos de regressão LASSO com cada um dos $M$ valores de $\\lambda$.     \n",
    "    * Com cada um dos valores de $\\lambda$, treine um modelo de regressão linear com regularização LASSO com os dados de treinamento. \n",
    "    * Armazene os valores dos pesos, da norma L1 dos pesos e do erro quadrático médio (MSE) de treinamento e de teste para cada valor de $\\lambda$.\n",
    "    * Após ter treinado e calculado os erros para os vários valores de $\\lambda$, encontre e imprima o valor de $\\lambda$ que resulta no menor erro com o conjunto de testes.\n",
    "\n",
    "**DICAS**\n",
    "+ Use a função `logspace` da biblioteca NumPy para gerar o vetor de valores de $\\lambda$.\n",
    "+ Use a classe `Lasso` da biblioteca SciKit-Learn.\n",
    "+ Utilize padronização para escalonar os atributos.\n",
    "+ Use uma sequência de ações (`PolynomialFeatures`, `StandardScaler` e `Lasso`) utilizando a classe `Pipeline` da biblioteca SciKit-Learn para realizar a regressão com regularização. Veja o notebook de exemplo.\n",
    "+ Configure o parâmetro `include_bias` da classe `PolynomialFeatures` para `True`, ou seja, `include_bias=True`.\n",
    "+ Se o seguinte warning ocorrer durante o treinamento: `ConvergenceWarning: Objective did not converge.`, aumente a tolerância (parâmetro `tol`) da classe `Lasso`. Por exemplo, se ela estiver em `tol=1e-2` aumente para `tol=1e-1`, e assim por diante até um valor máximo igual a `tol=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Crie 3 gráficos que mostrem (i) a variação dos pesos em função de $\\lambda$, (ii) a variação da norma L1 dos pesos em função de $\\lambda$ e (iii) a variação do MSE de treinamento e de teste em função dos valores de $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Neste item, você irá realizar o ajuste fino do valor de $\\lambda$ baseado no valor encontrado através da busca logarítmica. Faça o seguinte:\n",
    "    * Crie um vetor com $M = 1000$ valores no intervalo de $\\lambda_{log}/10$ até $10 \\lambda_{log}$ em **escala linear**. \n",
    "    * Use um laço de repetição para treinar modelos de regressão LASSO com cada um dos $M$ valores de $\\lambda$.     \n",
    "    * Com cada um dos valores de $\\lambda$, treine um modelo de regressão linear com regularização LASSO com os dados de treinamento. \n",
    "    * Armazene os valores dos pesos, da norma L1 dos pesos e do erro quadrático médio (MSE) de treinamento e de teste para cada valor de $\\lambda$.\n",
    "    * Após ter treinado e calculado os erros para os vários valores de $\\lambda$, encontre e imprima o valor de $\\lambda$ que resulta no menor erro com o conjunto de testes.\n",
    "\n",
    "**DICAS**\n",
    "+ Use a função `linspace` da biblioteca NumPy para gerar o vetor de valores de $\\lambda$.\n",
    "+ Use a classe `Lasso` da biblioteca SciKit-Learn.\n",
    "+ Utilize padronização para escalonar os atributos.\n",
    "+ Use uma sequência de ações (`PolynomialFeatures`, `StandardScaler` e `Lasso`) utilizando a classe `Pipeline` da biblioteca SciKit-Learn para realizar a regressão com regularização. Veja o notebook de exemplo.\n",
    "+ Configure o parâmetro `include_bias` da classe `PolynomialFeatures` para `True`, ou seja, `include_bias=True`.\n",
    "+ Se o seguinte warning ocorrer durante o treinamento: `ConvergenceWarning: Objective did not converge.`, aumente a tolerância (parâmetro `tol`) da classe `Lasso`. Por exemplo, se ela estiver em `tol=1e-2` aumente para `tol=1e-1`, e assim por diante até um valor máximo igual a `tol=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Neste item, você irá verificar a aproximação do modelo de regressão polinomial com regularização LASSO utilizando o valor de $\\lambda$ encontrado o item anterior. Faça o seguinte:    \n",
    "    * Com o valor ideal de $\\lambda$ encontrado no item anterior, treine um modelo de regressão linear com regularização LASSO com os dados de treinamento. \n",
    "    * Crie um gráfico comparando as versões original, ruidosa e as obtidas com o modelo treinado tanto com a base de treinamento quanto com a de teste (ou validação).\n",
    "    \n",
    "**DICAS**\n",
    "+ Use a classe `Lasso` da biblioteca SciKit-Learn.\n",
    "+ Utilize padronização para escalonar os atributos.\n",
    "+ Use uma sequência de ações (`PolynomialFeatures`, `StandardScaler` e `Lasso`) utilizando a classe `Pipeline` da biblioteca SciKit-Learn para realizar a regressão com regularização. Veja o notebook de exemplo.\n",
    "+ Configure o parâmetro `include_bias` da classe `PolynomialFeatures` para `True`, ou seja, `include_bias=True`.\n",
    "+ Se o seguinte warning ocorrer durante o treinamento: `ConvergenceWarning: Objective did not converge.`, aumente a tolerância (parâmetro `tol`) da classe `Lasso`. Por exemplo, se ela estiver em `tol=1e-2` aumente para `tol=1e-1`, e assim por diante até um valor máximo igual a `tol=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Crie um gráfico mostrando a importância dos atributos do modelo através do valor absoluto de seus respectivos pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Após analisar os gráfico obtidos nos itens 2, 7 e 8 deste exercício, responda:\n",
    "\n",
    "* O que você conclui sobre o comportamento do modelo treinado com regularização L1 (ou seja, LASSO)? \n",
    "\n",
    "**Justifique sua resposta**.\n",
    "\n",
    "**DICA**\n",
    "+ Verifique se o modelo está subajustando, sobreajustando ou se encontrou um balanço entre grau de generaliação e flexibilidade.\n",
    "+ Verifique o que houve com os pesos no gráfico de importância dos atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3)  Neste exercício, você irá utilizar estratégias de validação cruzada para encontrar a ordem ideal para uma função hipótese que será usada para aproximar o conjunto de dados do Boston Housing e prever o custo médio de uma casa em uma área de Boston. O objetivo é prever o valor dos preços de casas usando os atributos fornecidos.\n",
    "\n",
    "Esta base de dados contém informações do censo dos EUA relativos a casas em várias áreas da cidade de Boston. Cada exemplo corresponde a uma área única e possui 13 medidas. Devemos pensar em exemplos como linhas e medidas como colunas da base de dados. A base de dados do Boston Housing é um das várias bases de dados disponibilizadas pela biblioteca SciKit-Learn. \n",
    "\n",
    "A base de dados possui 506 exemplos e 13 atributos numéricos. O décimo quarto atributo (i.e., MEDV: Median value of owner-occupied homes in USD 1000's) é considerado como sendo o rótulo, ou seja, o valor que queremos prever com o modelo. A descrição das informações contidas no banco de dados segue abaixo.\n",
    "\n",
    "| Attribute |                              Description                              |\n",
    "|:---------:|:---------------------------------------------------------------------:|\n",
    "|    CRIM   |                     per capita crime rate by town                     |\n",
    "|     ZN    |    proportion of residential land zoned for lots over 25,000 sq.ft.   |\n",
    "|   INDUS   |            proportion of non-retail business acres per town           |\n",
    "|    CHAS   | Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) |\n",
    "|    NOX    |           nitric oxides concentration (parts per 10 million)          |\n",
    "|     RM    |                  average number of rooms per dwelling                 |\n",
    "|    AGE    |         proportion of owner-occupied units built prior to 1940        |\n",
    "|    DIS    |          weighted distances to five Boston employment centres         |\n",
    "|    RAD    |               index of accessibility to radial highways               |\n",
    "|    TAX    |                full-value property-tax rate per USD 10.000               |\n",
    "|  PTRATIO  |                      pupil-teacher ratio by town                      |\n",
    "|     B     |  1000(Bk - 0.63)^2 where Bk is the proportion of black people by town |\n",
    "|   LSTAT   |                     lower status of the population                    |\n",
    "|    MEDV   |            Median value of owner-occupied homes in USD 1000's            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Execute a célula abaixo para importar o conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "!git clone https://github.com/zz4fap/t319_aprendizado_de_maquina.git\n",
    "import sys\n",
    "sys.path.insert(0,'./t319_aprendizado_de_maquina/projeto/')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import util_functions as util\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Reset PN sequence generator.\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Load the dataset.\n",
    "dataset = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Na sequência, faremos uma análise exploratória simplificada dos dados para escolhermos quais são os melhores atributos para serem usados para a aproximação do preço médio dado pelo atributo **MEDV**. \n",
    "\n",
    "+ No trecho de código abaixo, para facilitar o processamento dos dados, transformamos a base de dados em um objeto do tipo `DataFrame` da biblioteca `pandas`, em seguida, criamos uma matriz de correlação que mede as relações lineares entre os atributos, incluindo o rótulo. A matriz de correlação é criada usando-se a função `corr` da biblioteca `pandas`. \n",
    "+ Usamos a função `heatmap` (mapa de calor) da biblioteca `seaborn` para plotar a matriz de correlação.\n",
    "+ A matriz de correlação vai nos ajudar a entender a relação do rótulo com os atributos.\n",
    "\n",
    "Execute o trecho de código abaixo e analise a matriz de correlação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries.\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data into a pandas dataframe using pd.DataFrame.\n",
    "boston = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "\n",
    "# Create a new column of target values and add it to the dataframe.\n",
    "boston['MEDV'] = dataset.target\n",
    "\n",
    "# Create a correlation matrix\n",
    "correlation_matrix = boston.corr().round(2)\n",
    "# Plot the correlation matrix.\n",
    "plt.figure(figsize=(10,5))\n",
    "# annot = True to print the values inside the square\n",
    "sns.heatmap(data=correlation_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Agora, baseado em nossa análise da matriz de correlação, iremos escolher **2** atributos que têm maior correlação com o objetivo, ou seja, o rótulo **MEDV**. Seguem algumas dicas de como essa escolha deve ser feita:\n",
    "\n",
    "+ Os coeficientes de correlação (ou seja, os valores mostrados na matriz de correlação) variam de -1 a 1. Se o valor for próximo a 1, significa que há uma forte correlação positiva entre as duas variáveis. Quando é próximo a -1, as variáveis apresentam forte correlação negativa.\n",
    "+ Para treinar um modelo de regressão linear, selecionamos os atributos que têm uma alta correlação (tanto positiva quanto negativa) com nossa variável-alvo **MEDV**. \n",
    "\n",
    "Após observar os coeficientes de correlação da matriz, quais são os 2 atributos com maior correlação com o rótulo, **MEDV**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Agora iremos preparar os dados para treinar o modelo de regressão. Precisamos criar uma matriz de atributos, $X$, com os 2 atributos escolhidos e o vetor de rótulos, $y$, com os valores de **MEDV**.\n",
    "\n",
    "**DICAS**\n",
    "+ Para concatenar os colunas dos atributos escolhidos, usamos `np.c_` fornecido pela biblioteca numpy. Segue um exemplo de uso:\n",
    "```python\n",
    "N = 10\n",
    "x1 = np.random.rand(N,1) # vetor coluna com N linhas e 1 coluna\n",
    "x2 = np.random.rand(N,1) # vetor coluna com N linhas e 1 coluna\n",
    "X = np.c_[x1,x2]\n",
    "```\n",
    "+ A matriz de atributos, $X$, resultante deve ter 506 linhas por 2 coluna. O vetor de rótulos, $y$, deve ter uma única dimensão, com 506 valores. Imprima as dimensões dos dois vetores com o atributo `shape`.\n",
    "+ As colunas com os valores dos atributos escolhidos podem ser obtidas a partir do objeto `boston` (que é do tipo `DataFrame` da biblioteca `pandas`) da mesma forma que acessamos valores de um dicionário Python, ou seja, utilizamos a `chave`, que no caso é o nome do atributo, para obtermos a coluna de valores associados àquele atributo. A mesma coisa deve ser feita para o rótulo, o qual foi concatenado ao objeto `boston` para que conseguíssemos criar a matriz de correlação. Veja o exemplo abaixo que obtem a coluna de valores referentes ao rótulo `MEDV`:\n",
    "```python\n",
    "y = boston['MEDV']\n",
    "```\n",
    "\n",
    "Portanto, crie na célula abaixo a matriz de atributos `X` e o vetor de rótulos $y$. Não se esqueça de imprimir as dimensões da matriz e do vetor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Usando a estratégia de validação cruzada conhecida como **holdout**, encontre a ordem ideal para que uma função hipótese polinomial aproxime bem o conjunto de dados. Para avaliar qual é a ordem ideal para o polinômio aproximador, plote a curva do erro quadrático médio (MSE) versus a ordem do polinômio.\n",
    "\n",
    "**DICAS**\n",
    "+ Use o **holdout** com 70% do conjunto original para treinamento e 30% para validação.\n",
    "+ Analise polinômios com ordens variando de 1 até e **incluindo** 10.\n",
    "+ Configure o parâmetro `include_bias` da classe `PolynomialFeatures` para `True`, ou seja, `include_bias=True`.\n",
    "+ Use a função `plotHoldOutResultsv2` do módulo `util_functions` que foi importado como `util` para plotar os resultados obtidos com o **holdout**. A função espera 3 parâmetros de entrada, na seguinte sequência: \n",
    "    * **poly_orders**: lista com as ordens dos polinômios sendo testados.\n",
    "    * **mse_train_vec**: vetor com os valores do MSE obtido com o conjunto de treinamento para cada uma das ordens testadas.\n",
    "    * **mse_val_vec**: vetor com os valores do MSE obtido com o conjunto de validação para cada uma das ordens testadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Usando a estratégia de validação cruzada conhecida como **k-Fold**, encontre a ordem ideal para que uma função hipótese polinomial aproxime bem o conjunto de dados. Para avaliar qual é a ordem ideal para o polinômio aproximador, plote as curvas da média do erro quadrático médio (MSE) versus a ordem do polinômio e do desvio padrão versus a ordem do polinômio.\n",
    "\n",
    "**DICAS**\n",
    "+ Use o **k-Fold** com **k** igual a 5.\n",
    "+ Configure o parâmetro `shuffle` da classe `KFold` como `True`, ou seja, `shuffle=True`.\n",
    "+ Analise polinômios com ordens variando de 1 até e **incluindo** 10.\n",
    "+ Configure o parâmetro `include_bias` da classe `PolynomialFeatures` para `True`, ou seja, `include_bias=True`.\n",
    "+ Use a função `plotKFoldResultsv2` do módulo `util_functions` que foi importado como `util` para plotar os resultados obtidos com o **holdout**. A função espera 3 parâmetros de entrada, na seguinte sequência: \n",
    "    * **poly_orders**: lista com as ordens dos polinômios sendo testados.\n",
    "    * **kfold_mean_vec**: vetor com os valores da média do MSE obtidos para cada ordem testada.\n",
    "    * **kfold_std_vec**: vetor com os valores do desvio padrão do MSE obtidos para cada ordem testada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Após analisar os resultados obtidos com as validações cruzadas do **holdout** e **k-Fold**, reponda qual é a melhor ordem de polinômio para aproximar os dados. **Justifique sua resposta.**\n",
    "\n",
    "**Dica**\n",
    "* Lembre-se do princípio da navalha de Occam para escolher a melhor ordem.\n",
    "* Comente sobre a flexibilidade e grau de generalização do modelo escolhido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Em seguida, de posse da melhor ordem de polinômio que aproxima os dados observados, faça:\n",
    "+ Treine um modelo, \n",
    "+ Realize predições (ou seja, use o modelo treinado para **predizer** os valores de $y$ com os valores de $X$.) com todos os dados observados, ou seja, $X$.\n",
    "+ Imprima o erro quadrático médio, **MSE** entre a predição e os valores esperados, ou seja, o vetor $y$.\n",
    "\n",
    "**Dica:**\n",
    "\n",
    "* Utilize **padronização de atributos** com a classe `StandardScaler` da biblioteca SciKit-Learn.\n",
    "* Crie uma sequência de ações (`PolynomialFeatures`, `StandardScaler` e `LinearRegression`) utilizando a classe `Pipeline` da biblioteca SciKit-Learn para realizar a regressão.\n",
    "+ Configure o parâmetro `include_bias` da classe `PolynomialFeatures` para `True`, ou seja, `include_bias=True`.\n",
    "+ Para calcular o erro quadrático médio, **MSE**, entre a predição e os valores esperados use a função `mean_squared_error` do módulo `sklearn.metrics`. Note que ela já foi importada, então, apenas a invoque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. E se acrescentássemos um terceiro atribuito à matriz de atributos $X$, o erro quadrático médio seria menor?\n",
    "\n",
    "\n",
    "**DICAS**\n",
    "\n",
    "+ Volte ao item onde plotamos a matriz de correlação e encontre um terceiro atributo que possui um coeficiente de correlação (positivo ou negativo) alto.\n",
    "+ A matriz de atributos, $X$, resultante deve ter 506 linhas por 3 coluna. O vetor de rótulos, $y$, deve ter uma única dimensão, com 506 valores. Imprima as dimensões dos dois vetores com o atributo `shape`.\n",
    "\n",
    "Portanto, crie na célula abaixo a nova matriz de atributos `X` e o vetor de rótulos $y$. Não se esqueça de imprimir as dimensões da matriz e do vetor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Usando a estratégia de validação cruzada conhecida como **k-Fold**, encontre a ordem ideal para que uma função hipótese polinomial aproxime bem o conjunto de dados. Para avaliar qual é a ordem ideal para o polinômio aproximador, plote as curvas da média do erro quadrático médio (MSE) versus a ordem do polinômio e do desvio padrão versus a ordem do polinômio.\n",
    "\n",
    "**DICAS**\n",
    "+ Use o **k-Fold** com **k** igual a 5.\n",
    "+ Configure o parâmetro `shuffle` da classe `KFold` como `True`, ou seja, `shuffle=True`.\n",
    "+ Analise polinômios com ordens variando de 1 até e **incluindo** 10.\n",
    "+ Configure o parâmetro `include_bias` da classe `PolynomialFeatures` para `True`, ou seja, `include_bias=True`.\n",
    "+ Use a função `plotKFoldResultsv2` do módulo `util_functions` que foi importado como `util` para plotar os resultados obtidos com o **holdout**. A função espera 3 parâmetros de entrada, na seguinte sequência: \n",
    "    * **poly_orders**: lista com as ordens dos polinômios sendo testados.\n",
    "    * **kfold_mean_vec**: vetor com os valores da média do MSE obtidos para cada ordem testada.\n",
    "    * **kfold_std_vec**: vetor com os valores do desvio padrão do MSE obtidos para cada ordem testada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Em seguida, de posse da melhor ordem de polinômio que aproxima os dados observados, faça:\n",
    "+ Treine um modelo, \n",
    "+ Realize predições (ou seja, use o modelo treinado para **predizer** os valores de $y$ com os valores de $X$.) com todos os dados observados, ou seja, $X$.\n",
    "+ Imprima o erro quadrático médio, **MSE** entre a predição e os valores esperados, ou seja, o vetor $y$.\n",
    "\n",
    "**Dica:**\n",
    "\n",
    "* Utilize **padronização de atributos** com a classe `StandardScaler` da biblioteca SciKit-Learn.\n",
    "* Crie uma sequência de ações (`PolynomialFeatures`, `StandardScaler` e `LinearRegression`) utilizando a classe `Pipeline` da biblioteca SciKit-Learn para realizar a regressão.\n",
    "+ Configure o parâmetro `include_bias` da classe `PolynomialFeatures` para `True`, ou seja, `include_bias=True`.\n",
    "+ Para calcular o erro quadrático médio, **MSE**, entre a predição e os valores esperados use a função `mean_squared_error` do módulo `sklearn.metrics`. Note que ela já foi importada, então, apenas a invoque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digite o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Neste exercício, você irá usar a classe `SGDRegressor` da biblioteca SciKit-Learn para resolver um problema de regressão linear. \n",
    "\n",
    "O link abaixo contém a versão mais recente da documentação da classe `SGDRegressor`. Antes de resolver o exercício, faça uma leitura rápida da documentação. \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html\n",
    "\n",
    "**DICA**: \n",
    "* Use o exemplo [SGD_with_scikit_learn_lib.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/master/notebooks/regression/gd_versions/SGD_with_scikit_learn_lib.ipynb) como modelo para resolução deste exercício.\n",
    "\n",
    "Em seguida, faça o seguinte:\n",
    "\n",
    "1. Analise e execute o trecho de código abaixo para gerar o conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries.\n",
    "!git clone https://github.com/zz4fap/t319_aprendizado_de_maquina.git\n",
    "import sys\n",
    "sys.path.insert(0,'./t319_aprendizado_de_maquina/projeto/')\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Número de exemplos.\n",
    "N = 30\n",
    "\n",
    "# Atributo.\n",
    "x = np.linspace(-1,1,N).reshape(N,1)\n",
    "\n",
    "# Ruído.\n",
    "w = np.random.randn(N, 1)\n",
    "\n",
    "# Modelo gerador.\n",
    "y = 1 + 0.5*x + 2*(x**2)\n",
    "\n",
    "# Função observável.\n",
    "y_noisy = (y + w).reshape(N,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Crie um gráfico comparando as versões original e ruidosa do modelo gerador.\n",
    "\n",
    "**DICAS**\n",
    "+ Se baseie no código do exemplo [error_surface_example1.ipynb](https://colab.research.google.com/github/zz4fap/t319_aprendizado_de_maquina/blob/master/notebooks/regression/error_surface_example1.ipynb) para criar o gráfico solicitado. \n",
    "+ Não se esqueça de importar a biblioteca `Matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escreva o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Na célula abaixo, **importe** a classe `SGDRegressor` e instancie um objeto da classe `Pipeline` para sequencializar a criação da matriz polinomial, padronização dos atributos e treinamento/predição do modelo de regressão.\n",
    "\n",
    "**DICAS**\n",
    "+ Crie uma matriz polinomial adequeda ao problema de regressão com um objeto da classe `PolynomialFeatures`.\n",
    "+ Não se esqueça de adicionar o termo de bias fazendo o parâmetro `include_bias` da classe `PolynomialFeatures` igual a `True`.\n",
    "+ Faça a padronização de atributos com um objeto da classe `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escreva o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Treine o modelo de regressão linear utilizando o método `fit` do objeto da classe `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escreva o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. De posse do modelo treinado, use o método `predict` para prever os valores de saída do modelo usando como entrada o vetor de atributo `x`. Armazene, ou seja, atribua, o resultado da predição em uma variável.\n",
    "\n",
    "**DICA**:\n",
    "+ O vetor `x` foi gerado no item 1 deste exercício."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escreva o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Usando os valores esperados, ou seja, `y_noisy`, e os valores de saída do modelo de regressão linear, ou seja, o resultado da predição feita no item anterior, calcule e imprima o erro quadrático médio.\n",
    "\n",
    "**DICAS**\n",
    "+ Se certifique que ambos os vetores tem as mesmas dimensões. Imprima o atributo `shape` deles para verificar suas dimensões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escreva o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Crie um gráfico comparando os valores originais, ruidosos e gerados pelo modelo de regressão linear obtido com o gradiente descendente estocástico.\n",
    "\n",
    "**DICA**\n",
    "+ Para gerar este gráfico, use o código do item 2 acrescentando o plot dos valores obtidos com a predição feita no item 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escreva o código do exercício aqui."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Observando o gráfico acima, podemos dizer que o modelo aproxima bem o mapeamento original (ou seja, a função geradora)? **Justifique sua resposta.**\n",
    "\n",
    "**DICA**\n",
    "+ O que pode ser feito caso o modelo não aproxime bem o mapeamento verdadeiro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Caso o modelo não aproxime bem o mapeamento verdadeiro, qual parâmetro deve ser alterado para que a aproximação melhore? Altere este parâmetro e re-execute todos os itens deste exercício."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Digite aqui a resposta do exercício.</span>\n",
    "\n",
    "**Resposta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
